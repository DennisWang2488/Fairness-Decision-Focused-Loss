{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87a476d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'solveGroupProblem' from 'src.utils.myOptimization' (/Users/dennis/Downloads/2024-fall/research/Fairness-Decision-Focused-Loss/Organized-FDFL/src/utils/myOptimization.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmyOptimization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m solveGroupProblem\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmyPrediction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_random_features, customPredictionModel\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'solveGroupProblem' from 'src.utils.myOptimization' (/Users/dennis/Downloads/2024-fall/research/Fairness-Decision-Focused-Loss/Organized-FDFL/src/utils/myOptimization.py)"
     ]
    }
   ],
   "source": [
    "from src.utils.myOptimization import solveGroupProblem\n",
    "from src.utils.myPrediction import generate_random_features, customPredictionModel\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from src.utils.features import get_all_features\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c475882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('E:\\\\User\\\\Stevens\\\\MyRepo\\\\Organized-FDFL\\\\src\\\\data\\\\data.csv')\n",
    "df = df.sample(n=5000,random_state=1)\n",
    "\n",
    "# Normalized cost \n",
    "cost = np.array(df['cost_t_capped'].values) \n",
    "cost = np.maximum(cost, 0.1) \n",
    " \n",
    "\n",
    "# All features, standardized\n",
    "features = df[get_all_features(df)].values\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "# True benefit, predictor label \n",
    "true_benefit = np.array(df['benefit'].values).reshape(-1, 1) * 100\n",
    "true_benefit = np.maximum(true_benefit, 0.1) \n",
    "\n",
    "\n",
    "# Group labels, 0 is White (Majority), 1 is Black\n",
    "race = np.array(df['race'].values).reshape(-1, 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b965492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81.98538295015143, 0.1)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_benefit.max(), true_benefit.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07862fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost.max(), cost.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b81891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_fairness_group_utilities(benefit, allocation, group, alpha):\n",
    "    \"\"\"\n",
    "    Compute group-wise alpha-fairness utilities.\n",
    "    \"\"\"\n",
    "    groups = np.unique(group)\n",
    "    utils = []\n",
    "    for k in groups:\n",
    "        mask = (group == k)\n",
    "        Gk = float(mask.sum())\n",
    "        # Compute average utility in group k\n",
    "        util_k = (benefit[mask] * allocation[mask]).sum(axis=0).mean()  # mean total utility per individual in group\n",
    "        if alpha == 1:\n",
    "            val = np.log(util_k) if util_k > 0 else -np.inf\n",
    "        elif alpha == 0:\n",
    "            val = util_k\n",
    "        elif alpha == float('inf'):\n",
    "            # Min utility as min total utility)\n",
    "            val = (benefit[mask] * allocation[mask]).sum(axis=0).min()\n",
    "        else:\n",
    "            val = util_k**(1 - alpha) / (1 - alpha)\n",
    "        utils.append(val)\n",
    "    return np.array(utils).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465940bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Benefit:\n",
      " [[0.001]\n",
      " [0.001]\n",
      " [0.03 ]\n",
      " [0.001]]\n",
      "Allocation:\n",
      " [[ 0.   ]\n",
      " [ 0.   ]\n",
      " [14.473]\n",
      " [14.421]]\n",
      "Objective value: -5.079654644712488\n",
      "Group utilities: -5.079654644712488\n",
      "Groups: [1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "def run_prediction_and_optimization(n=4, T=1, n_features=3, n_groups=2, alpha=1.0, Q=5.0):\n",
    "    # Step 1: Generate random data\n",
    "    features, costs, groups, budget = generate_random_features(n, n_features, T, n_groups, Q)\n",
    "    # Flatten features per individual and time for model input, shape (n*T, n_features)\n",
    "    # Or aggregate features across time depending on your model design\n",
    "    X = features.reshape(n * T, n_features)\n",
    "    \n",
    "    # Step 2: Predict benefit using a simple linear model\n",
    "    # Convert to torch tensor\n",
    "    X_torch = torch.tensor(X, dtype=torch.float32)\n",
    "    model = nn.Linear(n_features, 1)  # simple linear regression\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_torch).numpy().reshape(n, T)\n",
    "    \n",
    "    # Optional: ensure positivity of predicted benefits (important for alpha-fairness)\n",
    "    preds = np.maximum(preds, 1e-3)\n",
    "    \n",
    "    # Step 3: Solve group problem\n",
    "    allocation, obj_value = solveGroupProblem(preds, costs, groups, alpha, budget)\n",
    "    \n",
    "    # Step 4: Compute group-wise utility values\n",
    "    group_utils = alpha_fairness_group_utilities(preds, allocation, groups, alpha)\n",
    "    \n",
    "    return {\n",
    "        'predicted_benefit': preds,\n",
    "        'allocation': allocation,\n",
    "        'objective_value': obj_value,\n",
    "        'group_utilities': group_utils,\n",
    "        'groups': groups\n",
    "    }\n",
    "\n",
    "# Run example\n",
    "result = run_prediction_and_optimization()\n",
    "print(\"Predicted Benefit:\\n\", np.round(result['predicted_benefit'], 3))\n",
    "print(\"Allocation:\\n\", np.round(result['allocation'], 3))\n",
    "print(\"Objective value:\", result['objective_value'])\n",
    "print(\"Group utilities:\", result['group_utilities'])\n",
    "print(\"Groups:\", result['groups'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d8f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6d76bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairRiskPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            # Output layer\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca01c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Loss: 134.3057\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convert the preprocessed features and true benefit to torch tensors\n",
    "X_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(true_benefit, dtype=torch.float32)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataLoader for the training data\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=len(y_tensor), shuffle=True)\n",
    "\n",
    "# Define a simple linear regression model\n",
    "input_dim = X_train.shape[1]\n",
    "# model = nn.Linear(input_dim, 1)\n",
    "model = FairRiskPredictor(input_dim, dropout_rate=0.1)\n",
    "\n",
    "# Use Mean Squared Error loss and Adam optimizer with weight decay to alleviate overfitting\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "\n",
    "# Train for a moderate number of epochs with early stopping hints through monitoring loss\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "    avg_loss = running_loss / len(train_dataset)\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')\n",
    "\n",
    "# With the trained model, generate predictions on the full dataset\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred_benefit = model(X_tensor).numpy()\n",
    "\n",
    "pred_benefit = np.maximum(pred_benefit, 1e-3)  # Ensure positivity\n",
    "  # Ensure positivity of costs\n",
    "\n",
    "# Solve the group problem with the predicted benefits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350fdf7e",
   "metadata": {},
   "source": [
    "1. I have PTO first half\n",
    "2. Need to calculate `regret`\n",
    "3. Train end-to-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416cae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 2\n",
    "Q = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9e235d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\14469\\anaconda3\\Lib\\site-packages\\cvxpy\\reductions\\solvers\\solving_chain_utils.py:30: UserWarning: The problem includes expressions that don't support CPP backend. Defaulting to the SCIPY backend for canonicalization.\n",
      "  warnings.warn(UserWarning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Objective Value: -0.04606651691343278\n",
      "Predicted Objective Value: -0.055021162113291666\n"
     ]
    }
   ],
   "source": [
    "sol, _ = solveGroupProblem(pred_benefit, cost, race, alpha=alpha, Q=Q)\n",
    "\n",
    "true_sol, _ = solveGroupProblem(true_benefit, cost, race, alpha=alpha, Q=Q)\n",
    "  # Ensure positivity\n",
    "true_obj = alpha_fairness_group_utilities(true_benefit, true_sol, race, alpha=alpha)\n",
    "\n",
    "print(\"True Objective Value:\", true_obj)\n",
    "\n",
    "pred_obj = alpha_fairness_group_utilities(true_benefit, sol, race, alpha=alpha)\n",
    "\n",
    "print(\"Predicted Objective Value:\", pred_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a1a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Regret: 0.19438469329506494\n"
     ]
    }
   ],
   "source": [
    "normalized_regret = (true_obj - pred_obj) / (abs(true_obj) + 1e-7)\n",
    "print(\"Normalized Regret:\", normalized_regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9c1210",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_benefit.shape\n",
    "mask = race == 2\n",
    "# per-group best benefit-cost ratio ρ_k and its argmax (i*,t*)\n",
    "rho_k = np.zeros(2)\n",
    "idx_k = np.zeros((2, 2), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e576b623",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 25000000 but corresponding boolean dimension is 5000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[147], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m mask \u001b[38;5;241m=\u001b[39m (race \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m      2\u001b[0m ratio \u001b[38;5;241m=\u001b[39m (true_benefit \u001b[38;5;241m/\u001b[39m cost)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m----> 3\u001b[0m ratio \u001b[38;5;241m=\u001b[39m ratio[mask]\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 25000000 but corresponding boolean dimension is 5000"
     ]
    }
   ],
   "source": [
    "mask = race == 0\n",
    "ratio = (true_benefit / cost)\n",
    "ratio = ratio[mask].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17afb18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " ...\n",
      " [ True]\n",
      " [False]\n",
      " [ True]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[138], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m mask \u001b[38;5;241m=\u001b[39m race \u001b[38;5;241m==\u001b[39m i\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(mask)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(true_benefit[mask]\u001b[38;5;241m.\u001b[39mshape, cost[mask]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      5\u001b[0m ratio \u001b[38;5;241m=\u001b[39m (true_benefit[mask] \u001b[38;5;241m/\u001b[39m cost[mask])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m i_star \u001b[38;5;241m=\u001b[39m ratio\u001b[38;5;241m.\u001b[39margmax()\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    mask = race == i\n",
    "    print(mask)\n",
    "    print(true_benefit[mask].shape, cost[mask].shape)\n",
    "    ratio = (true_benefit[mask] / cost[mask]).reshape(-1)\n",
    "    i_star = ratio.argmax()\n",
    "    i_glob = np.where(mask)[0][i_star // true_benefit.shape[1]]\n",
    "    t_glob = i_star % true_benefit.shape[1]\n",
    "    rho_k[i] = ratio.max()\n",
    "    idx_k[i] = [i_glob, t_glob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f4e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closed_form_group_alpha(\n",
    "    b_hat,\n",
    "    cost,\n",
    "    group,\n",
    "    alpha, \n",
    "    Q\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    b_hat : (N,T)  positive utilities\n",
    "    cost  : (N,T)  positive costs\n",
    "    group : (N,)   integers 0..K-1\n",
    "    Q     : float  budget\n",
    "    alpha : float >0 or 0 or 1 or np.inf\n",
    "    Returns\n",
    "    -------\n",
    "    d_star : (N,T) optimal doses\n",
    "    \"\"\"\n",
    "    N, T = b_hat.shape\n",
    "    K = group.max() + 1\n",
    "\n",
    "    # per-group best benefit-cost ratio ρ_k and its argmax (i*,t*)\n",
    "    rho_k = np.zeros(K)\n",
    "    idx_k = np.zeros((K, 2), dtype=int)\n",
    "    for k in range(K):\n",
    "        mask = group == k\n",
    "        ratio = (b_hat[mask] / cost[mask]).reshape(-1)\n",
    "        i_star = ratio.argmax()\n",
    "        i_glob = np.where(mask)[0][i_star // T]\n",
    "        t_glob = i_star % T\n",
    "        rho_k[k] = ratio.max()\n",
    "        idx_k[k] = [i_glob, t_glob]\n",
    "\n",
    "    p_k = rho_k / np.bincount(group)  # p_k = ρ_k / G_k\n",
    "\n",
    "    # ------------ Stage I: allocate budget B_k = x_k ------------\n",
    "    if alpha == 0:  # utilitarian\n",
    "        winners = np.flatnonzero(p_k == p_k.max())\n",
    "        x = np.zeros(K)\n",
    "        x[winners] = Q / len(winners)\n",
    "    elif alpha == 1:  # logarithmic\n",
    "        x = np.full(K, Q / K)\n",
    "    elif alpha == np.inf:  # max-min\n",
    "        inv = 1 / p_k\n",
    "        x = Q * inv / inv.sum()\n",
    "    else:  # generic  (0<α<∞, α≠1)\n",
    "        weights = p_k ** (1 / alpha - 1)\n",
    "        x = Q * weights / weights.sum()\n",
    "\n",
    "    # ------------ Stage II: spend each x_k on its best item -----\n",
    "    d_star = np.zeros_like(b_hat)\n",
    "    for k in range(K):\n",
    "        i, t = idx_k[k]\n",
    "        d_star[i, t] = x[k] / cost[i, t]\n",
    "\n",
    "    return d_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd281d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sol \u001b[38;5;241m=\u001b[39m closed_form_group_alpha(true_benefit, cost, race, alpha\u001b[38;5;241m=\u001b[39malpha, Q\u001b[38;5;241m=\u001b[39mQ)\n",
      "Cell \u001b[1;32mIn[125], line 28\u001b[0m, in \u001b[0;36mclosed_form_group_alpha\u001b[1;34m(b_hat, cost, group, alpha, Q)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(K):\n\u001b[0;32m     27\u001b[0m     mask \u001b[38;5;241m=\u001b[39m group \u001b[38;5;241m==\u001b[39m k\n\u001b[1;32m---> 28\u001b[0m     ratio \u001b[38;5;241m=\u001b[39m (b_hat[mask] \u001b[38;5;241m/\u001b[39m cost[mask])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     29\u001b[0m     i_star \u001b[38;5;241m=\u001b[39m ratio\u001b[38;5;241m.\u001b[39margmax()\n\u001b[0;32m     30\u001b[0m     i_glob \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(mask)[\u001b[38;5;241m0\u001b[39m][i_star \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m T]\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "sol = closed_form_group_alpha(true_benefit, cost, race, alpha=alpha, Q=Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f859bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AlphaFairness(util, alpha):\n",
    "    if isinstance(util, torch.Tensor):\n",
    "        util = util.detach().cpu().numpy() if isinstance(util, torch.Tensor) else util\n",
    "    if alpha == 1:\n",
    "        return np.sum(np.log(util))\n",
    "    elif alpha == 0:\n",
    "        return np.sum(util)\n",
    "    elif alpha == 'inf':\n",
    "        return np.min(util)\n",
    "    else:\n",
    "        return np.sum(util**(1-alpha) / (1-alpha))\n",
    "\n",
    "def solve_optimization(gainF, risk, cost, alpha, Q):\n",
    "    gainF = gainF.detach().cpu().numpy() if isinstance(gainF, torch.Tensor) else gainF\n",
    "    risk = risk.detach().cpu().numpy() if isinstance(risk, torch.Tensor) else risk\n",
    "    cost = cost.detach().cpu().numpy() if isinstance(cost, torch.Tensor) else cost\n",
    "\n",
    "    risk = risk.clip(0.001)\n",
    "    gainF, risk, cost = gainF.flatten(), risk.flatten(), cost.flatten()\n",
    "    d = cp.Variable(risk.shape, nonneg=True)\n",
    "\n",
    "    if gainF.shape != risk.shape or risk.shape != cost.shape:\n",
    "        raise ValueError(\"Dimensions of gainF, risk, and cost do not match\")\n",
    "\n",
    "    utils = cp.multiply(cp.multiply(gainF, risk), d)\n",
    "    constraints = [d >= 0, cp.sum(cost * d) <= Q]\n",
    "\n",
    "    if alpha == 'inf':\n",
    "        t = cp.Variable()\n",
    "        objective = cp.Maximize(t)\n",
    "        constraints.append(utils >= t)\n",
    "    elif alpha == 1:\n",
    "        objective = cp.Maximize(cp.sum(cp.log(utils)))\n",
    "    elif alpha == 0:\n",
    "        objective = cp.Maximize(cp.sum(utils))\n",
    "    else:\n",
    "        objective = cp.Maximize(cp.sum(utils**(1-alpha)) / (1-alpha))\n",
    "\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve(solver=cp.MOSEK, verbose=False, warm_start=True, mosek_params={'MSK_IPAR_LOG': 1})\n",
    "\n",
    "    if problem.status != 'optimal':\n",
    "        print(f\"Warning: Problem status is {problem.status}\")\n",
    "\n",
    "    optimal_decision = d.value\n",
    "    optimal_value = AlphaFairness(optimal_decision * gainF * risk, alpha)\n",
    "\n",
    "    return optimal_decision, optimal_value\n",
    "import numpy as np\n",
    "\n",
    "def solve_closed_form(g, r, c, alpha, Q):\n",
    "\n",
    "    g = g.detach().cpu().numpy() if isinstance(g, torch.Tensor) else g\n",
    "    r = r.detach().cpu().numpy() if isinstance(r, torch.Tensor) else r\n",
    "    c = c.detach().cpu().numpy() if isinstance(c, torch.Tensor) else c\n",
    "    if c.shape != r.shape or c.shape != g.shape:\n",
    "        raise ValueError(\"c, r, and g must have the same shape.\")\n",
    "    if np.any(c <= 0):\n",
    "        raise ValueError(\"All cost values must be positive.\")\n",
    "    if np.any(r <= 0):\n",
    "        raise ValueError(\"All risk values must be positive.\")\n",
    "    if np.any(g <= 0):\n",
    "        raise ValueError(\"All gain factors must be positive.\")\n",
    "    \n",
    "    n = len(c)\n",
    "    utility = r * g\n",
    "    \n",
    "    if alpha == 0:\n",
    "        ratios = utility / c\n",
    "        sorted_indices = np.argsort(-ratios)  # Descending order\n",
    "        d_star_closed = np.zeros(n)\n",
    "        d_star_closed[sorted_indices[0]] = Q / c[sorted_indices[0]]\n",
    "        \n",
    "    elif alpha == 1:\n",
    "        d_star_closed = Q / (n * c)\n",
    "    \n",
    "    elif alpha == 'inf':\n",
    "        d_star_closed = (Q * c) / (utility * np.sum(c * c / utility))\n",
    "        \n",
    "    else:\n",
    "        if alpha <= 0:\n",
    "            raise ValueError(\"Alpha must be positive for general case.\")\n",
    "        #\n",
    "        # d_i* = (c_i^(-1/alpha) * (r_i*g_i)^(1/alpha - 1) * Q) / sum_j(c_j^(-1/alpha) * (r_j*g_j)^(1/alpha - 1))\n",
    "        \n",
    "        numerator = np.power(c, -1/alpha) * np.power(utility, 1/alpha - 1)\n",
    "        denominator = np.sum(numerator)\n",
    "        \n",
    "        if denominator == 0:\n",
    "            raise ValueError(\"Denominator is zero in closed-form solution.\")\n",
    "            \n",
    "        d_star_closed = (numerator / denominator) * Q\n",
    "    \n",
    "    # if not np.isclose(np.sum(c * d_star_closed), Q, rtol=1e-5):\n",
    "    #     raise ValueError(\"Solution does not satisfy budget constraint.\")\n",
    "    obj = AlphaFairness(d_star_closed * utility, alpha)\n",
    "        \n",
    "    return d_star_closed, obj\n",
    "\n",
    "def compute_gradient_closed_form(g, r, c, alpha, Q):\n",
    "    \"\"\"\n",
    "    Compute the analytical gradient of the optimal solution with respect to r.\n",
    "\n",
    "    This function computes the gradient matrix where each element (i, k) is the partial derivative\n",
    "    of d_i* with respect to r_k.\n",
    "\n",
    "    Parameters:\n",
    "    - g (np.ndarray): Gain factors (g_i), shape (n,)\n",
    "    - r (np.ndarray): Risk values (r_i), shape (n,)\n",
    "    - c (np.ndarray): Cost values (c_i), shape (n,)\n",
    "    - alpha (float or str): Fairness parameter. Can be 0, 1, 'inf', or a positive real number.\n",
    "    - Q (float): Total budget.\n",
    "\n",
    "    Returns:\n",
    "    - gradient (np.ndarray): Gradient matrix of shape (n, n)\n",
    "    \"\"\"\n",
    "    if alpha == 1:\n",
    "        S = np.sum(c / (r * g))\n",
    "\n",
    "    if alpha == 0:\n",
    "        # Utilitarian case: Allocate everything to the individual with the highest ratio\n",
    "        ratios = (r * g) / c\n",
    "        i_star = np.argmax(ratios)\n",
    "        # Gradient is Q * g_i / c_i at the allocated index, zero elsewhere\n",
    "        gradient[i_star, i_star] = Q * g[i_star] / c[i_star]\n",
    "        return gradient\n",
    "\n",
    "    elif alpha == 'inf':\n",
    "        # Maximin case\n",
    "        n = len(c)\n",
    "        utility = r * g  # Shape: (n,)\n",
    "        S = np.sum(c**2 / utility)  # Scalar\n",
    "\n",
    "        # Compute d_star\n",
    "        d_star, _ = solve_closed_form(g,r,c, alpha='inf', Q=Q)  # Shape: (n,)\n",
    "\n",
    "        # Initialize gradient matrix\n",
    "        gradient = np.zeros((n, n))\n",
    "\n",
    "        for i in range(n):\n",
    "            for k in range(n):\n",
    "                if i == k:\n",
    "                    # ∂d_i*/∂r_i = -d_i*/r_i - (d_i* * c_i) / (r_i * g_i * S)\n",
    "                    gradient[i, k] = -d_star[i] / r[i] - (d_star[i] * c[i]) / (r[i] * g[i] * S)\n",
    "                else:\n",
    "                    # ∂d_i*/∂r_k = (d_i* * c_k^2) / (c_i * r_k^2 * g_k * S)\n",
    "                    gradient[i, k] = (d_star[i] * c[k]**2) / (c[i] * r[k]**2 * g[k] * S)\n",
    "        return gradient\n",
    "\n",
    "    else:\n",
    "        # General alpha case\n",
    "        if not isinstance(alpha, (int, float)):\n",
    "            raise TypeError(\"Alpha must be a positive real number, 0, 1, or 'inf'.\")\n",
    "        if alpha <= 0:\n",
    "            raise ValueError(\"Alpha must be positive for gradient computation.\")\n",
    "\n",
    "        # Compute the optimal decision variables\n",
    "        d_star, _ = solve_closed_form(g, r, c, alpha, Q)  # Shape: (n,)\n",
    "\n",
    "        # Compute the term (1/alpha - 1) * g / r\n",
    "        term = (1.0 / alpha - 1.0) * g / r  # Shape: (n,)\n",
    "\n",
    "        # Compute the outer product for off-diagonal elements\n",
    "        # Each element (i, k) = -d_star[i] * d_star[k] * term[k] / Q\n",
    "        gradient = -np.outer(d_star, d_star * term) / Q  # Shape: (n, n)\n",
    "\n",
    "        # Compute the diagonal elements\n",
    "        # Each diagonal element (i, i) = d_star[i] * term[i] * (1 - d_star[i]/Q)\n",
    "        diag_elements = d_star * term * (1 - d_star / Q)  # Shape: (n,)\n",
    "\n",
    "        # Set the diagonal elements\n",
    "        np.fill_diagonal(gradient, diag_elements)\n",
    "\n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4080e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "c, r, and g must have the same shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m pred_r \u001b[38;5;241m=\u001b[39m pred_benefit\n\u001b[0;32m      3\u001b[0m gainF \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones_like(true_r)\n\u001b[1;32m----> 5\u001b[0m sol, obj \u001b[38;5;241m=\u001b[39m solve_closed_form(gainF, true_r, cost, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, Q\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      6\u001b[0m sol, obj\n",
      "Cell \u001b[1;32mIn[98], line 57\u001b[0m, in \u001b[0;36msolve_closed_form\u001b[1;34m(g, r, c, alpha, Q)\u001b[0m\n\u001b[0;32m     55\u001b[0m c \u001b[38;5;241m=\u001b[39m c\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(c, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m c\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m c\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m r\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mor\u001b[39;00m c\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m g\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc, r, and g must have the same shape.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(c \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll cost values must be positive.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: c, r, and g must have the same shape."
     ]
    }
   ],
   "source": [
    "true_r = true_benefit\n",
    "pred_r = pred_benefit\n",
    "gainF = np.ones_like(true_r)\n",
    "\n",
    "sol, obj = solve_closed_form(gainF, true_r, cost, alpha=2, Q=100)\n",
    "sol, obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e757513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\14469\\anaconda3\\Lib\\site-packages\\cvxpy\\expressions\\expression.py:674: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "This code path has been hit 2 times so far.\n",
      "\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "ename": "SolverError",
     "evalue": "Solver 'MOSEK' failed. Try another solver, or solve with verbose=True for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSolverError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sol, obj \u001b[38;5;241m=\u001b[39m solve_optimization(gainF, true_r, cost, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, Q\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      2\u001b[0m sol, obj\n",
      "Cell \u001b[1;32mIn[58], line 40\u001b[0m, in \u001b[0;36msolve_optimization\u001b[1;34m(gainF, risk, cost, alpha, Q)\u001b[0m\n\u001b[0;32m     37\u001b[0m     objective \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mMaximize(cp\u001b[38;5;241m.\u001b[39msum(utils\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39malpha)) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39malpha))\n\u001b[0;32m     39\u001b[0m problem \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mProblem(objective, constraints)\n\u001b[1;32m---> 40\u001b[0m problem\u001b[38;5;241m.\u001b[39msolve(solver\u001b[38;5;241m=\u001b[39mcp\u001b[38;5;241m.\u001b[39mMOSEK, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, warm_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mosek_params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSK_IPAR_LOG\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m})\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m problem\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: Problem status is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproblem\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\14469\\anaconda3\\Lib\\site-packages\\cvxpy\\problems\\problem.py:600\u001b[0m, in \u001b[0;36mProblem.solve\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    598\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot specify both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver_path\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please choose one.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solve_solver_path(solve_func,solver_path, args, kwargs)\n\u001b[1;32m--> 600\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solve_func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\14469\\anaconda3\\Lib\\site-packages\\cvxpy\\problems\\problem.py:1187\u001b[0m, in \u001b[0;36mProblem._solve\u001b[1;34m(self, solver, warm_start, verbose, gp, qcp, requires_grad, enforce_dpp, ignore_dpp, canon_backend, **kwargs)\u001b[0m\n\u001b[0;32m   1185\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solve_time \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m-> 1187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munpack_results(solution, solving_chain, inverse_data)\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m   1189\u001b[0m     \u001b[38;5;28mprint\u001b[39m(_FOOTER)\n",
      "File \u001b[1;32mc:\\Users\\14469\\anaconda3\\Lib\\site-packages\\cvxpy\\problems\\problem.py:1512\u001b[0m, in \u001b[0;36mProblem.unpack_results\u001b[1;34m(self, solution, chain, inverse_data)\u001b[0m\n\u001b[0;32m   1510\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(INF_OR_UNB_MESSAGE)\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solution\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m s\u001b[38;5;241m.\u001b[39mERROR:\n\u001b[1;32m-> 1512\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mSolverError(\n\u001b[0;32m   1513\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolver \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m failed. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m chain\u001b[38;5;241m.\u001b[39msolver\u001b[38;5;241m.\u001b[39mname() \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m   1514\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry another solver, or solve with verbose=True for more \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1515\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minformation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munpack(solution)\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solver_stats \u001b[38;5;241m=\u001b[39m SolverStats\u001b[38;5;241m.\u001b[39mfrom_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solution\u001b[38;5;241m.\u001b[39mattr,\n\u001b[0;32m   1519\u001b[0m                                  chain\u001b[38;5;241m.\u001b[39msolver\u001b[38;5;241m.\u001b[39mname())\n",
      "\u001b[1;31mSolverError\u001b[0m: Solver 'MOSEK' failed. Try another solver, or solve with verbose=True for more information."
     ]
    }
   ],
   "source": [
    "sol, obj = solve_optimization(gainF, true_r, cost, alpha=2, Q=100)\n",
    "sol, obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0471a517",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fair",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
