{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87a476d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.myOptimization import solveGroupProblem\n",
    "from src.utils.myPrediction import generate_random_features, customPredictionModel\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from src.utils.features import get_all_features\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c475882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('E:\\\\User\\\\Stevens\\\\MyRepo\\\\Organized-FDFL\\\\src\\\\data\\\\data.csv')\n",
    "df = df.sample(n=200,random_state=1)\n",
    "\n",
    "# Normalized cost \n",
    "cost = np.array(df['cost_t_capped'].values).reshape(-1, 1) * 10\n",
    "cost = np.maximum(cost, 0.1)\n",
    "\n",
    "\n",
    "# All features, standardized\n",
    "features = df[get_all_features(df)].values\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "# True benefit, predictor label \n",
    "true_benefit = np.array(df['benefit'].values).reshape(-1, 1) * 100\n",
    "true_benefit = np.maximum(true_benefit, 0.1) \n",
    "\n",
    "\n",
    "# Group labels, 0 is White (Majority), 1 is Black\n",
    "race = np.array(df['race'].values).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07862fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_individual_fairness(pred: torch.Tensor,\n",
    "                                 true: torch.Tensor,\n",
    "                                 race: torch.Tensor,\n",
    "                                 d_func=None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes individual fairness: similar individuals across groups should receive similar predictions.\n",
    "    \"\"\"\n",
    "    # Flatten everything to 1D\n",
    "    pred = pred.view(-1)\n",
    "    true = true.view(-1)\n",
    "    race = race.view(-1)\n",
    "\n",
    "    if d_func is None:\n",
    "        d_func = lambda y1, y2: torch.exp(-(y1 - y2).pow(2))\n",
    "\n",
    "    mask0 = (race == 0)\n",
    "    mask1 = (race == 1)\n",
    "\n",
    "    pred0, pred1 = pred[mask0], pred[mask1]\n",
    "    true0, true1 = true[mask0], true[mask1]\n",
    "\n",
    "    n0, n1 = pred0.shape[0], pred1.shape[0]\n",
    "    if n0 == 0 or n1 == 0:\n",
    "        return torch.tensor(0.0, device=pred.device)\n",
    "\n",
    "    pred_diff = pred0.unsqueeze(1) - pred1.unsqueeze(0)       # (n0, n1)\n",
    "    true_sim = d_func(true0.unsqueeze(1), true1.unsqueeze(0)) # (n0, n1)\n",
    "\n",
    "    fairness_penalty = (true_sim * pred_diff.pow(2)).mean()\n",
    "    return fairness_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b81891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_fairness_group_utilities(benefit, allocation, group, alpha):\n",
    "    \"\"\"\n",
    "    Compute group-wise alpha-fairness utilities.\n",
    "    \"\"\"\n",
    "    groups = np.unique(group)\n",
    "    utils = []\n",
    "    for k in groups:\n",
    "        mask = (group == k)\n",
    "        Gk = float(mask.sum())\n",
    "        # Compute average utility in group k\n",
    "        util_k = (benefit[mask] * allocation[mask]).sum(axis=0).mean()  # mean total utility per individual in group\n",
    "        if alpha == 1:\n",
    "            val = np.log(util_k) if util_k > 0 else -np.inf\n",
    "        elif alpha == 0:\n",
    "            val = util_k\n",
    "        elif alpha == float('inf'):\n",
    "            # Min utility as min total utility)\n",
    "            val = (benefit[mask] * allocation[mask]).sum(axis=0).min()\n",
    "        else:\n",
    "            val = util_k**(1 - alpha) / (1 - alpha)\n",
    "        utils.append(val)\n",
    "    return np.array(utils).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "465940bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Benefit:\n",
      " [[0.001]\n",
      " [0.001]\n",
      " [0.001]\n",
      " [0.001]]\n",
      "Allocation:\n",
      " [[ 0.   ]\n",
      " [ 0.   ]\n",
      " [14.471]\n",
      " [14.423]]\n",
      "Objective value: -8.474528929210692\n",
      "Group utilities: -8.474528929210692\n",
      "Groups: [1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "def run_prediction_and_optimization(n=4, T=1, n_features=3, n_groups=2, alpha=1.0, Q=5.0):\n",
    "    # Step 1: Generate random data\n",
    "    features, costs, groups, budget = generate_random_features(n, n_features, T, n_groups, Q)\n",
    "    # Flatten features per individual and time for model input, shape (n*T, n_features)\n",
    "    # Or aggregate features across time depending on your model design\n",
    "    X = features.reshape(n * T, n_features)\n",
    "    \n",
    "    # Step 2: Predict benefit using a simple linear model\n",
    "    # Convert to torch tensor\n",
    "    X_torch = torch.tensor(X, dtype=torch.float32)\n",
    "    model = nn.Linear(n_features, 1)  # simple linear regression\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_torch).numpy().reshape(n, T)\n",
    "    \n",
    "    # Optional: ensure positivity of predicted benefits (important for alpha-fairness)\n",
    "    preds = np.maximum(preds, 1e-3)\n",
    "    \n",
    "    # Step 3: Solve group problem\n",
    "    allocation, obj_value = solveGroupProblem(preds, costs, groups, alpha, budget)\n",
    "    \n",
    "    # Step 4: Compute group-wise utility values\n",
    "    group_utils = alpha_fairness_group_utilities(preds, allocation, groups, alpha)\n",
    "    \n",
    "    return {\n",
    "        'predicted_benefit': preds,\n",
    "        'allocation': allocation,\n",
    "        'objective_value': obj_value,\n",
    "        'group_utilities': group_utils,\n",
    "        'groups': groups\n",
    "    }\n",
    "\n",
    "# Run example\n",
    "result = run_prediction_and_optimization()\n",
    "print(\"Predicted Benefit:\\n\", np.round(result['predicted_benefit'], 3))\n",
    "print(\"Allocation:\\n\", np.round(result['allocation'], 3))\n",
    "print(\"Objective value:\", result['objective_value'])\n",
    "print(\"Group utilities:\", result['group_utilities'])\n",
    "print(\"Groups:\", result['groups'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d8f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af6d76bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairRiskPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(64, 32),      # added hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfca01c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 423.8417\n",
      "Epoch 5/30, Loss: 389.8014\n",
      "Epoch 10/30, Loss: 315.7221\n",
      "Epoch 15/30, Loss: 296.7944\n",
      "Epoch 20/30, Loss: 298.0353\n",
      "Epoch 25/30, Loss: 291.8675\n",
      "Epoch 30/30, Loss: 292.7226\n",
      "Individual fairness score: 0.4415\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convert the preprocessed features, target, and race labels to torch tensors\n",
    "X_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(true_benefit, dtype=torch.float32)\n",
    "race_tensor = torch.tensor(race, dtype=torch.int64)  # assumes race is a 1D array of 0/1\n",
    "\n",
    "# Split the data into training and testing sets (80/20)\n",
    "X_train, X_test, y_train, y_test, race_train, race_test = train_test_split(\n",
    "    X_tensor, y_tensor, race_tensor, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create a DataLoader for the training data\n",
    "train_dataset = TensorDataset(X_train, y_train, race_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=len(y_train), shuffle=True)\n",
    "\n",
    "# Define model\n",
    "input_dim = X_train.shape[1]\n",
    "model = FairRiskPredictor(input_dim, dropout_rate=0.1)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "\n",
    "# Fairness regularization weight\n",
    "lambda_fair = 1.0  # tune this hyperparameter\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch, race_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred_batch = model(X_batch).squeeze()  # shape: (batch,)\n",
    "        \n",
    "        mse_loss = criterion(pred_batch, y_batch)\n",
    "        fair_penalty = compute_individual_fairness(\n",
    "            pred_batch.squeeze(),    # ensure shape (n,)\n",
    "            y_batch.squeeze(),\n",
    "            race_batch.squeeze()\n",
    "        )\n",
    "        loss = mse_loss + lambda_fair * fair_penalty\n",
    "\n",
    "        loss = mse_loss + lambda_fair * fair_penalty # type: ignore\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    avg_loss = running_loss / len(train_dataset)\n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Inference on full data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred_benefit = model(X_tensor).squeeze().numpy()\n",
    "\n",
    "# Ensure positivity for decision optimization\n",
    "pred_benefit = np.maximum(pred_benefit, 1e-1)\n",
    "\n",
    "# Fairness evaluation\n",
    "fairness_score = compute_individual_fairness(\n",
    "    torch.tensor(pred_benefit, dtype=torch.float32),\n",
    "    y_tensor.view(-1),\n",
    "    torch.tensor(race, dtype=torch.int64)\n",
    ")\n",
    "print(f\"Individual fairness score: {fairness_score.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350fdf7e",
   "metadata": {},
   "source": [
    "1. I have PTO first half\n",
    "2. Need to calculate `regret`\n",
    "3. Train end-to-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "416cae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 2\n",
    "Q = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f9e235d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sol, _ \u001b[38;5;241m=\u001b[39m solveGroupProblem(pred_benefit, cost, race, alpha\u001b[38;5;241m=\u001b[39malpha, Q\u001b[38;5;241m=\u001b[39mQ)\n\u001b[0;32m      3\u001b[0m true_sol, _ \u001b[38;5;241m=\u001b[39m solveGroupProblem(true_benefit, cost, race, alpha\u001b[38;5;241m=\u001b[39malpha, Q\u001b[38;5;241m=\u001b[39mQ)\n\u001b[0;32m      4\u001b[0m true_obj \u001b[38;5;241m=\u001b[39m alpha_fairness_group_utilities(true_benefit, true_sol, race, alpha\u001b[38;5;241m=\u001b[39malpha)\n",
      "File \u001b[1;32me:\\user\\stevens\\myrepo\\organized-fdfl\\src\\utils\\myOptimization.py:91\u001b[0m, in \u001b[0;36msolveGroupProblem\u001b[1;34m(benefit, cost, group, alpha, Q)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msolveGroupProblem\u001b[39m(benefit,\n\u001b[0;32m     69\u001b[0m                       cost,\n\u001b[0;32m     70\u001b[0m                       group,\n\u001b[0;32m     71\u001b[0m                       alpha,\n\u001b[0;32m     72\u001b[0m                       Q):\n\u001b[0;32m     73\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m    Solve the group-based alpha-fair allocation problem:\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m       max_d  W_alpha(d)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m        Total available budget.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m     n, T \u001b[38;5;241m=\u001b[39m benefit\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     92\u001b[0m     groups \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(group)\n\u001b[0;32m     93\u001b[0m     K \u001b[38;5;241m=\u001b[39m groups\u001b[38;5;241m.\u001b[39msize\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "sol, _ = solveGroupProblem(pred_benefit, cost, race, alpha=alpha, Q=Q)\n",
    "\n",
    "true_sol, _ = solveGroupProblem(true_benefit, cost, race, alpha=alpha, Q=Q)\n",
    "true_obj = alpha_fairness_group_utilities(true_benefit, true_sol, race, alpha=alpha)\n",
    "\n",
    "print(\"True Objective Value:\", true_obj)\n",
    "\n",
    "pred_obj = alpha_fairness_group_utilities(true_benefit, sol, race, alpha=alpha)\n",
    "\n",
    "print(\"Predicted Objective Value:\", pred_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a1a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Regret: 0.017005703424885735\n"
     ]
    }
   ],
   "source": [
    "normalized_regret = (true_obj - pred_obj) / (abs(true_obj) + 1e-7)\n",
    "print(\"Normalized Regret:\", normalized_regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e373df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 1), (200, 1), (200, 1))"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race.shape, true_benefit.shape, cost.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f4e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closed_form_group_alpha(b_hat, cost, group, Q, alpha):\n",
    "    \"\"\"\n",
    "    b_hat : (N,)  or (N,1) or (N,T)    strictly positive\n",
    "    cost  : same shape as b_hat (broadcast OK)\n",
    "    group : (N,)  or (N,1)  integer labels 0 … K-1\n",
    "    Q     : scalar > 0\n",
    "    alpha : 0, 1, np.inf, or positive float\n",
    "    \"\"\"\n",
    "    # ------------ 1. normalise shapes ---------------------------------\n",
    "    b_hat = np.asarray(b_hat, dtype=float)\n",
    "    cost  = np.asarray(cost,  dtype=float)\n",
    "\n",
    "    if b_hat.ndim == 1:                        # promote to 2-D (N,1)\n",
    "        b_hat = b_hat[:, None]\n",
    "    if cost.ndim == 1:\n",
    "        cost  = cost[:, None]\n",
    "    if cost.shape[1] == 1 and b_hat.shape[1] > 1:\n",
    "        cost = np.repeat(cost, b_hat.shape[1], axis=1)\n",
    "    if b_hat.shape[1] == 1 and cost.shape[1] > 1:\n",
    "        b_hat = np.repeat(b_hat, cost.shape[1], axis=1)\n",
    "    assert b_hat.shape == cost.shape, \"benefit & cost must broadcast\"\n",
    "\n",
    "    # ------------ 2. squeeze group to 1-D int array -------------------\n",
    "    group = np.asarray(group).astype(int).reshape(-1)\n",
    "    if group.ndim != 1:\n",
    "        raise ValueError(\"`group` must be 1-D after reshape\")\n",
    "    N, T = b_hat.shape\n",
    "    if group.size != N:\n",
    "        raise ValueError(\"length of `group` must equal #rows of b_hat\")\n",
    "\n",
    "    K  = group.max() + 1\n",
    "    G  = np.bincount(group, minlength=K)       # each G_k > 0 ?\n",
    "\n",
    "    # ------------ 3. best ratio per group ----------------------------\n",
    "    rho   = np.empty(K)\n",
    "    idx_k = np.empty((K, 2), dtype=int)\n",
    "\n",
    "    for k in range(K):\n",
    "        rows = np.flatnonzero(group == k)\n",
    "        ratio_sub = b_hat[rows] / cost[rows]   # shape (|rows|, T)\n",
    "        flat_idx  = ratio_sub.argmax()         # 0 … |rows|·T−1\n",
    "        r_loc, t_star = divmod(flat_idx, T)\n",
    "        i_star = rows[r_loc] # type: ignore\n",
    "        rho[k]  = ratio_sub.flat[flat_idx]\n",
    "        idx_k[k] = (i_star, t_star)\n",
    "\n",
    "    p = rho / G                                # p_k = ρ_k / G_k\n",
    "\n",
    "    # ------------ 4. allocate budgets x_k ----------------------------\n",
    "    if alpha == 0:                             # utilitarian\n",
    "        winners = np.flatnonzero(p == p.max())\n",
    "        x = np.zeros(K)\n",
    "        x[winners] = Q / len(winners)\n",
    "    elif alpha == 1:                           # log utility\n",
    "        x = np.full(K, Q / K)\n",
    "    elif alpha == np.inf:                      # max–min\n",
    "        inv = 1 / p\n",
    "        x = Q * inv / inv.sum()\n",
    "    else:                                      # generic α\n",
    "        beta   = 1.0 / alpha\n",
    "        w      = p ** (beta - 1)\n",
    "        x = Q * w / w.sum()\n",
    "\n",
    "    # ------------ 5. build decision matrix ---------------------------\n",
    "    d_star = np.zeros_like(b_hat)\n",
    "    for k, (i, t) in enumerate(idx_k):\n",
    "        d_star[i, t] = x[k] / cost[i, t]\n",
    "\n",
    "    return d_star, idx_k, x, rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd281d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed Form Objective Value: -0.0005896091691414507\n"
     ]
    }
   ],
   "source": [
    "sol_c, _, _, _ = closed_form_group_alpha(true_benefit, cost, race, Q, alpha)\n",
    "obj_c = alpha_fairness_group_utilities(true_benefit, sol_c, race, alpha)\n",
    "print(\"Closed Form Objective Value:\", obj_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e69f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(sol_c, np.array(true_sol), rtol=1e-3, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f859bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AlphaFairness(util, alpha):\n",
    "    if isinstance(util, torch.Tensor):\n",
    "        util = util.detach().cpu().numpy() if isinstance(util, torch.Tensor) else util\n",
    "    if alpha == 1:\n",
    "        return np.sum(np.log(util))\n",
    "    elif alpha == 0:\n",
    "        return np.sum(util)\n",
    "    elif alpha == 'inf':\n",
    "        return np.min(util)\n",
    "    else:\n",
    "        return np.sum(util**(1-alpha) / (1-alpha))\n",
    "\n",
    "def solve_optimization(gainF, risk, cost, alpha, Q):\n",
    "    gainF = gainF.detach().cpu().numpy() if isinstance(gainF, torch.Tensor) else gainF\n",
    "    risk = risk.detach().cpu().numpy() if isinstance(risk, torch.Tensor) else risk\n",
    "    cost = cost.detach().cpu().numpy() if isinstance(cost, torch.Tensor) else cost\n",
    "\n",
    "    risk = risk.clip(0.001)\n",
    "    gainF, risk, cost = gainF.flatten(), risk.flatten(), cost.flatten()\n",
    "    d = cp.Variable(risk.shape, nonneg=True)\n",
    "\n",
    "    if gainF.shape != risk.shape or risk.shape != cost.shape:\n",
    "        raise ValueError(\"Dimensions of gainF, risk, and cost do not match\")\n",
    "\n",
    "    utils = cp.multiply(cp.multiply(gainF, risk), d)\n",
    "    constraints = [d >= 0, cp.sum(cost * d) <= Q]\n",
    "\n",
    "    if alpha == 'inf':\n",
    "        t = cp.Variable()\n",
    "        objective = cp.Maximize(t)\n",
    "        constraints.append(utils >= t)\n",
    "    elif alpha == 1:\n",
    "        objective = cp.Maximize(cp.sum(cp.log(utils)))\n",
    "    elif alpha == 0:\n",
    "        objective = cp.Maximize(cp.sum(utils))\n",
    "    else:\n",
    "        objective = cp.Maximize(cp.sum(utils**(1-alpha)) / (1-alpha))\n",
    "\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve(solver=cp.MOSEK, verbose=False, warm_start=True, mosek_params={'MSK_IPAR_LOG': 1})\n",
    "\n",
    "    if problem.status != 'optimal':\n",
    "        print(f\"Warning: Problem status is {problem.status}\")\n",
    "\n",
    "    optimal_decision = d.value\n",
    "    optimal_value = AlphaFairness(optimal_decision * gainF * risk, alpha)\n",
    "\n",
    "    return optimal_decision, optimal_value\n",
    "def solve_closed_form(g, r, c, alpha, Q):\n",
    "    g = g.detach().cpu().numpy() if isinstance(g, torch.Tensor) else g\n",
    "    r = r.detach().cpu().numpy() if isinstance(r, torch.Tensor) else r\n",
    "    c = c.detach().cpu().numpy() if isinstance(c, torch.Tensor) else c\n",
    "\n",
    "    if np.any(c <= 0) or np.any(r <= 0) or np.any(g <= 0):\n",
    "        raise ValueError(\"Inputs must be strictly positive.\")\n",
    "\n",
    "    n = len(c)\n",
    "    utility = np.maximum(r * g, 1e-6)\n",
    "\n",
    "    if alpha == 0:\n",
    "        ratios = utility / c\n",
    "        sorted_indices = np.argsort(-ratios)\n",
    "        d_star_closed = np.zeros(n)\n",
    "        i = sorted_indices[0]\n",
    "        d_star_closed[i] = Q / c[i]\n",
    "\n",
    "    elif alpha == 1:\n",
    "        weight = c / utility\n",
    "        denom = np.sum(weight)\n",
    "        d_star_closed = (Q / denom) * (1 / utility)\n",
    "\n",
    "    elif alpha == 'inf':\n",
    "        denom = np.sum(c * c / utility)\n",
    "        d_star_closed = (Q * c) / (utility * denom)\n",
    "\n",
    "    else:\n",
    "        if alpha <= 0:\n",
    "            raise ValueError(\"Alpha must be positive.\")\n",
    "\n",
    "        numerator = np.power(c, -1/alpha) * np.power(utility, 1/alpha - 1)\n",
    "        d_unscaled = numerator\n",
    "        cost_total = np.sum(c * d_unscaled)\n",
    "        if cost_total == 0:\n",
    "            raise ValueError(\"Degenerate solution: cost_total is zero\")\n",
    "        d_star_closed = (Q / cost_total) * d_unscaled\n",
    "\n",
    "    obj = AlphaFairness(d_star_closed * utility, alpha)\n",
    "    return d_star_closed, obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d872f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4080e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gainF.shape: (200, 1) float64\n",
      "true_r.shape: (200, 1) float64\n",
      "cost.shape: (200, 1) float64\n"
     ]
    }
   ],
   "source": [
    "true_r = true_benefit\n",
    "pred_r = model(X_tensor).detach().cpu().numpy().flatten()\n",
    "pred_r = np.maximum(pred_r, 1e-1)  # Ensure positivity\n",
    "gainF = np.ones_like(true_r)\n",
    "\n",
    "print(\"gainF.shape:\", gainF.shape, gainF.dtype)\n",
    "print(\"true_r.shape:\", true_r.shape, true_r.dtype)\n",
    "print(\"cost.shape:\", cost.shape, cost.dtype)\n",
    "gainF = gainF.reshape(-1)\n",
    "true_r = true_r.reshape(-1)\n",
    "pred_r = pred_r.reshape(-1)\n",
    "cost = cost.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e757513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-489.29710409190614, -489.29710406250916)"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_c, obj_c = solve_closed_form(gainF, true_r, cost, alpha=alpha, Q=Q)\n",
    "\n",
    "\n",
    "sol, obj = solve_optimization(gainF, true_r, cost, alpha=alpha, Q=Q)\n",
    "obj, obj_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e8672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1131.3969020634959, -1131.396136288176)"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted solution in closed form\n",
    "pred_sol_c, _ = solve_closed_form(gainF, pred_r, cost, alpha=alpha, Q=Q)\n",
    "pred_obj_c = AlphaFairness(pred_sol_c * gainF * true_r, alpha)\n",
    "# predicted solution in optimization solver\n",
    "pred_sol, _ = solve_optimization(gainF, pred_r, cost, alpha=alpha, Q=Q)\n",
    "pred_obj = AlphaFairness(pred_sol * gainF * true_r, alpha)\n",
    "\n",
    "\n",
    "pred_obj, pred_obj_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63ab96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Regret: 1.3122902066466209\n"
     ]
    }
   ],
   "source": [
    "normalized_regret = (obj - pred_obj) / (abs(obj) + 1e-7)\n",
    "print(\"Normalized Regret:\", normalized_regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c29dff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
