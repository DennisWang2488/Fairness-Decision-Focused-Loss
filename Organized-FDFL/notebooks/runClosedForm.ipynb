{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0469d29",
   "metadata": {},
   "source": [
    "- Change min-risk from 0.001 to 1\n",
    "\n",
    "- Write fold-opt subsection.\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9450ea9",
   "metadata": {},
   "source": [
    "5. For group, report group-wise performance (MSE and Decision Solution&Objective)\n",
    "     - Closed-Form Done\n",
    "     - <b>2-Stage Done</b>\n",
    "\n",
    "6. <b>For Fold-OPT Change PGD closed-form to solver.</b>\n",
    "\n",
    "8. Verify Individual and Group Regret Performance Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "66fb1b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.myOptimization import (\n",
    "     AlphaFairnesstorch,\n",
    "    solveIndProblem, solve_closed_form, solve_coupled_group_alpha, compute_coupled_group_obj\n",
    ")\n",
    "from src.utils.myPrediction import generate_random_features, customPredictionModel\n",
    "from src.utils.plots import visLearningCurve\n",
    "from src.fairness.cal_fair_penalty import atkinson_loss, mean_abs_dev, compute_group_accuracy_parity\n",
    "\n",
    "from src.utils.myOptimization import AlphaFairness, AlphaFairnesstorch, solve_coupled_group_grad, compute_gradient_closed_form\n",
    "from src.utils.myOptimization import compute_group_gradient_analytical\n",
    "# ------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils.features import get_all_features\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# ------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6818df",
   "metadata": {},
   "source": [
    "## Define Alpha & Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "39fa5508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n"
     ]
    }
   ],
   "source": [
    "# Save to json\n",
    "import json\n",
    "params = {\n",
    "    \"n_sample\": 5000 ,\n",
    "    \"alpha\": 2,\n",
    "    \"Q\": 1000,\n",
    "    \"epochs\": 50,\n",
    "    \"lambdas\": 1.0,\n",
    "    \"lr\": 0.01\n",
    "}\n",
    "\n",
    "# with open(\"E:\\\\User\\\\Stevens\\\\MyRepo\\\\Organized-FDFL\\\\src\\\\models\\\\config_CF.json\", \"w\") as f:\n",
    "#     json.dump(params, f, indent=4)\n",
    "\n",
    "# import json\n",
    "\n",
    "# with open(\"E:\\\\User\\\\Stevens\\\\MyRepo\\\\Organized-FDFL\\\\src\\\\models\\\\config_CF.json\", \"r\") as f:\n",
    "#     params = json.load(f)\n",
    "\n",
    "n_sample = params[\"n_sample\"]\n",
    "alpha    = params[\"alpha\"]\n",
    "Q        = params[\"n_sample\"]//2\n",
    "epochs   = params[\"epochs\"]\n",
    "lambdas  = params[\"lambdas\"]\n",
    "lr       = params[\"lr\"]\n",
    "print(Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/Users/dennis/Downloads/2024-fall/research/Fairness-Decision-Focused-Loss/Organized-FDFL/src/data/data.csv')\n",
    "df = pd.read_csv('E:\\\\myREPO\\\\Fairness-Decision-Focused-Loss\\\\Organized-FDFL\\\\src\\\\data\\\\data.csv')\n",
    "df = df.sample(n=n_sample,random_state=42)\n",
    "\n",
    "# Normalized cost to 0.1-10 range\n",
    "cost = np.array(df['cost_t_capped'].values) * 10\n",
    "cost = np.maximum(cost, 0.1)\n",
    "\n",
    "# All features, standardized\n",
    "features = df[get_all_features(df)].values\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "# True benefit, predictor label normalzied to 1-100 range\n",
    "benefit = np.array(df['benefit'].values) * 100\n",
    "benefit = np.maximum(benefit, 1) \n",
    "# benefit = benefit + 1\n",
    "\n",
    "# Group labels, 0 is White (Majority), 1 is Black\n",
    "race = np.array(df['race'].values)\n",
    "\n",
    "gainF = np.ones_like(benefit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f20f2",
   "metadata": {},
   "source": [
    "## Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "cef7387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairRiskPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cd6cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df314909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d661549",
   "metadata": {},
   "source": [
    "## JVP calculation (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "37802e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def solve_coupled_group_jvp(b, c, group_idx, Q, alpha, beta, v):\n",
    "#     \"\"\"\n",
    "#     Computes the vector-Jacobian product v @ J for the coupled group-alpha problem\n",
    "#     without explicitly forming the full Jacobian matrix J.\n",
    "#     Complexity: O(n) for each element of the output, avoiding O(n^2).\n",
    "#     \"\"\"\n",
    "#     # Ensure inputs are NumPy arrays\n",
    "#     b, c, group_idx, v = map(np.asarray, [b, c, group_idx, v])\n",
    "#     n = len(b)\n",
    "#     final_grad = np.zeros(n)\n",
    "\n",
    "#     # --- 1. Forward Pass: Pre-compute terms from the solver ---\n",
    "#     # This part is identical to the start of the original _grad function\n",
    "#     if beta > 1:\n",
    "#         gamma = beta - 2 + alpha - alpha * beta\n",
    "#         psi_s_exp_factor = (2 - alpha) / gamma\n",
    "#     else: # beta < 1\n",
    "#         gamma = beta + alpha - alpha * beta\n",
    "#         psi_s_exp_factor = -alpha / gamma\n",
    "\n",
    "#     d_star = solve_coupled_group_alpha(b, c, group_idx, Q, alpha, beta)\n",
    "#     unique_groups = np.unique(group_idx)\n",
    "#     S, H, Psi = {}, {}, {}\n",
    "#     for k in unique_groups:\n",
    "#         mask = (group_idx == k)\n",
    "#         G_k, b_k, c_k = np.sum(mask), b[mask], c[mask]\n",
    "#         S[k] = np.sum((c_k**(-(1-beta)/beta)) * (b_k**((1-beta)/beta)))\n",
    "#         H[k] = np.sum((c_k**((beta-1)/beta)) * (b_k**((1-beta)/beta)))\n",
    "#         const_factor = (beta - 1) if beta > 1 else (1 - beta)\n",
    "#         if beta > 1:\n",
    "#             Psi[k] = (S[k]**psi_s_exp_factor) * (const_factor**((alpha-2)/gamma))\n",
    "#         else:\n",
    "#             Psi[k] = (G_k**((alpha-1)/gamma)) * (S[k]**psi_s_exp_factor) * (const_factor**(alpha/gamma))\n",
    "#     Xi = np.sum([H[k] * Psi[k] for k in unique_groups])\n",
    "#     phi_all = (c**(-1/beta)) * (b**((1-beta)/beta))\n",
    "\n",
    "#     # --- 2. Compute the scalar term `Σᵢ vᵢ * dᵢ*` ---\n",
    "#     v_dot_d_star = np.dot(v, d_star)\n",
    "\n",
    "#     # --- 3. Backward Pass: Loop through each prediction `b_j` to get the j-th grad component ---\n",
    "#     for j in range(n):\n",
    "#         m = group_idx[j] # Group of the variable b_j\n",
    "\n",
    "#         # --- Calculate `∂Ξ/∂bⱼ` (same as before) ---\n",
    "#         dS_m_db_j = ((1-beta)/beta) * (c[j]**(-(1-beta)/beta)) * (b[j]**((1-2*beta)/beta))\n",
    "#         dH_m_db_j = ((1-beta)/beta) * (c[j]**((beta-1)/beta)) * (b[j]**((1-2*beta)/beta))\n",
    "#         dPsi_m_db_j = (psi_s_exp_factor / S[m]) * Psi[m] * dS_m_db_j\n",
    "#         dXi_db_j = dH_m_db_j * Psi[m] + H[m] * dPsi_m_db_j\n",
    "\n",
    "#         # --- Calculate the JVP-specific term `Σᵢ vᵢ * (∂Nᵢ/∂bⱼ)` ---\n",
    "#         # ∂Nᵢ/∂bⱼ = Q * ( (∂Ψₖ/∂bⱼ) * φᵢ + Ψₖ * (∂φᵢ/∂bⱼ) )\n",
    "#         # We need to sum vᵢ * (∂Nᵢ/∂bⱼ) over all i\n",
    "#         sum_v_dN_db_j = 0\n",
    "#         dphi_j_db_j = ((1-beta)/beta) * (c[j]**(-1/beta)) * (b[j]**((1-2*beta)/beta))\n",
    "\n",
    "#         # The derivative ∂Ψₖ/∂bⱼ is only non-zero if k == m\n",
    "#         # The derivative ∂φᵢ/∂bⱼ is only non-zero if i == j\n",
    "#         # This makes the sum sparse and efficient to compute\n",
    "#         sum_v_dN_db_j += Q * dPsi_m_db_j * np.dot(v[group_idx == m], phi_all[group_idx == m])\n",
    "#         sum_v_dN_db_j += Q * Psi[m] * v[j] * dphi_j_db_j\n",
    "\n",
    "#         # --- 4. Assemble the final gradient component ---\n",
    "#         final_grad[j] = (1/Xi) * sum_v_dN_db_j - (dXi_db_j / Xi) * v_dot_d_star\n",
    "\n",
    "#     return final_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43773c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33ea0565",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a78a9423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "def to_numpy_1d(x):\n",
    "    \"\"\"Return a 1-D NumPy array; error if the length is not > 1.\"\"\"\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        x = x.detach().cpu().numpy()\n",
    "    x = np.asarray(x).reshape(-1)\n",
    "    assert x.ndim == 1, f\"expected 1-D, got shape {x.shape}\"\n",
    "    return x\n",
    "\n",
    "class optDataset(Dataset):\n",
    "    def __init__(self, feats, risk, gainF, cost, race, alpha=alpha, Q=Q):\n",
    "        # Store as numpy arrays for now\n",
    "        self.feats = feats\n",
    "        self.risk = risk\n",
    "        self.gainF = gainF\n",
    "        self.cost = cost\n",
    "        self.race = race\n",
    "\n",
    "\n",
    "        # Call optmodel (expects numpy arrays)\n",
    "        sol_group = solve_coupled_group_alpha(self.risk, self.cost, self.race, Q=Q, alpha=alpha)\n",
    "        obj_group = compute_coupled_group_obj(sol_group, self.risk, self.race, alpha=alpha)\n",
    "\n",
    "        sol_ind, _ = solve_closed_form(self.gainF, self.risk, self.cost, alpha=alpha, Q=Q)\n",
    "\n",
    "        obj_ind = AlphaFairness(self.risk*sol_ind,alpha=alpha)\n",
    "\n",
    "        # Convert everything to torch tensors for storage\n",
    "        self.feats = torch.from_numpy(self.feats).float()\n",
    "        self.risk = torch.from_numpy(self.risk).float()\n",
    "        self.gainF = torch.from_numpy(self.gainF).float()\n",
    "        self.cost = torch.from_numpy(self.cost).float()\n",
    "        self.race = torch.from_numpy(self.race).float()\n",
    "        self.sol_ind = torch.from_numpy(sol_ind).float()\n",
    "        self.sol_group = torch.from_numpy(sol_group).float()\n",
    "\n",
    "        # to array\n",
    "        obj_group = np.array(obj_group)\n",
    "        self.obj_group = torch.from_numpy(obj_group).float()\n",
    "        self.obj_ind = torch.tensor(obj_ind).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feats)\n",
    "\n",
    "    # def __getitem__(self, idx):\n",
    "    #     return self.feats, self.risk, self.gainF, self.cost, self.race, self.sol, self.obj\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.feats[idx],\n",
    "            self.risk[idx],\n",
    "            self.gainF[idx],\n",
    "            self.cost[idx],\n",
    "            self.race[idx],\n",
    "            self.sol_ind[idx],\n",
    "            self.sol_group[idx],\n",
    "            self.obj_group,\n",
    "            self.obj_ind\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "22d84524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2500\n",
      "Test size: 2500\n",
      "First five feats: tensor([[-1.3127, -0.1998, -0.3537, -0.4862,  1.7943]])\n",
      "risk: tensor([2.])\n",
      "gainF: tensor([1.])\n",
      "cost: tensor([0.1000])\n",
      "race: tensor([0.])\n",
      "sol_ind: tensor([7.5626])\n",
      "sol_group: tensor([7.5626])\n",
      "obj_group: tensor([-218.5607])\n",
      "obj_ind: tensor([-218.5607])\n"
     ]
    }
   ],
   "source": [
    "optmodel_group = solve_coupled_group_alpha\n",
    "optmodel_ind = solve_closed_form\n",
    "\n",
    "# Perform train-test split\n",
    "feats_train, feats_test, gainF_train, gainF_test, b_train, b_test, cost_train, cost_test, race_train, race_test = train_test_split(\n",
    "    features, gainF, benefit, cost, df['race'].values, test_size=0.5, random_state=2\n",
    ")\n",
    "\n",
    "print(f\"Train size: {feats_train.shape[0]}\")\n",
    "print(f\"Test size: {feats_test.shape[0]}\")\n",
    "\n",
    "dataset_train = optDataset(feats_train, b_train, gainF_train, cost_train, race_train, alpha=alpha, Q=Q)\n",
    "dataset_test = optDataset(feats_test, b_test, gainF_test, cost_test, race_test, alpha=alpha, Q=Q)\n",
    "\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=len(dataset_train), shuffle=False)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=len(dataset_train), shuffle=False)\n",
    "\n",
    "predmodel = FairRiskPredictor(feats_train.shape[1])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "predmodel.to(device)\n",
    "\n",
    "\n",
    "# Get a batch from the dataloader\n",
    "for batch in dataloader_train:\n",
    "    names = [\n",
    "        \"feats\", \"risk\", \"gainF\", \"cost\", \"race\",\n",
    "        \"sol_ind\", \"sol_group\", \"obj_group\", \"obj_ind\"\n",
    "    ]\n",
    "    for name, item in zip(names, batch):\n",
    "        # Only show first five elements for feats\n",
    "        if name == \"feats\":\n",
    "            print(f\"First five {name}: {item[:1, :5]}\")\n",
    "        else:\n",
    "            print(f\"{name}: {item[:1]}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73847c1c",
   "metadata": {},
   "source": [
    "## Regret Loss nn.Module Gemini Version\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "2886a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_loss_and_decision(pred_r, true_r, gainF, cost, race, Q, alpha, lambdas, fairness_type, group, **kwargs):\n",
    "    \"\"\"\n",
    "    Helper function to compute loss. Detaches inputs to prevent this logic from being part of the graph,\n",
    "    as its gradient is handled manually in the backward pass.\n",
    "    \"\"\"\n",
    "    # Use detached tensors for calculation\n",
    "    pred_r_d, true_r_d, gainF_d, cost_d, race_d = map(\n",
    "        lambda t: t.detach(), [pred_r, true_r, gainF, cost, race]\n",
    "    )\n",
    "    pred_r_np, true_r_np, gainF_np, cost_np, race_np = map(to_numpy_1d, [pred_r_d, true_r_d, gainF_d, cost_d, race_d])\n",
    "\n",
    "    try:\n",
    "        if group:\n",
    "            d_hat_np = solve_coupled_group_alpha(pred_r_np, cost_np, race_np, Q, alpha)\n",
    "            d_star_np = solve_coupled_group_alpha(true_r_np, cost_np, race_np, Q, alpha)\n",
    "            obj_val_at_d_hat = compute_coupled_group_obj(d_hat_np, true_r_np, race_np, alpha)\n",
    "            obj_val_at_d_star = compute_coupled_group_obj(d_star_np, true_r_np, race_np, alpha)\n",
    "        else:\n",
    "            d_hat_np, _ = solve_closed_form(gainF_np, pred_r_np, cost_np, alpha, Q)\n",
    "            d_star_np, _ = solve_closed_form(gainF_np, true_r_np, cost_np, alpha, Q)\n",
    "            obj_val_at_d_hat = AlphaFairness(true_r_np * d_hat_np, alpha)\n",
    "            obj_val_at_d_star = AlphaFairness(true_r_np * d_star_np, alpha)\n",
    "\n",
    "        # Ensure regret is not negative due to solver noise\n",
    "        regret_loss = torch.tensor(max(0, obj_val_at_d_star - obj_val_at_d_hat), dtype=pred_r.dtype, device=pred_r.device)\n",
    "\n",
    "    except (ValueError, cp.error.SolverError, np.linalg.LinAlgError) as e: # type: ignore[catch]\n",
    "        print(f\"Warning: Solver failed: {e}\")\n",
    "        return torch.tensor(0.0), torch.tensor(0.0), None\n",
    "\n",
    "    # Use the original tensors (with graph) for fairness calculation for autograd\n",
    "    fairness_penalty = torch.tensor(0.0, device=pred_r.device)\n",
    "    if fairness_type != 'none':\n",
    "        mode = 'between' if group else 'individual'\n",
    "        if fairness_type == 'atkinson': fairness_penalty = atkinson_loss(pred_r, true_r, race=race, beta=0.5, mode=mode)\n",
    "        elif fairness_type == 'mad': fairness_penalty = mean_abs_dev(pred_r, true_r, race=race, mode=mode)\n",
    "        elif fairness_type == 'acc_parity' and group: fairness_penalty = compute_group_accuracy_parity(pred_r, true_r, race)\n",
    "\n",
    "    total_loss = regret_loss + lambdas * fairness_penalty\n",
    "    return total_loss, fairness_penalty, d_hat_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "2ee06d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from torch.autograd import Function\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# (Assuming all previous helper functions like to_numpy_1d, solvers, etc. are defined)\n",
    "\n",
    "def _calculate_regret_and_d_hat(pred_r_np, true_r_np, gainF_np, cost_np, race_np, Q, alpha, group):\n",
    "    \"\"\"Helper to compute regret and the decision variable d_hat.\"\"\"\n",
    "    try:\n",
    "        if group:\n",
    "            d_hat_np = solve_coupled_group_alpha(pred_r_np, cost_np, race_np, Q, alpha)\n",
    "            d_star_np = solve_coupled_group_alpha(true_r_np, cost_np, race_np, Q, alpha)\n",
    "            obj_val_at_d_hat = compute_coupled_group_obj(d_hat_np, true_r_np, race_np, alpha)\n",
    "            obj_val_at_d_star = compute_coupled_group_obj(d_star_np, true_r_np, race_np, alpha)\n",
    "        else:\n",
    "            d_hat_np, _ = solve_closed_form(gainF_np, pred_r_np, cost_np, alpha, Q)\n",
    "            d_star_np, _ = solve_closed_form(gainF_np, true_r_np, cost_np, alpha, Q)\n",
    "            obj_val_at_d_hat = AlphaFairness(true_r_np * d_hat_np, alpha)\n",
    "            obj_val_at_d_star = AlphaFairness(true_r_np * d_star_np, alpha)\n",
    "\n",
    "        regret = obj_val_at_d_star - obj_val_at_d_hat\n",
    "        # regret = np.log1p(np.exp(regret * 10)) / 10\n",
    "        return regret, d_hat_np\n",
    "\n",
    "    except (ValueError, cp.error.SolverError, np.linalg.LinAlgError) as e: # type: ignore[catch]\n",
    "        print(f\"Warning: Solver failed: {e}\")\n",
    "        # Return a zero regret and a placeholder for d_hat\n",
    "        return 0.0, np.zeros_like(pred_r_np)\n",
    "\n",
    "class RegretLossFn(Function):\n",
    "    \"\"\"\n",
    "    Custom autograd Function for regret with a closed-form or finite-difference gradient.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, pred_r, true_r, gainF, cost, race, Q, alpha, group, grad_method):\n",
    "        # --- Loss Calculation (Regret) ---\n",
    "        pred_r_np, true_r_np, gainF_np, cost_np, race_np = map(\n",
    "            lambda t: to_numpy_1d(t.detach()), [pred_r, true_r, gainF, cost, race]\n",
    "        )\n",
    "\n",
    "        regret, d_hat_np = _calculate_regret_and_d_hat(pred_r_np, true_r_np, gainF_np, cost_np, race_np, Q, alpha, group)\n",
    "        regret_loss = torch.tensor(regret, dtype=pred_r.dtype, device=pred_r.device)\n",
    "        # regret_loss = F.softplus(torch.tensor(regret, dtype=pred_r.dtype,device=pred_r.device), beta=10)\n",
    "        d_hat = torch.from_numpy(d_hat_np).to(pred_r.device, dtype=pred_r.dtype)\n",
    "\n",
    "        # --- Save for Backward ---\n",
    "        ctx.save_for_backward(pred_r, true_r, gainF, cost, race, d_hat)\n",
    "        ctx.params = {'Q': Q, 'alpha': alpha, 'group': group, 'grad_method': grad_method}\n",
    "        return regret_loss\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output): # type: ignore[override]\n",
    "        pred_r, true_r, gainF, cost, race, d_hat = ctx.saved_tensors\n",
    "        params = ctx.params\n",
    "        grad_regret = torch.zeros_like(pred_r)\n",
    "\n",
    "        if d_hat is None:\n",
    "            return (torch.zeros_like(pred_r),) + (None,) * 8\n",
    "\n",
    "        try:\n",
    "            if params['grad_method'] == 'closed-form':\n",
    "                # (Closed-form gradient calculation remains the same)\n",
    "                if params['group']:\n",
    "                    pred_r_np, cost_np, race_np = map(to_numpy_1d, [pred_r, cost, race])\n",
    "                    grad_obj_wrt_d_hat = compute_group_gradient_analytical(d_hat, true_r, race, params['alpha'])\n",
    "                    v_np = to_numpy_1d(grad_obj_wrt_d_hat)\n",
    "                    Jac_mat = solve_coupled_group_grad(pred_r_np, cost_np, race_np, params['Q'], params['alpha'])\n",
    "                    vT_J_np = v_np @ Jac_mat\n",
    "                    grad_regret = -torch.from_numpy(vT_J_np).to(pred_r.device,dtype=pred_r.dtype)\n",
    "\n",
    "                else:\n",
    "                    pred_r_np, cost_np, gainF_np = map(to_numpy_1d, [pred_r, cost, gainF])\n",
    "                    jac = compute_gradient_closed_form(gainF_np, pred_r_np, cost_np, params['alpha'], params['Q'])\n",
    "                    grad_obj_wrt_d_hat = (true_r * gainF) ** (1 - params['alpha']) * d_hat ** (-params['alpha']) # Grad of alpha-fairness obj\n",
    "                    jac_tensor = torch.from_numpy(jac).to(pred_r.device, dtype=pred_r.dtype)\n",
    "                    grad_obj_tensor = grad_obj_wrt_d_hat.to(dtype=pred_r.dtype, device=pred_r.device)\n",
    "                    grad_regret = -grad_obj_tensor @ jac_tensor\n",
    "            \n",
    "            elif params['grad_method'] == 'finite-diff':\n",
    "\n",
    "                pred_r_np = to_numpy_1d(pred_r)\n",
    "                grad_regret_np = np.zeros_like(pred_r_np)\n",
    "\n",
    "                eps = 1e-3                                    # relative 0.1 %\n",
    "                eps_vec = eps * np.maximum(1.0, np.abs(pred_r_np))\n",
    "\n",
    "                # Detach and convert tensors needed for perturbations once\n",
    "                true_r_np, gainF_np, cost_np, race_np = map(\n",
    "                    lambda t: to_numpy_1d(t.detach()), [true_r, gainF, cost, race]\n",
    "                )\n",
    "\n",
    "                for i in range(len(pred_r_np)):\n",
    "                    # Perturb pred_r for forward and backward steps\n",
    "                    pred_r_plus = pred_r_np.copy(); pred_r_plus[i]  += eps_vec[i]\n",
    "                    pred_r_minus = pred_r_np.copy(); pred_r_minus[i] -= eps_vec[i]\n",
    "\n",
    "                    regret_plus, _ = _calculate_regret_and_d_hat(pred_r_plus, true_r_np, gainF_np, cost_np, race_np, params['Q'], params['alpha'], params['group'])\n",
    "                    regret_minus, _ = _calculate_regret_and_d_hat(pred_r_minus, true_r_np, gainF_np, cost_np, race_np, params['Q'], params['alpha'], params['group'])\n",
    "\n",
    "                    grad_regret_np[i] = (regret_plus - regret_minus) / (2 * eps_vec[i])\n",
    "\n",
    "                # The gradient of the loss is the negative of the gradient of the regret\n",
    "                grad_regret = torch.from_numpy(grad_regret_np).to(pred_r.device, dtype=pred_r.dtype)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Gradient calculation failed: {e}. Returning zero grad.\")\n",
    "\n",
    "        return (grad_output * grad_regret, None, None, None, None, None, None, None, None)\n",
    "\n",
    "\n",
    "class FDFLLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Decision-Focused + Fairness Loss Module.\n",
    "    \"\"\"\n",
    "    def __init__(self, Q, alpha, lambdas, fairness_type, group, grad_method='closed-form'):\n",
    "        super().__init__()\n",
    "        self.Q, self.alpha, self.lambdas = Q, alpha, lambdas\n",
    "        self.fairness_type, self.group, self.grad_method = fairness_type, group, grad_method\n",
    "\n",
    "    def forward(self, pred_r, true_r, gainF, cost, race):\n",
    "        # 1. Regret loss from the custom function\n",
    "        regret_loss = RegretLossFn.apply(pred_r, true_r, gainF, cost, race, self.Q, self.alpha, self.group, self.grad_method)\n",
    "\n",
    "        # 2. Fairness penalty using standard PyTorch autograd\n",
    "        fairness_penalty = torch.tensor(0.0, device=pred_r.device)\n",
    "        if self.lambdas > 0 and self.fairness_type != 'none':\n",
    "            mode = 'between' if self.group else 'individual'\n",
    "            if self.fairness_type == 'atkinson':\n",
    "                fairness_penalty = atkinson_loss(pred_r, true_r, race=race, beta=0.5, mode=mode)\n",
    "            elif self.fairness_type == 'mad':\n",
    "                fairness_penalty = mean_abs_dev(pred_r, true_r, race=race, mode=mode)\n",
    "            elif self.fairness_type == 'acc_parity' and self.group:\n",
    "                fairness_penalty = compute_group_accuracy_parity(pred_r, true_r, race)\n",
    "        \n",
    "        # 3. Total loss\n",
    "        total_loss = regret_loss + self.lambdas * fairness_penalty\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a09dba",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b0ebf186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Assume helper functions (FDFLLoss, _calculate_loss_and_decision, etc.) are defined elsewhere\n",
    "\n",
    "def train_model_regret(\n",
    "        X_train, y_train, race_train, cost_train, gainF_train,\n",
    "        X_test,  y_test,  race_test,  cost_test, gainF_test,\n",
    "        model_class, input_dim,\n",
    "        alpha, Q,\n",
    "        lambda_fair=0.0, fairness_type=\"none\", group=True, grad_method='closed-form',\n",
    "        num_epochs=30, lr=1e-2, batch_size=None,\n",
    "        dropout_rate=0.1, weight_decay=1e-4,\n",
    "        device=torch.device(\"cpu\")):\n",
    "    \"\"\"\n",
    "    Train a predictor via direct regret minimization, logging detailed metrics\n",
    "    at each evaluation point.\n",
    "    \"\"\"\n",
    "    # --- Setup (Tensors, Dataloader, Model, etc.) ---\n",
    "    tensors = [X_train, y_train, race_train, cost_train, gainF_train, X_test, y_test, race_test, cost_test, gainF_test]\n",
    "    X_train, y_train, race_train, cost_train, gainF_train, X_test, y_test, race_test, cost_test, gainF_test = [\n",
    "        torch.tensor(t, dtype=torch.float32, device=device) if not isinstance(t, torch.Tensor) else t.to(device) for t in tensors\n",
    "    ]\n",
    "    train_ds = TensorDataset(X_train, y_train, race_train, cost_train, gainF_train)\n",
    "    if batch_size is None: batch_size = len(train_ds)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    model = model_class(input_dim, dropout_rate=dropout_rate).to(device)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    crit = FDFLLoss(Q, alpha, lambda_fair, fairness_type, group, grad_method)\n",
    "\n",
    "    # --- Initialize Logs ---\n",
    "    loss_log, mse_log, regret_log, fairness_log = [], [], [], []\n",
    "    unique_groups = torch.unique(race_test).cpu().numpy()\n",
    "    per_group_mse_log = {g: [] for g in unique_groups}\n",
    "    per_group_obj_log = {g: [] for g in unique_groups}\n",
    "    per_group_pred_benefit_log = {g: [] for g in unique_groups}\n",
    "    per_group_pred_sol_log = {g: [] for g in unique_groups}\n",
    "    per_group_true_sol_log = {g: [] for g in unique_groups}\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # --- Training Loop ---\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for x_b, y_b, r_b, c_b, g_b in train_loader:\n",
    "            pred_b = model(x_b).squeeze().clamp(min=1)\n",
    "            loss = crit(pred_b, y_b, g_b, c_b, r_b)\n",
    "            optim.zero_grad()\n",
    "            if loss.requires_grad:\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "            epoch_loss += loss.item() * x_b.size(0)\n",
    "        loss_log.append(epoch_loss / len(train_ds))\n",
    "\n",
    "        # --- Periodic Evaluation on Test Set ---\n",
    "        if epoch == 1 or epoch % 10 == 0 or epoch == num_epochs:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred_test = model(X_test).squeeze().clamp(min=1)\n",
    "                # Overall MSE\n",
    "                mse_val = ((pred_test - y_test).pow(2)).mean().item()\n",
    "                mse_log.append(mse_val)\n",
    "\n",
    "                # Overall Regret\n",
    "                _, _, d_pred_np = _calculate_loss_and_decision(pred_test, y_test, gainF_test, cost_test, race_test, Q, alpha, 0, 'none', group)\n",
    "                _, _, d_true_np = _calculate_loss_and_decision(y_test, y_test, gainF_test, cost_test, race_test, Q, alpha, 0, 'none', group)\n",
    "                if d_pred_np is not None and d_true_np is not None:\n",
    "                    y_test_np = to_numpy_1d(y_test)\n",
    "                    race_test_np = to_numpy_1d(race_test)\n",
    "                    if group:\n",
    "                        true_obj = compute_coupled_group_obj(d_true_np, y_test_np, race_test_np, alpha)\n",
    "                        pred_obj = compute_coupled_group_obj(d_pred_np, y_test_np, race_test_np, alpha)\n",
    "                    else:\n",
    "                        true_obj = AlphaFairness(y_test_np * d_true_np, alpha)\n",
    "                        pred_obj = AlphaFairness(y_test_np * d_pred_np, alpha)\n",
    "                    norm_regret = (true_obj - pred_obj) / (abs(true_obj) + 1e-7)\n",
    "                else:\n",
    "                    norm_regret = np.nan\n",
    "                regret_log.append(norm_regret)\n",
    "\n",
    "                # Overall Fairness\n",
    "                fair_val = 0.0\n",
    "                mode = 'between' if group else 'individual'\n",
    "                if fairness_type == \"acc_parity\" and group: fair_val = compute_group_accuracy_parity(pred_test, y_test, race_test).item()\n",
    "                elif fairness_type == \"atkinson\": fair_val = atkinson_loss(pred_test, y_test, race_test, beta=0.5, mode=mode).item()\n",
    "                elif fairness_type == \"mad\": fair_val = mean_abs_dev(pred_test, y_test, race_test, mode=mode).item()\n",
    "                fairness_log.append(fair_val)\n",
    "\n",
    "                # Group-wise Metrics\n",
    "                for g in unique_groups:\n",
    "                    mask = (race_test == g)\n",
    "                    if mask.sum() == 0: continue\n",
    "                    # Group MSE\n",
    "                    per_group_mse_log[g].append(((pred_test[mask] - y_test[mask]).pow(2)).mean().item())\n",
    "                    # Group pred Benefit\n",
    "                    per_group_pred_benefit_log[g].append(pred_test[mask].mean().item())\n",
    "\n",
    "\n",
    "                    # Group Decision Objective\n",
    "                    if d_pred_np is not None:\n",
    "                        group_mask_np = (race_test_np == g) # type: ignore\n",
    "                        # We use the true benefits (y_test) to evaluate the utility of the decisions (d_pred_np)\n",
    "                        group_utility = y_test_np[group_mask_np] * d_pred_np[group_mask_np] # type: ignore\n",
    "                        # For simplicity, we report the mean utility as the objective\n",
    "                        per_group_obj_log[g].append(group_utility.mean())\n",
    "                    else:\n",
    "                        per_group_obj_log[g].append(np.nan)\n",
    "\n",
    "                    # # Group Decision Variables\n",
    "                    # if d_pred_np is not None:\n",
    "                    #     per_group_pred_sol_log[g].append(d_pred_np[mask].mean().item())\n",
    "                    # else:\n",
    "                    #     per_group_pred_sol_log[g].append(np.nan)\n",
    "                    \n",
    "                    # # True Decision Variables\n",
    "                    # if d_true_np is not None:\n",
    "                    #     per_group_true_sol_log[g].append(d_true_np[mask].mean().item().cpu())\n",
    "                    # else:\n",
    "                    #     per_group_true_sol_log[g].append(np.nan)\n",
    "                    \n",
    "\n",
    "                print(f\"Epoch {epoch:03d}/{num_epochs} | Train-Loss {loss_log[-1]:.4f} | Test-MSE {mse_log[-1]:.4f} | Regret {regret_log[-1]:.4f} | Fair-Val {fairness_log[-1]:.4f}\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Training finished in {total_time:.2f}s.\")\n",
    "\n",
    "    # Return a dictionary of all logs\n",
    "    return model, {\n",
    "        \"loss_log\": loss_log, \"mse_log\": mse_log, \"regret_log\": regret_log, \"fairness_log\": fairness_log,\n",
    "        \"training_time\": total_time,\n",
    "        \"per_group_mse\": per_group_mse_log,\n",
    "        \"per_group_decision_objective\": per_group_obj_log,\n",
    "        \"per_group_true_benefit\": per_group_pred_benefit_log\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f8386a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "23a66413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # alpha = 2\n",
    "# hyperparams = {\n",
    "#     \"alpha\":alpha,\n",
    "#     \"Q\": 1000,\n",
    "#     \"lambda_fair\": 0,\n",
    "#     \"fairness_type\": \"atkinson\",   \n",
    "#     \"group\": True,            # Set to True for group fairness, False for individual\n",
    "#     \"grad_method\": \"finite-diff\",\n",
    "#     \"num_epochs\": 20,        \n",
    "#     \"lr\": 0.005,\n",
    "#     \"batch_size\": len(b_train),\n",
    "#     \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# }\n",
    "\n",
    "# final_model, logs = train_model_regret(\n",
    "#     X_train=feats_train, y_train=b_train, race_train=race_train, cost_train=cost_train, gainF_train=gainF_train,\n",
    "#     X_test=feats_test, y_test=b_test, race_test=race_test, cost_test=cost_test, gainF_test=gainF_test,\n",
    "#     model_class=FairRiskPredictor,\n",
    "#     input_dim=feats_train.shape[1],\n",
    "#     **hyperparams\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ab4122e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 1.  MULTI-TRIAL REGRET TRAINING WITH FULL LOGGING\n",
    "# ---------------------------------------------------------------------\n",
    "def train_many_trials_regret(n_trials=3, base_seed=2025, **train_args):\n",
    "    \"\"\"\n",
    "    Run `train_model_regret` for `n_trials` different seeds.\n",
    "    Returns a FLAT dict whose keys are:\n",
    "        regret, regret_std, mse, mse_std, fairness, fairness_std, …,\n",
    "        G0_mse, G0_mse_std, G0_decision_obj, G0_decision_obj_std, …\n",
    "    \"\"\"\n",
    "    # -------------------- run all trials -----------------------------\n",
    "    per_trial_metrics = defaultdict(list)      # collects trial-level scalars\n",
    "\n",
    "    final_model = None\n",
    "    for t in range(n_trials):\n",
    "        seed = base_seed + t\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        final_model, logs = train_model_regret(**train_args)   # one full run\n",
    "\n",
    "        # ---- overall scalars ---------------------------------------\n",
    "        per_trial_metrics['regret'       ].append(logs['regret_log']  [-1])\n",
    "        per_trial_metrics['mse'          ].append(logs['mse_log']     [-1])\n",
    "        per_trial_metrics['fairness'     ].append(logs['fairness_log'][-1])\n",
    "        per_trial_metrics['training_time'].append(logs['training_time'])\n",
    "\n",
    "        # ---- per-group metrics (final epoch) -----------------------\n",
    "        for g_id, g_log in logs['per_group_mse'].items():\n",
    "            if g_log:                      # just in case\n",
    "                per_trial_metrics[f'G{int(g_id)}_mse'          ].append(g_log[-1])\n",
    "        for g_id, g_log in logs['per_group_decision_objective'].items():\n",
    "            if g_log:\n",
    "                per_trial_metrics[f'G{int(g_id)}_decision_obj' ].append(g_log[-1])\n",
    "\n",
    "\n",
    "    # -------------------- aggregate over trials ----------------------\n",
    "    avg_results = {}\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"      AVERAGED RESULTS ACROSS ALL TRIALS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    for key, values in per_trial_metrics.items():\n",
    "        μ, sigma = np.mean(values), np.std(values)\n",
    "        avg_results[key]      = μ\n",
    "        avg_results[f'{key}_std'] = sigma\n",
    "        print(f\"[{key.upper():>20s}]  μ = {μ:.4f} | σ = {sigma:.4f}\")\n",
    "\n",
    "    return avg_results, final_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d239f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c175a7d",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "68991548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 0.5, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 29.5233 | Test-MSE 362.5882 | Regret 0.0654 | Fair-Val 85.7126\n",
      "Epoch 010/50 | Train-Loss 28.0600 | Test-MSE 359.5536 | Regret 0.0629 | Fair-Val 84.0788\n",
      "Epoch 020/50 | Train-Loss 24.5694 | Test-MSE 349.9480 | Regret 0.0559 | Fair-Val 79.6147\n",
      "Epoch 030/50 | Train-Loss 22.4776 | Test-MSE 338.2161 | Regret 0.0529 | Fair-Val 74.0088\n",
      "Epoch 040/50 | Train-Loss 21.4223 | Test-MSE 330.0174 | Regret 0.0515 | Fair-Val 68.6312\n",
      "Epoch 050/50 | Train-Loss 20.2540 | Test-MSE 325.5493 | Regret 0.0493 | Fair-Val 64.6542\n",
      "Training finished in 267.64s.\n",
      "Epoch 001/50 | Train-Loss 29.5398 | Test-MSE 362.6682 | Regret 0.0654 | Fair-Val 85.7927\n",
      "Epoch 010/50 | Train-Loss 28.2099 | Test-MSE 360.7528 | Regret 0.0632 | Fair-Val 83.7940\n",
      "Epoch 020/50 | Train-Loss 24.9695 | Test-MSE 352.4016 | Regret 0.0568 | Fair-Val 78.6377\n",
      "Epoch 030/50 | Train-Loss 22.7432 | Test-MSE 341.1671 | Regret 0.0533 | Fair-Val 72.6761\n",
      "Epoch 040/50 | Train-Loss 21.2087 | Test-MSE 332.7242 | Regret 0.0513 | Fair-Val 67.6399\n",
      "Epoch 050/50 | Train-Loss 20.0087 | Test-MSE 327.6390 | Regret 0.0486 | Fair-Val 63.7942\n",
      "Training finished in 445.98s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0490 | σ = 0.0003\n",
      "[                 MSE]  μ = 326.5941 | σ = 1.0449\n",
      "[            FAIRNESS]  μ = 64.2242 | σ = 0.4300\n",
      "[       TRAINING_TIME]  μ = 356.8104 | σ = 89.1687\n",
      "[              G0_MSE]  μ = 311.2831 | σ = 1.1474\n",
      "[              G1_MSE]  μ = 439.7315 | σ = 0.2874\n",
      "[     G0_DECISION_OBJ]  μ = 30.1280 | σ = 0.1536\n",
      "[     G1_DECISION_OBJ]  μ = 216.1720 | σ = 4.1176\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 0.8, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 0.0804 | Test-MSE 362.6652 | Regret 0.0013 | Fair-Val 85.7816\n",
      "Epoch 010/50 | Train-Loss 0.0806 | Test-MSE 362.6914 | Regret 0.0013 | Fair-Val 85.8060\n",
      "Epoch 020/50 | Train-Loss 0.0805 | Test-MSE 362.7132 | Regret 0.0013 | Fair-Val 85.8104\n",
      "Epoch 030/50 | Train-Loss 0.0806 | Test-MSE 362.7295 | Regret 0.0013 | Fair-Val 85.8202\n",
      "Epoch 040/50 | Train-Loss 0.0806 | Test-MSE 362.7379 | Regret 0.0013 | Fair-Val 85.8313\n",
      "Epoch 050/50 | Train-Loss 0.0807 | Test-MSE 362.7411 | Regret 0.0013 | Fair-Val 85.8445\n",
      "Training finished in 464.27s.\n",
      "Epoch 001/50 | Train-Loss 0.0805 | Test-MSE 362.6976 | Regret 0.0013 | Fair-Val 85.8439\n",
      "Epoch 010/50 | Train-Loss 0.0803 | Test-MSE 362.7106 | Regret 0.0013 | Fair-Val 85.8435\n",
      "Epoch 020/50 | Train-Loss 0.0802 | Test-MSE 362.7162 | Regret 0.0013 | Fair-Val 85.8457\n",
      "Epoch 030/50 | Train-Loss 0.0803 | Test-MSE 362.7271 | Regret 0.0013 | Fair-Val 85.8447\n",
      "Epoch 040/50 | Train-Loss 0.0804 | Test-MSE 362.7357 | Regret 0.0013 | Fair-Val 85.8449\n",
      "Epoch 050/50 | Train-Loss 0.0805 | Test-MSE 362.7398 | Regret 0.0013 | Fair-Val 85.8452\n",
      "Training finished in 362.32s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0013 | σ = 0.0000\n",
      "[                 MSE]  μ = 362.7404 | σ = 0.0006\n",
      "[            FAIRNESS]  μ = 85.8448 | σ = 0.0004\n",
      "[       TRAINING_TIME]  μ = 413.2925 | σ = 50.9744\n",
      "[              G0_MSE]  μ = 342.2750 | σ = 0.0007\n",
      "[              G1_MSE]  μ = 513.9647 | σ = 0.0000\n",
      "[     G0_DECISION_OBJ]  μ = 18.7367 | σ = 0.0001\n",
      "[     G1_DECISION_OBJ]  μ = 155.4197 | σ = 0.0002\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 1.5, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 2.6700 | Test-MSE 362.5711 | Regret 0.0277 | Fair-Val 85.7275\n",
      "Epoch 010/50 | Train-Loss 2.3361 | Test-MSE 356.0368 | Regret 0.0244 | Fair-Val 83.2741\n",
      "Epoch 020/50 | Train-Loss 1.9996 | Test-MSE 341.6579 | Regret 0.0213 | Fair-Val 77.9836\n",
      "Epoch 030/50 | Train-Loss 1.8232 | Test-MSE 328.7763 | Regret 0.0197 | Fair-Val 72.8149\n",
      "Epoch 040/50 | Train-Loss 1.6750 | Test-MSE 320.3246 | Regret 0.0184 | Fair-Val 69.1289\n",
      "Epoch 050/50 | Train-Loss 1.5218 | Test-MSE 314.2570 | Regret 0.0170 | Fair-Val 67.0112\n",
      "Training finished in 352.64s.\n",
      "Epoch 001/50 | Train-Loss 2.6796 | Test-MSE 362.6305 | Regret 0.0277 | Fair-Val 85.7628\n",
      "Epoch 010/50 | Train-Loss 2.3915 | Test-MSE 356.9067 | Regret 0.0248 | Fair-Val 82.3280\n",
      "Epoch 020/50 | Train-Loss 2.0206 | Test-MSE 342.3160 | Regret 0.0216 | Fair-Val 76.4700\n",
      "Epoch 030/50 | Train-Loss 1.8436 | Test-MSE 328.2391 | Regret 0.0200 | Fair-Val 71.3114\n",
      "Epoch 040/50 | Train-Loss 1.6985 | Test-MSE 319.4410 | Regret 0.0188 | Fair-Val 67.9619\n",
      "Epoch 050/50 | Train-Loss 1.5419 | Test-MSE 313.8950 | Regret 0.0173 | Fair-Val 66.1429\n",
      "Training finished in 342.59s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0171 | σ = 0.0002\n",
      "[                 MSE]  μ = 314.0760 | σ = 0.1810\n",
      "[            FAIRNESS]  μ = 66.5771 | σ = 0.4341\n",
      "[       TRAINING_TIME]  μ = 347.6172 | σ = 5.0244\n",
      "[              G0_MSE]  μ = 298.2040 | σ = 0.0776\n",
      "[              G1_MSE]  μ = 431.3581 | σ = 0.9458\n",
      "[     G0_DECISION_OBJ]  μ = 18.6739 | σ = 0.0086\n",
      "[     G1_DECISION_OBJ]  μ = 60.4789 | σ = 0.1573\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 2, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 77.0923 | Test-MSE 362.5725 | Regret 0.3399 | Fair-Val 85.7344\n",
      "Epoch 010/50 | Train-Loss 66.8899 | Test-MSE 355.8989 | Regret 0.2944 | Fair-Val 83.3396\n",
      "Epoch 020/50 | Train-Loss 56.4135 | Test-MSE 341.2964 | Regret 0.2517 | Fair-Val 78.1670\n",
      "Epoch 030/50 | Train-Loss 50.4986 | Test-MSE 328.4142 | Regret 0.2307 | Fair-Val 72.9110\n",
      "Epoch 040/50 | Train-Loss 45.6707 | Test-MSE 319.5847 | Regret 0.2160 | Fair-Val 68.9799\n",
      "Epoch 050/50 | Train-Loss 41.1907 | Test-MSE 312.7964 | Regret 0.2000 | Fair-Val 66.6828\n",
      "Training finished in 402.52s.\n",
      "Epoch 001/50 | Train-Loss 77.3852 | Test-MSE 362.6297 | Regret 0.3406 | Fair-Val 85.7649\n",
      "Epoch 010/50 | Train-Loss 68.6658 | Test-MSE 356.7938 | Regret 0.3013 | Fair-Val 82.4005\n",
      "Epoch 020/50 | Train-Loss 57.1655 | Test-MSE 342.0331 | Regret 0.2571 | Fair-Val 76.6522\n",
      "Epoch 030/50 | Train-Loss 51.2218 | Test-MSE 327.9701 | Regret 0.2354 | Fair-Val 71.5093\n",
      "Epoch 040/50 | Train-Loss 46.5796 | Test-MSE 318.9726 | Regret 0.2199 | Fair-Val 67.9160\n",
      "Epoch 050/50 | Train-Loss 41.7972 | Test-MSE 312.8373 | Regret 0.2039 | Fair-Val 65.7456\n",
      "Training finished in 268.11s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.2020 | σ = 0.0019\n",
      "[                 MSE]  μ = 312.8168 | σ = 0.0204\n",
      "[            FAIRNESS]  μ = 66.2142 | σ = 0.4686\n",
      "[       TRAINING_TIME]  μ = 335.3185 | σ = 67.2040\n",
      "[              G0_MSE]  μ = 297.0313 | σ = 0.1321\n",
      "[              G1_MSE]  μ = 429.4598 | σ = 0.8050\n",
      "[     G0_DECISION_OBJ]  μ = 19.3481 | σ = 0.0170\n",
      "[     G1_DECISION_OBJ]  μ = 25.8111 | σ = 0.0934\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 0.5, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 130.2154 | Test-MSE 362.6483 | Regret 0.0654 | Fair-Val 85.7719\n",
      "Epoch 010/50 | Train-Loss 125.1227 | Test-MSE 360.9868 | Regret 0.0643 | Fair-Val 84.5118\n",
      "Epoch 020/50 | Train-Loss 112.3825 | Test-MSE 353.3299 | Regret 0.0585 | Fair-Val 79.4169\n",
      "Epoch 030/50 | Train-Loss 97.0297 | Test-MSE 341.2158 | Regret 0.0561 | Fair-Val 71.6073\n",
      "Epoch 040/50 | Train-Loss 79.6001 | Test-MSE 325.7060 | Regret 0.0583 | Fair-Val 61.9023\n",
      "Epoch 050/50 | Train-Loss 62.5274 | Test-MSE 308.4339 | Regret 0.0639 | Fair-Val 52.0551\n",
      "Training finished in 346.73s.\n",
      "Epoch 001/50 | Train-Loss 130.2901 | Test-MSE 362.6556 | Regret 0.0654 | Fair-Val 85.7719\n",
      "Epoch 010/50 | Train-Loss 123.4417 | Test-MSE 360.3678 | Regret 0.0631 | Fair-Val 83.1680\n",
      "Epoch 020/50 | Train-Loss 110.7962 | Test-MSE 352.4832 | Regret 0.0582 | Fair-Val 77.3392\n",
      "Epoch 030/50 | Train-Loss 96.0271 | Test-MSE 339.6193 | Regret 0.0561 | Fair-Val 69.0095\n",
      "Epoch 040/50 | Train-Loss 78.8885 | Test-MSE 323.5952 | Regret 0.0589 | Fair-Val 59.0856\n",
      "Epoch 050/50 | Train-Loss 63.4397 | Test-MSE 306.4568 | Regret 0.0648 | Fair-Val 48.9863\n",
      "Training finished in 296.03s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0644 | σ = 0.0005\n",
      "[                 MSE]  μ = 307.4454 | σ = 0.9886\n",
      "[            FAIRNESS]  μ = 50.5207 | σ = 1.5344\n",
      "[       TRAINING_TIME]  μ = 321.3794 | σ = 25.3500\n",
      "[              G0_MSE]  μ = 295.4012 | σ = 0.6228\n",
      "[              G1_MSE]  μ = 396.4426 | σ = 3.6916\n",
      "[     G0_DECISION_OBJ]  μ = 29.8892 | σ = 0.1038\n",
      "[     G1_DECISION_OBJ]  μ = 226.6886 | σ = 5.0464\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 0.8, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 100.7725 | Test-MSE 362.6483 | Regret 0.0013 | Fair-Val 85.7719\n",
      "Epoch 010/50 | Train-Loss 96.5796 | Test-MSE 360.9876 | Regret 0.0012 | Fair-Val 84.5123\n",
      "Epoch 020/50 | Train-Loss 86.7496 | Test-MSE 353.3367 | Regret 0.0011 | Fair-Val 79.4182\n",
      "Epoch 030/50 | Train-Loss 72.7795 | Test-MSE 341.2287 | Regret 0.0010 | Fair-Val 71.6066\n",
      "Epoch 040/50 | Train-Loss 54.5527 | Test-MSE 325.7184 | Regret 0.0011 | Fair-Val 61.8955\n",
      "Epoch 050/50 | Train-Loss 35.3403 | Test-MSE 308.4192 | Regret 0.0011 | Fair-Val 52.0435\n",
      "Training finished in 324.78s.\n",
      "Epoch 001/50 | Train-Loss 100.8308 | Test-MSE 362.6556 | Regret 0.0013 | Fair-Val 85.7719\n",
      "Epoch 010/50 | Train-Loss 95.4344 | Test-MSE 360.3693 | Regret 0.0012 | Fair-Val 83.1687\n",
      "Epoch 020/50 | Train-Loss 85.4720 | Test-MSE 352.4933 | Regret 0.0011 | Fair-Val 77.3413\n",
      "Epoch 030/50 | Train-Loss 72.1862 | Test-MSE 339.6256 | Regret 0.0010 | Fair-Val 69.0098\n",
      "Epoch 040/50 | Train-Loss 54.5452 | Test-MSE 323.5974 | Regret 0.0011 | Fair-Val 59.0837\n",
      "Epoch 050/50 | Train-Loss 36.5848 | Test-MSE 306.4532 | Regret 0.0011 | Fair-Val 48.9802\n",
      "Training finished in 279.26s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0011 | σ = 0.0000\n",
      "[                 MSE]  μ = 307.4362 | σ = 0.9830\n",
      "[            FAIRNESS]  μ = 50.5118 | σ = 1.5317\n",
      "[       TRAINING_TIME]  μ = 302.0203 | σ = 22.7581\n",
      "[              G0_MSE]  μ = 295.3941 | σ = 0.6178\n",
      "[              G1_MSE]  μ = 396.4178 | σ = 3.6811\n",
      "[     G0_DECISION_OBJ]  μ = 19.3110 | σ = 0.0099\n",
      "[     G1_DECISION_OBJ]  μ = 162.8253 | σ = 0.5470\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 1.5, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 103.3621 | Test-MSE 362.6467 | Regret 0.0277 | Fair-Val 85.7721\n",
      "Epoch 010/50 | Train-Loss 98.9615 | Test-MSE 360.8216 | Regret 0.0265 | Fair-Val 84.4563\n",
      "Epoch 020/50 | Train-Loss 88.7549 | Test-MSE 352.6399 | Regret 0.0234 | Fair-Val 79.2661\n",
      "Epoch 030/50 | Train-Loss 74.4656 | Test-MSE 339.9374 | Regret 0.0218 | Fair-Val 71.4170\n",
      "Epoch 040/50 | Train-Loss 56.0584 | Test-MSE 323.8929 | Regret 0.0216 | Fair-Val 61.7597\n",
      "Epoch 050/50 | Train-Loss 37.0417 | Test-MSE 306.6014 | Regret 0.0224 | Fair-Val 52.1142\n",
      "Training finished in 296.73s.\n",
      "Epoch 001/50 | Train-Loss 103.4299 | Test-MSE 362.6548 | Regret 0.0277 | Fair-Val 85.7708\n",
      "Epoch 010/50 | Train-Loss 97.8700 | Test-MSE 360.2820 | Regret 0.0262 | Fair-Val 83.1282\n",
      "Epoch 020/50 | Train-Loss 87.5531 | Test-MSE 352.0337 | Regret 0.0234 | Fair-Val 77.2430\n",
      "Epoch 030/50 | Train-Loss 74.1029 | Test-MSE 338.7573 | Regret 0.0217 | Fair-Val 68.8983\n",
      "Epoch 040/50 | Train-Loss 56.4744 | Test-MSE 322.4345 | Regret 0.0215 | Fair-Val 59.0208\n",
      "Epoch 050/50 | Train-Loss 38.6476 | Test-MSE 304.9985 | Regret 0.0223 | Fair-Val 48.9706\n",
      "Training finished in 268.70s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0224 | σ = 0.0001\n",
      "[                 MSE]  μ = 305.8000 | σ = 0.8014\n",
      "[            FAIRNESS]  μ = 50.5424 | σ = 1.5718\n",
      "[       TRAINING_TIME]  μ = 282.7134 | σ = 14.0170\n",
      "[              G0_MSE]  μ = 293.7507 | σ = 0.4267\n",
      "[              G1_MSE]  μ = 394.8355 | σ = 3.5704\n",
      "[     G0_DECISION_OBJ]  μ = 18.7271 | σ = 0.0081\n",
      "[     G1_DECISION_OBJ]  μ = 59.3638 | σ = 0.0822\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 2, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 177.7844 | Test-MSE 362.5771 | Regret 0.3400 | Fair-Val 85.7359\n",
      "Epoch 010/50 | Train-Loss 163.1482 | Test-MSE 356.4633 | Regret 0.2972 | Fair-Val 83.2471\n",
      "Epoch 020/50 | Train-Loss 142.1007 | Test-MSE 341.9572 | Regret 0.2544 | Fair-Val 77.4566\n",
      "Epoch 030/50 | Train-Loss 123.3582 | Test-MSE 325.2898 | Regret 0.2364 | Fair-Val 69.9401\n",
      "Epoch 040/50 | Train-Loss 104.9167 | Test-MSE 308.7340 | Regret 0.2292 | Fair-Val 61.1807\n",
      "Epoch 050/50 | Train-Loss 88.6840 | Test-MSE 292.8383 | Regret 0.2271 | Fair-Val 52.2089\n",
      "Training finished in 268.26s.\n",
      "Epoch 001/50 | Train-Loss 178.1356 | Test-MSE 362.6313 | Regret 0.3406 | Fair-Val 85.7629\n",
      "Epoch 010/50 | Train-Loss 164.6715 | Test-MSE 357.3351 | Regret 0.3046 | Fair-Val 82.2790\n",
      "Epoch 020/50 | Train-Loss 141.7579 | Test-MSE 342.8730 | Regret 0.2601 | Fair-Val 75.7928\n",
      "Epoch 030/50 | Train-Loss 123.0221 | Test-MSE 325.2637 | Regret 0.2415 | Fair-Val 68.1689\n",
      "Epoch 040/50 | Train-Loss 104.4815 | Test-MSE 308.2598 | Regret 0.2354 | Fair-Val 59.7016\n",
      "Epoch 050/50 | Train-Loss 88.5161 | Test-MSE 292.5441 | Regret 0.2331 | Fair-Val 51.1753\n",
      "Training finished in 268.45s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.2301 | σ = 0.0030\n",
      "[                 MSE]  μ = 292.6912 | σ = 0.1471\n",
      "[            FAIRNESS]  μ = 51.6921 | σ = 0.5168\n",
      "[       TRAINING_TIME]  μ = 268.3563 | σ = 0.0935\n",
      "[              G0_MSE]  μ = 280.3678 | σ = 0.0239\n",
      "[              G1_MSE]  μ = 383.7521 | σ = 1.0576\n",
      "[     G0_DECISION_OBJ]  μ = 19.2860 | σ = 0.0003\n",
      "[     G1_DECISION_OBJ]  μ = 24.9230 | σ = 0.0714\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 0.5, 'Lambda': 0.01, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 30.5302 | Test-MSE 362.6432 | Regret 0.0654 | Fair-Val 85.7556\n",
      "Epoch 010/50 | Train-Loss 29.5437 | Test-MSE 360.8899 | Regret 0.0642 | Fair-Val 84.4460\n",
      "Epoch 020/50 | Train-Loss 26.3543 | Test-MSE 352.7033 | Regret 0.0582 | Fair-Val 79.2786\n",
      "Epoch 030/50 | Train-Loss 24.6967 | Test-MSE 340.0005 | Regret 0.0556 | Fair-Val 71.5930\n",
      "Epoch 040/50 | Train-Loss 25.1136 | Test-MSE 324.0827 | Regret 0.0577 | Fair-Val 62.1698\n",
      "Epoch 050/50 | Train-Loss 26.8329 | Test-MSE 307.1001 | Regret 0.0628 | Fair-Val 52.6012\n",
      "Training finished in 266.47s.\n",
      "Epoch 001/50 | Train-Loss 30.5473 | Test-MSE 362.6559 | Regret 0.0654 | Fair-Val 85.7722\n",
      "Epoch 010/50 | Train-Loss 28.9897 | Test-MSE 360.2559 | Regret 0.0630 | Fair-Val 83.0967\n",
      "Epoch 020/50 | Train-Loss 26.0722 | Test-MSE 351.8758 | Regret 0.0578 | Fair-Val 77.1533\n",
      "Epoch 030/50 | Train-Loss 24.4456 | Test-MSE 338.5999 | Regret 0.0559 | Fair-Val 68.8598\n",
      "Epoch 040/50 | Train-Loss 24.6349 | Test-MSE 322.4050 | Regret 0.0586 | Fair-Val 59.1644\n",
      "Epoch 050/50 | Train-Loss 26.6595 | Test-MSE 305.2552 | Regret 0.0641 | Fair-Val 49.2956\n",
      "Training finished in 419.09s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0635 | σ = 0.0006\n",
      "[                 MSE]  μ = 306.1777 | σ = 0.9225\n",
      "[            FAIRNESS]  μ = 50.9484 | σ = 1.6528\n",
      "[       TRAINING_TIME]  μ = 342.7807 | σ = 76.3143\n",
      "[              G0_MSE]  μ = 294.0316 | σ = 0.5284\n",
      "[              G1_MSE]  μ = 395.9283 | σ = 3.8340\n",
      "[     G0_DECISION_OBJ]  μ = 30.1655 | σ = 0.0515\n",
      "[     G1_DECISION_OBJ]  μ = 227.1473 | σ = 4.8200\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 0.8, 'Lambda': 0.01, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 1.0873 | Test-MSE 362.6432 | Regret 0.0012 | Fair-Val 85.7556\n",
      "Epoch 010/50 | Train-Loss 1.0415 | Test-MSE 360.9721 | Regret 0.0012 | Fair-Val 84.4836\n",
      "Epoch 020/50 | Train-Loss 0.9340 | Test-MSE 353.3260 | Regret 0.0011 | Fair-Val 79.3717\n",
      "Epoch 030/50 | Train-Loss 0.7887 | Test-MSE 341.1286 | Regret 0.0010 | Fair-Val 71.5154\n",
      "Epoch 040/50 | Train-Loss 0.6041 | Test-MSE 325.3916 | Regret 0.0011 | Fair-Val 61.7520\n",
      "Epoch 050/50 | Train-Loss 0.4148 | Test-MSE 308.0678 | Regret 0.0011 | Fair-Val 51.9945\n",
      "Training finished in 340.55s.\n",
      "Epoch 001/50 | Train-Loss 1.0880 | Test-MSE 362.6558 | Regret 0.0013 | Fair-Val 85.7721\n",
      "Epoch 010/50 | Train-Loss 1.0294 | Test-MSE 360.3712 | Regret 0.0012 | Fair-Val 83.1614\n",
      "Epoch 020/50 | Train-Loss 0.9218 | Test-MSE 352.5085 | Regret 0.0011 | Fair-Val 77.3232\n",
      "Epoch 030/50 | Train-Loss 0.7838 | Test-MSE 339.6726 | Regret 0.0010 | Fair-Val 68.9828\n",
      "Epoch 040/50 | Train-Loss 0.6069 | Test-MSE 323.6768 | Regret 0.0011 | Fair-Val 59.0530\n",
      "Epoch 050/50 | Train-Loss 0.4308 | Test-MSE 306.5899 | Regret 0.0011 | Fair-Val 48.9691\n",
      "Training finished in 361.94s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0011 | σ = 0.0000\n",
      "[                 MSE]  μ = 307.3289 | σ = 0.7390\n",
      "[            FAIRNESS]  μ = 50.4818 | σ = 1.5127\n",
      "[       TRAINING_TIME]  μ = 351.2439 | σ = 10.6984\n",
      "[              G0_MSE]  μ = 295.2940 | σ = 0.3783\n",
      "[              G1_MSE]  μ = 396.2576 | σ = 3.4037\n",
      "[     G0_DECISION_OBJ]  μ = 19.3103 | σ = 0.0071\n",
      "[     G1_DECISION_OBJ]  μ = 162.8144 | σ = 0.5578\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 1.5, 'Lambda': 0.01, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 3.6769 | Test-MSE 362.5726 | Regret 0.0277 | Fair-Val 85.7273\n",
      "Epoch 010/50 | Train-Loss 3.2996 | Test-MSE 356.2181 | Regret 0.0245 | Fair-Val 83.2347\n",
      "Epoch 020/50 | Train-Loss 2.8634 | Test-MSE 341.7350 | Regret 0.0213 | Fair-Val 77.5835\n",
      "Epoch 030/50 | Train-Loss 2.5789 | Test-MSE 326.7568 | Regret 0.0198 | Fair-Val 71.0170\n",
      "Epoch 040/50 | Train-Loss 2.3359 | Test-MSE 314.2299 | Regret 0.0188 | Fair-Val 64.5092\n",
      "Epoch 050/50 | Train-Loss 2.1223 | Test-MSE 303.4616 | Regret 0.0177 | Fair-Val 58.6577\n",
      "Training finished in 385.22s.\n",
      "Epoch 001/50 | Train-Loss 3.6871 | Test-MSE 362.6311 | Regret 0.0277 | Fair-Val 85.7630\n",
      "Epoch 010/50 | Train-Loss 3.3516 | Test-MSE 357.0846 | Regret 0.0249 | Fair-Val 82.2713\n",
      "Epoch 020/50 | Train-Loss 2.8716 | Test-MSE 342.4451 | Regret 0.0217 | Fair-Val 75.9838\n",
      "Epoch 030/50 | Train-Loss 2.5876 | Test-MSE 326.3674 | Regret 0.0202 | Fair-Val 69.4149\n",
      "Epoch 040/50 | Train-Loss 2.3497 | Test-MSE 313.2939 | Regret 0.0193 | Fair-Val 63.2335\n",
      "Epoch 050/50 | Train-Loss 2.1405 | Test-MSE 302.7037 | Regret 0.0183 | Fair-Val 57.8042\n",
      "Training finished in 269.27s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0180 | σ = 0.0003\n",
      "[                 MSE]  μ = 303.0827 | σ = 0.3790\n",
      "[            FAIRNESS]  μ = 58.2310 | σ = 0.4268\n",
      "[       TRAINING_TIME]  μ = 327.2468 | σ = 57.9761\n",
      "[              G0_MSE]  μ = 289.2003 | σ = 0.2772\n",
      "[              G1_MSE]  μ = 405.6623 | σ = 1.1308\n",
      "[     G0_DECISION_OBJ]  μ = 18.6525 | σ = 0.0026\n",
      "[     G1_DECISION_OBJ]  μ = 59.9648 | σ = 0.1821\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 2, 'Lambda': 0.01, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 78.0992 | Test-MSE 362.5724 | Regret 0.3399 | Fair-Val 85.7343\n",
      "Epoch 010/50 | Train-Loss 67.8506 | Test-MSE 355.8994 | Regret 0.2944 | Fair-Val 83.3360\n",
      "Epoch 020/50 | Train-Loss 57.2858 | Test-MSE 341.2715 | Regret 0.2517 | Fair-Val 78.1373\n",
      "Epoch 030/50 | Train-Loss 51.2969 | Test-MSE 328.2801 | Regret 0.2307 | Fair-Val 72.7832\n",
      "Epoch 040/50 | Train-Loss 46.4348 | Test-MSE 319.2548 | Regret 0.2162 | Fair-Val 68.6675\n",
      "Epoch 050/50 | Train-Loss 41.9582 | Test-MSE 312.2520 | Regret 0.2004 | Fair-Val 66.1505\n",
      "Training finished in 272.84s.\n",
      "Epoch 001/50 | Train-Loss 78.3927 | Test-MSE 362.6296 | Regret 0.3406 | Fair-Val 85.7648\n",
      "Epoch 010/50 | Train-Loss 69.6245 | Test-MSE 356.7945 | Regret 0.3013 | Fair-Val 82.3959\n",
      "Epoch 020/50 | Train-Loss 58.0225 | Test-MSE 342.0085 | Regret 0.2571 | Fair-Val 76.6216\n",
      "Epoch 030/50 | Train-Loss 52.0082 | Test-MSE 327.8282 | Regret 0.2354 | Fair-Val 71.3934\n",
      "Epoch 040/50 | Train-Loss 47.3309 | Test-MSE 318.6347 | Regret 0.2201 | Fair-Val 67.6292\n",
      "Epoch 050/50 | Train-Loss 42.5579 | Test-MSE 312.2805 | Regret 0.2043 | Fair-Val 65.2584\n",
      "Training finished in 394.81s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.2024 | σ = 0.0019\n",
      "[                 MSE]  μ = 312.2662 | σ = 0.0142\n",
      "[            FAIRNESS]  μ = 65.7045 | σ = 0.4460\n",
      "[       TRAINING_TIME]  μ = 333.8248 | σ = 60.9813\n",
      "[              G0_MSE]  μ = 296.6023 | σ = 0.1206\n",
      "[              G1_MSE]  μ = 428.0112 | σ = 0.7715\n",
      "[     G0_DECISION_OBJ]  μ = 19.3478 | σ = 0.0158\n",
      "[     G1_DECISION_OBJ]  μ = 25.7841 | σ = 0.0940\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 0.5, 'Lambda': 1, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 29.5290 | Test-MSE 362.6038 | Regret 0.0654 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 28.1536 | Test-MSE 359.7046 | Regret 0.0630 | Fair-Val 0.0049\n",
      "Epoch 020/50 | Train-Loss 24.5714 | Test-MSE 349.8254 | Regret 0.0561 | Fair-Val 0.0046\n",
      "Epoch 030/50 | Train-Loss 22.6066 | Test-MSE 337.6429 | Regret 0.0532 | Fair-Val 0.0043\n",
      "Epoch 040/50 | Train-Loss 21.5381 | Test-MSE 328.5183 | Regret 0.0521 | Fair-Val 0.0038\n",
      "Epoch 050/50 | Train-Loss 20.4785 | Test-MSE 322.7372 | Regret 0.0504 | Fair-Val 0.0034\n",
      "Training finished in 476.59s.\n",
      "Epoch 001/50 | Train-Loss 29.5455 | Test-MSE 362.6614 | Regret 0.0654 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 28.0794 | Test-MSE 360.3412 | Regret 0.0629 | Fair-Val 0.0048\n",
      "Epoch 020/50 | Train-Loss 24.8359 | Test-MSE 351.3416 | Regret 0.0569 | Fair-Val 0.0044\n",
      "Epoch 030/50 | Train-Loss 22.6804 | Test-MSE 339.3116 | Regret 0.0537 | Fair-Val 0.0040\n",
      "Epoch 040/50 | Train-Loss 21.3164 | Test-MSE 329.8042 | Regret 0.0521 | Fair-Val 0.0036\n",
      "Epoch 050/50 | Train-Loss 20.3925 | Test-MSE 323.6020 | Regret 0.0501 | Fair-Val 0.0032\n",
      "Training finished in 286.72s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0502 | σ = 0.0002\n",
      "[                 MSE]  μ = 323.1696 | σ = 0.4324\n",
      "[            FAIRNESS]  μ = 0.0033 | σ = 0.0001\n",
      "[       TRAINING_TIME]  μ = 381.6539 | σ = 94.9354\n",
      "[              G0_MSE]  μ = 308.6552 | σ = 0.5856\n",
      "[              G1_MSE]  μ = 430.4202 | σ = 0.6997\n",
      "[     G0_DECISION_OBJ]  μ = 29.8097 | σ = 0.0583\n",
      "[     G1_DECISION_OBJ]  μ = 217.9158 | σ = 4.0867\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 0.8, 'Lambda': 1, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 0.0861 | Test-MSE 362.6319 | Regret 0.0012 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 0.0830 | Test-MSE 361.4759 | Regret 0.0012 | Fair-Val 0.0049\n",
      "Epoch 020/50 | Train-Loss 0.0757 | Test-MSE 356.8882 | Regret 0.0011 | Fair-Val 0.0046\n",
      "Epoch 030/50 | Train-Loss 0.0691 | Test-MSE 348.6361 | Regret 0.0011 | Fair-Val 0.0041\n",
      "Epoch 040/50 | Train-Loss 0.0652 | Test-MSE 336.9047 | Regret 0.0010 | Fair-Val 0.0034\n",
      "Epoch 050/50 | Train-Loss 0.0646 | Test-MSE 323.1457 | Regret 0.0011 | Fair-Val 0.0028\n",
      "Training finished in 260.78s.\n",
      "Epoch 001/50 | Train-Loss 0.0862 | Test-MSE 362.6518 | Regret 0.0013 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 0.0818 | Test-MSE 360.7405 | Regret 0.0012 | Fair-Val 0.0048\n",
      "Epoch 020/50 | Train-Loss 0.0745 | Test-MSE 355.1739 | Regret 0.0011 | Fair-Val 0.0044\n",
      "Epoch 030/50 | Train-Loss 0.0678 | Test-MSE 345.5626 | Regret 0.0011 | Fair-Val 0.0039\n",
      "Epoch 040/50 | Train-Loss 0.0645 | Test-MSE 332.9325 | Regret 0.0010 | Fair-Val 0.0032\n",
      "Epoch 050/50 | Train-Loss 0.0650 | Test-MSE 318.0532 | Regret 0.0011 | Fair-Val 0.0026\n",
      "Training finished in 260.93s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0011 | σ = 0.0000\n",
      "[                 MSE]  μ = 320.5994 | σ = 2.5462\n",
      "[            FAIRNESS]  μ = 0.0027 | σ = 0.0001\n",
      "[       TRAINING_TIME]  μ = 260.8556 | σ = 0.0724\n",
      "[              G0_MSE]  μ = 307.6782 | σ = 2.1684\n",
      "[              G1_MSE]  μ = 416.0777 | σ = 5.3379\n",
      "[     G0_DECISION_OBJ]  μ = 19.1765 | σ = 0.0562\n",
      "[     G1_DECISION_OBJ]  μ = 162.5349 | σ = 0.3621\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 1.5, 'Lambda': 1, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 2.6757 | Test-MSE 362.5711 | Regret 0.0277 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 2.3415 | Test-MSE 356.0378 | Regret 0.0244 | Fair-Val 0.0049\n",
      "Epoch 020/50 | Train-Loss 2.0045 | Test-MSE 341.6594 | Regret 0.0213 | Fair-Val 0.0047\n",
      "Epoch 030/50 | Train-Loss 1.8276 | Test-MSE 328.7594 | Regret 0.0197 | Fair-Val 0.0044\n",
      "Epoch 040/50 | Train-Loss 1.6791 | Test-MSE 320.2709 | Regret 0.0184 | Fair-Val 0.0042\n",
      "Epoch 050/50 | Train-Loss 1.5259 | Test-MSE 314.1585 | Regret 0.0170 | Fair-Val 0.0041\n",
      "Training finished in 262.43s.\n",
      "Epoch 001/50 | Train-Loss 2.6853 | Test-MSE 362.6305 | Regret 0.0277 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 2.3969 | Test-MSE 356.9092 | Regret 0.0248 | Fair-Val 0.0048\n",
      "Epoch 020/50 | Train-Loss 2.0253 | Test-MSE 342.3135 | Regret 0.0216 | Fair-Val 0.0045\n",
      "Epoch 030/50 | Train-Loss 1.8478 | Test-MSE 328.2204 | Regret 0.0200 | Fair-Val 0.0043\n",
      "Epoch 040/50 | Train-Loss 1.7034 | Test-MSE 319.3936 | Regret 0.0188 | Fair-Val 0.0041\n",
      "Epoch 050/50 | Train-Loss 1.5477 | Test-MSE 313.8046 | Regret 0.0173 | Fair-Val 0.0040\n",
      "Training finished in 260.92s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0172 | σ = 0.0002\n",
      "[                 MSE]  μ = 313.9816 | σ = 0.1770\n",
      "[            FAIRNESS]  μ = 0.0041 | σ = 0.0000\n",
      "[       TRAINING_TIME]  μ = 261.6765 | σ = 0.7584\n",
      "[              G0_MSE]  μ = 298.1332 | σ = 0.0747\n",
      "[              G1_MSE]  μ = 431.0894 | σ = 0.9327\n",
      "[     G0_DECISION_OBJ]  μ = 18.6739 | σ = 0.0083\n",
      "[     G1_DECISION_OBJ]  μ = 60.4759 | σ = 0.1593\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 2, 'Lambda': 1, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 77.0980 | Test-MSE 362.5725 | Regret 0.3399 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 66.8953 | Test-MSE 355.8989 | Regret 0.2944 | Fair-Val 0.0049\n",
      "Epoch 020/50 | Train-Loss 56.4184 | Test-MSE 341.2963 | Regret 0.2517 | Fair-Val 0.0047\n",
      "Epoch 030/50 | Train-Loss 50.5031 | Test-MSE 328.4134 | Regret 0.2307 | Fair-Val 0.0045\n",
      "Epoch 040/50 | Train-Loss 45.6749 | Test-MSE 319.5829 | Regret 0.2160 | Fair-Val 0.0042\n",
      "Epoch 050/50 | Train-Loss 41.1950 | Test-MSE 312.7910 | Regret 0.2000 | Fair-Val 0.0041\n",
      "Training finished in 259.58s.\n",
      "Epoch 001/50 | Train-Loss 77.3910 | Test-MSE 362.6297 | Regret 0.3406 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 68.6712 | Test-MSE 356.7938 | Regret 0.3013 | Fair-Val 0.0048\n",
      "Epoch 020/50 | Train-Loss 57.1702 | Test-MSE 342.0330 | Regret 0.2571 | Fair-Val 0.0045\n",
      "Epoch 030/50 | Train-Loss 51.2262 | Test-MSE 327.9689 | Regret 0.2354 | Fair-Val 0.0043\n",
      "Epoch 040/50 | Train-Loss 46.5838 | Test-MSE 318.9694 | Regret 0.2199 | Fair-Val 0.0041\n",
      "Epoch 050/50 | Train-Loss 41.8016 | Test-MSE 312.8323 | Regret 0.2039 | Fair-Val 0.0040\n",
      "Training finished in 260.83s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.2020 | σ = 0.0019\n",
      "[                 MSE]  μ = 312.8117 | σ = 0.0207\n",
      "[            FAIRNESS]  μ = 0.0041 | σ = 0.0001\n",
      "[       TRAINING_TIME]  μ = 260.2085 | σ = 0.6247\n",
      "[              G0_MSE]  μ = 297.0271 | σ = 0.1324\n",
      "[              G1_MSE]  μ = 429.4478 | σ = 0.8047\n",
      "[     G0_DECISION_OBJ]  μ = 19.3481 | σ = 0.0170\n",
      "[     G1_DECISION_OBJ]  μ = 25.8110 | σ = 0.0933\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 0.5, 'Lambda': 10, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 29.5806 | Test-MSE 362.6355 | Regret 0.0654 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 28.6529 | Test-MSE 360.9622 | Regret 0.0642 | Fair-Val 0.0049\n",
      "Epoch 020/50 | Train-Loss 25.4188 | Test-MSE 352.9271 | Regret 0.0581 | Fair-Val 0.0046\n",
      "Epoch 030/50 | Train-Loss 23.5175 | Test-MSE 341.6461 | Regret 0.0552 | Fair-Val 0.0041\n",
      "Epoch 040/50 | Train-Loss 22.9987 | Test-MSE 330.0063 | Regret 0.0552 | Fair-Val 0.0035\n",
      "Epoch 050/50 | Train-Loss 22.6031 | Test-MSE 319.3196 | Regret 0.0556 | Fair-Val 0.0029\n",
      "Training finished in 259.83s.\n",
      "Epoch 001/50 | Train-Loss 29.5971 | Test-MSE 362.6551 | Regret 0.0654 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 28.0454 | Test-MSE 360.1558 | Regret 0.0628 | Fair-Val 0.0048\n",
      "Epoch 020/50 | Train-Loss 25.0484 | Test-MSE 351.6490 | Regret 0.0575 | Fair-Val 0.0044\n",
      "Epoch 030/50 | Train-Loss 23.1864 | Test-MSE 339.7278 | Regret 0.0553 | Fair-Val 0.0039\n",
      "Epoch 040/50 | Train-Loss 22.4376 | Test-MSE 328.1502 | Regret 0.0556 | Fair-Val 0.0033\n",
      "Epoch 050/50 | Train-Loss 22.4326 | Test-MSE 317.6123 | Regret 0.0562 | Fair-Val 0.0027\n",
      "Training finished in 260.49s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0559 | σ = 0.0003\n",
      "[                 MSE]  μ = 318.4660 | σ = 0.8536\n",
      "[            FAIRNESS]  μ = 0.0028 | σ = 0.0001\n",
      "[       TRAINING_TIME]  μ = 260.1610 | σ = 0.3322\n",
      "[              G0_MSE]  μ = 305.2962 | σ = 0.5932\n",
      "[              G1_MSE]  μ = 415.7805 | σ = 2.7780\n",
      "[     G0_DECISION_OBJ]  μ = 29.1375 | σ = 0.1208\n",
      "[     G1_DECISION_OBJ]  μ = 222.6461 | σ = 2.8655\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 0.8, 'Lambda': 10, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 0.1377 | Test-MSE 362.6393 | Regret 0.0012 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 0.1308 | Test-MSE 361.3857 | Regret 0.0012 | Fair-Val 0.0049\n",
      "Epoch 020/50 | Train-Loss 0.1164 | Test-MSE 356.3894 | Regret 0.0011 | Fair-Val 0.0046\n",
      "Epoch 030/50 | Train-Loss 0.1019 | Test-MSE 347.8393 | Regret 0.0011 | Fair-Val 0.0040\n",
      "Epoch 040/50 | Train-Loss 0.0891 | Test-MSE 336.4241 | Regret 0.0011 | Fair-Val 0.0033\n",
      "Epoch 050/50 | Train-Loss 0.0798 | Test-MSE 323.1142 | Regret 0.0011 | Fair-Val 0.0026\n",
      "Training finished in 260.83s.\n",
      "Epoch 001/50 | Train-Loss 0.1378 | Test-MSE 362.6504 | Regret 0.0013 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 0.1286 | Test-MSE 360.6392 | Regret 0.0012 | Fair-Val 0.0048\n",
      "Epoch 020/50 | Train-Loss 0.1148 | Test-MSE 355.1926 | Regret 0.0011 | Fair-Val 0.0044\n",
      "Epoch 030/50 | Train-Loss 0.1007 | Test-MSE 346.3723 | Regret 0.0011 | Fair-Val 0.0038\n",
      "Epoch 040/50 | Train-Loss 0.0875 | Test-MSE 334.7559 | Regret 0.0011 | Fair-Val 0.0031\n",
      "Epoch 050/50 | Train-Loss 0.0797 | Test-MSE 321.8490 | Regret 0.0011 | Fair-Val 0.0024\n",
      "Training finished in 408.94s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0011 | σ = 0.0000\n",
      "[                 MSE]  μ = 322.4816 | σ = 0.6326\n",
      "[            FAIRNESS]  μ = 0.0025 | σ = 0.0001\n",
      "[       TRAINING_TIME]  μ = 334.8877 | σ = 74.0534\n",
      "[              G0_MSE]  μ = 309.9310 | σ = 0.3677\n",
      "[              G1_MSE]  μ = 415.2212 | σ = 2.5901\n",
      "[     G0_DECISION_OBJ]  μ = 19.1314 | σ = 0.0211\n",
      "[     G1_DECISION_OBJ]  μ = 162.9914 | σ = 0.4096\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 1.5, 'Lambda': 10, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 2.7273 | Test-MSE 362.5713 | Regret 0.0277 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 2.3907 | Test-MSE 356.0499 | Regret 0.0244 | Fair-Val 0.0049\n",
      "Epoch 020/50 | Train-Loss 2.0489 | Test-MSE 341.6688 | Regret 0.0213 | Fair-Val 0.0047\n",
      "Epoch 030/50 | Train-Loss 1.8671 | Test-MSE 328.6107 | Regret 0.0197 | Fair-Val 0.0044\n",
      "Epoch 040/50 | Train-Loss 1.7152 | Test-MSE 319.8196 | Regret 0.0185 | Fair-Val 0.0042\n",
      "Epoch 050/50 | Train-Loss 1.5627 | Test-MSE 313.3242 | Regret 0.0170 | Fair-Val 0.0040\n",
      "Training finished in 500.36s.\n",
      "Epoch 001/50 | Train-Loss 2.7369 | Test-MSE 362.6306 | Regret 0.0277 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 2.4456 | Test-MSE 356.9247 | Regret 0.0248 | Fair-Val 0.0048\n",
      "Epoch 020/50 | Train-Loss 2.0681 | Test-MSE 342.3187 | Regret 0.0216 | Fair-Val 0.0045\n",
      "Epoch 030/50 | Train-Loss 1.8863 | Test-MSE 328.0780 | Regret 0.0200 | Fair-Val 0.0043\n",
      "Epoch 040/50 | Train-Loss 1.7378 | Test-MSE 318.9419 | Regret 0.0188 | Fair-Val 0.0041\n",
      "Epoch 050/50 | Train-Loss 1.5821 | Test-MSE 312.9915 | Regret 0.0174 | Fair-Val 0.0040\n",
      "Training finished in 466.79s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0172 | σ = 0.0002\n",
      "[                 MSE]  μ = 313.1578 | σ = 0.1663\n",
      "[            FAIRNESS]  μ = 0.0040 | σ = 0.0000\n",
      "[       TRAINING_TIME]  μ = 483.5744 | σ = 16.7827\n",
      "[              G0_MSE]  μ = 297.5373 | σ = 0.0784\n",
      "[              G1_MSE]  μ = 428.5819 | σ = 0.8161\n",
      "[     G0_DECISION_OBJ]  μ = 18.6751 | σ = 0.0081\n",
      "[     G1_DECISION_OBJ]  μ = 60.4228 | σ = 0.1619\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 2, 'Lambda': 10, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 77.1496 | Test-MSE 362.5725 | Regret 0.3399 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 66.9444 | Test-MSE 355.8990 | Regret 0.2944 | Fair-Val 0.0049\n",
      "Epoch 020/50 | Train-Loss 56.4633 | Test-MSE 341.2950 | Regret 0.2517 | Fair-Val 0.0047\n",
      "Epoch 030/50 | Train-Loss 50.5439 | Test-MSE 328.4061 | Regret 0.2307 | Fair-Val 0.0045\n",
      "Epoch 040/50 | Train-Loss 45.7133 | Test-MSE 319.5638 | Regret 0.2160 | Fair-Val 0.0042\n",
      "Epoch 050/50 | Train-Loss 41.2347 | Test-MSE 312.7614 | Regret 0.2001 | Fair-Val 0.0041\n",
      "Training finished in 319.28s.\n",
      "Epoch 001/50 | Train-Loss 77.4425 | Test-MSE 362.6297 | Regret 0.3406 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 68.7196 | Test-MSE 356.7939 | Regret 0.3013 | Fair-Val 0.0048\n",
      "Epoch 020/50 | Train-Loss 57.2132 | Test-MSE 342.0318 | Regret 0.2571 | Fair-Val 0.0045\n",
      "Epoch 030/50 | Train-Loss 51.2657 | Test-MSE 327.9603 | Regret 0.2354 | Fair-Val 0.0043\n",
      "Epoch 040/50 | Train-Loss 46.6216 | Test-MSE 318.9483 | Regret 0.2199 | Fair-Val 0.0041\n",
      "Epoch 050/50 | Train-Loss 41.8408 | Test-MSE 312.7939 | Regret 0.2039 | Fair-Val 0.0040\n",
      "Training finished in 259.10s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.2020 | σ = 0.0019\n",
      "[                 MSE]  μ = 312.7777 | σ = 0.0163\n",
      "[            FAIRNESS]  μ = 0.0041 | σ = 0.0001\n",
      "[       TRAINING_TIME]  μ = 289.1908 | σ = 30.0938\n",
      "[              G0_MSE]  μ = 297.0026 | σ = 0.1273\n",
      "[              G1_MSE]  μ = 429.3436 | σ = 0.8043\n",
      "[     G0_DECISION_OBJ]  μ = 19.3482 | σ = 0.0169\n",
      "[     G1_DECISION_OBJ]  μ = 25.8086 | σ = 0.0934\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 0.5, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 29.5233 | Test-MSE 362.5895 | Regret 0.0654 | Fair-Val 85.7606\n",
      "Epoch 010/50 | Train-Loss 27.4413 | Test-MSE 357.3732 | Regret 0.0611 | Fair-Val 83.7360\n",
      "Epoch 020/50 | Train-Loss 23.6288 | Test-MSE 344.2960 | Regret 0.0545 | Fair-Val 78.6169\n",
      "Epoch 030/50 | Train-Loss 21.6763 | Test-MSE 331.4693 | Regret 0.0516 | Fair-Val 73.7505\n",
      "Epoch 040/50 | Train-Loss 20.1722 | Test-MSE 324.3702 | Regret 0.0489 | Fair-Val 71.0329\n",
      "Epoch 050/50 | Train-Loss 18.5191 | Test-MSE 319.5913 | Regret 0.0454 | Fair-Val 70.0180\n",
      "Training finished in 79.52s.\n",
      "Epoch 001/50 | Train-Loss 29.5398 | Test-MSE 362.6480 | Regret 0.0654 | Fair-Val 85.7809\n",
      "Epoch 010/50 | Train-Loss 27.4538 | Test-MSE 358.2600 | Regret 0.0614 | Fair-Val 83.0503\n",
      "Epoch 020/50 | Train-Loss 23.7112 | Test-MSE 345.3168 | Regret 0.0546 | Fair-Val 77.4476\n",
      "Epoch 030/50 | Train-Loss 21.8452 | Test-MSE 332.2770 | Regret 0.0520 | Fair-Val 72.7404\n",
      "Epoch 040/50 | Train-Loss 20.0955 | Test-MSE 325.0252 | Regret 0.0494 | Fair-Val 70.3236\n",
      "Epoch 050/50 | Train-Loss 18.6030 | Test-MSE 320.5206 | Regret 0.0460 | Fair-Val 69.1981\n",
      "Training finished in 80.53s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0457 | σ = 0.0003\n",
      "[                 MSE]  μ = 320.0560 | σ = 0.4646\n",
      "[            FAIRNESS]  μ = 69.6081 | σ = 0.4099\n",
      "[       TRAINING_TIME]  μ = 80.0255 | σ = 0.5038\n",
      "[              G0_MSE]  μ = 303.4614 | σ = 0.5624\n",
      "[              G1_MSE]  μ = 442.6775 | σ = 0.2575\n",
      "[     G0_DECISION_OBJ]  μ = 32.4401 | σ = 0.1378\n",
      "[     G1_DECISION_OBJ]  μ = 203.2822 | σ = 2.3460\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 0.8, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 0.0804 | Test-MSE 362.5797 | Regret 0.0012 | Fair-Val 85.7201\n",
      "Epoch 010/50 | Train-Loss 0.0725 | Test-MSE 356.9172 | Regret 0.0011 | Fair-Val 83.4629\n",
      "Epoch 020/50 | Train-Loss 0.0624 | Test-MSE 344.4349 | Regret 0.0010 | Fair-Val 78.5112\n",
      "Epoch 030/50 | Train-Loss 0.0575 | Test-MSE 332.6458 | Regret 0.0010 | Fair-Val 73.7818\n",
      "Epoch 040/50 | Train-Loss 0.0542 | Test-MSE 325.1112 | Regret 0.0009 | Fair-Val 70.7179\n",
      "Epoch 050/50 | Train-Loss 0.0512 | Test-MSE 320.3793 | Regret 0.0009 | Fair-Val 68.9112\n",
      "Training finished in 141.21s.\n",
      "Epoch 001/50 | Train-Loss 0.0805 | Test-MSE 362.6312 | Regret 0.0012 | Fair-Val 85.7645\n",
      "Epoch 010/50 | Train-Loss 0.0730 | Test-MSE 357.5561 | Regret 0.0011 | Fair-Val 82.5470\n",
      "Epoch 020/50 | Train-Loss 0.0624 | Test-MSE 344.8214 | Regret 0.0010 | Fair-Val 76.9366\n",
      "Epoch 030/50 | Train-Loss 0.0579 | Test-MSE 333.3751 | Regret 0.0010 | Fair-Val 72.3884\n",
      "Epoch 040/50 | Train-Loss 0.0546 | Test-MSE 323.7946 | Regret 0.0009 | Fair-Val 69.2784\n",
      "Epoch 050/50 | Train-Loss 0.0521 | Test-MSE 317.2906 | Regret 0.0009 | Fair-Val 67.5543\n",
      "Training finished in 140.93s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0009 | σ = 0.0000\n",
      "[                 MSE]  μ = 318.8349 | σ = 1.5443\n",
      "[            FAIRNESS]  μ = 68.2327 | σ = 0.6785\n",
      "[       TRAINING_TIME]  μ = 141.0712 | σ = 0.1428\n",
      "[              G0_MSE]  μ = 302.5682 | σ = 1.3826\n",
      "[              G1_MSE]  μ = 439.0337 | σ = 2.7395\n",
      "[     G0_DECISION_OBJ]  μ = 19.4408 | σ = 0.0096\n",
      "[     G1_DECISION_OBJ]  μ = 160.5388 | σ = 0.0176\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 1.5, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 2.6700 | Test-MSE 362.5723 | Regret 0.0277 | Fair-Val 85.7296\n",
      "Epoch 010/50 | Train-Loss 2.3369 | Test-MSE 356.0949 | Regret 0.0244 | Fair-Val 83.3029\n",
      "Epoch 020/50 | Train-Loss 2.0032 | Test-MSE 341.8651 | Regret 0.0213 | Fair-Val 78.0603\n",
      "Epoch 030/50 | Train-Loss 1.8298 | Test-MSE 329.4337 | Regret 0.0198 | Fair-Val 73.0393\n",
      "Epoch 040/50 | Train-Loss 1.6873 | Test-MSE 321.0434 | Regret 0.0185 | Fair-Val 69.3719\n",
      "Epoch 050/50 | Train-Loss 1.5414 | Test-MSE 315.1289 | Regret 0.0171 | Fair-Val 67.2169\n",
      "Training finished in 141.54s.\n",
      "Epoch 001/50 | Train-Loss 2.6796 | Test-MSE 362.6337 | Regret 0.0277 | Fair-Val 85.7648\n",
      "Epoch 010/50 | Train-Loss 2.3967 | Test-MSE 357.0440 | Regret 0.0248 | Fair-Val 82.3350\n",
      "Epoch 020/50 | Train-Loss 2.0248 | Test-MSE 342.5698 | Regret 0.0216 | Fair-Val 76.4415\n",
      "Epoch 030/50 | Train-Loss 1.8513 | Test-MSE 327.6962 | Regret 0.0201 | Fair-Val 71.0900\n",
      "Epoch 040/50 | Train-Loss 1.7159 | Test-MSE 318.3011 | Regret 0.0189 | Fair-Val 67.5324\n",
      "Epoch 050/50 | Train-Loss 1.5679 | Test-MSE 313.9144 | Regret 0.0176 | Fair-Val 65.7166\n",
      "Training finished in 142.26s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0174 | σ = 0.0002\n",
      "[                 MSE]  μ = 314.5217 | σ = 0.6073\n",
      "[            FAIRNESS]  μ = 66.4668 | σ = 0.7502\n",
      "[       TRAINING_TIME]  μ = 141.9020 | σ = 0.3576\n",
      "[              G0_MSE]  μ = 298.6760 | σ = 0.4284\n",
      "[              G1_MSE]  μ = 431.6095 | σ = 1.9287\n",
      "[     G0_DECISION_OBJ]  μ = 18.6682 | σ = 0.0031\n",
      "[     G1_DECISION_OBJ]  μ = 60.4434 | σ = 0.1050\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 2, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 77.0923 | Test-MSE 362.5725 | Regret 0.3399 | Fair-Val 85.7348\n",
      "Epoch 010/50 | Train-Loss 66.8825 | Test-MSE 355.8950 | Regret 0.2944 | Fair-Val 83.3433\n",
      "Epoch 020/50 | Train-Loss 56.4134 | Test-MSE 341.3571 | Regret 0.2517 | Fair-Val 78.1917\n",
      "Epoch 030/50 | Train-Loss 50.4813 | Test-MSE 329.1970 | Regret 0.2309 | Fair-Val 73.0717\n",
      "Epoch 040/50 | Train-Loss 45.6946 | Test-MSE 320.0343 | Regret 0.2160 | Fair-Val 69.1631\n",
      "Epoch 050/50 | Train-Loss 41.1868 | Test-MSE 312.9399 | Regret 0.1999 | Fair-Val 66.7975\n",
      "Training finished in 98.80s.\n",
      "Epoch 001/50 | Train-Loss 77.3852 | Test-MSE 362.6294 | Regret 0.3406 | Fair-Val 85.7641\n",
      "Epoch 010/50 | Train-Loss 68.6669 | Test-MSE 356.7928 | Regret 0.3013 | Fair-Val 82.3926\n",
      "Epoch 020/50 | Train-Loss 57.1781 | Test-MSE 342.0085 | Regret 0.2572 | Fair-Val 76.6388\n",
      "Epoch 030/50 | Train-Loss 51.3102 | Test-MSE 327.7210 | Regret 0.2357 | Fair-Val 71.4638\n",
      "Epoch 040/50 | Train-Loss 46.7227 | Test-MSE 318.9861 | Regret 0.2203 | Fair-Val 67.9364\n",
      "Epoch 050/50 | Train-Loss 41.9862 | Test-MSE 313.2469 | Regret 0.2045 | Fair-Val 65.8277\n",
      "Training finished in 98.39s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.2022 | σ = 0.0023\n",
      "[                 MSE]  μ = 313.0934 | σ = 0.1535\n",
      "[            FAIRNESS]  μ = 66.3126 | σ = 0.4849\n",
      "[       TRAINING_TIME]  μ = 98.5945 | σ = 0.2067\n",
      "[              G0_MSE]  μ = 297.2845 | σ = 0.2690\n",
      "[              G1_MSE]  μ = 429.9096 | σ = 0.7007\n",
      "[     G0_DECISION_OBJ]  μ = 19.3491 | σ = 0.0207\n",
      "[     G1_DECISION_OBJ]  μ = 25.8269 | σ = 0.0861\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 0.5, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 130.2154 | Test-MSE 362.6341 | Regret 0.0654 | Fair-Val 85.7709\n",
      "Epoch 010/50 | Train-Loss 124.2301 | Test-MSE 359.7056 | Regret 0.0629 | Fair-Val 83.9972\n",
      "Epoch 020/50 | Train-Loss 109.9204 | Test-MSE 348.5715 | Regret 0.0557 | Fair-Val 78.4596\n",
      "Epoch 030/50 | Train-Loss 93.8072 | Test-MSE 333.2087 | Regret 0.0536 | Fair-Val 70.9548\n",
      "Epoch 040/50 | Train-Loss 76.6015 | Test-MSE 316.5945 | Regret 0.0553 | Fair-Val 62.0303\n",
      "Epoch 050/50 | Train-Loss 60.6635 | Test-MSE 300.4406 | Regret 0.0584 | Fair-Val 52.6691\n",
      "Training finished in 80.91s.\n",
      "Epoch 001/50 | Train-Loss 130.2901 | Test-MSE 362.6543 | Regret 0.0654 | Fair-Val 85.7720\n",
      "Epoch 010/50 | Train-Loss 123.1593 | Test-MSE 359.7429 | Regret 0.0626 | Fair-Val 82.9505\n",
      "Epoch 020/50 | Train-Loss 109.4201 | Test-MSE 349.2645 | Regret 0.0566 | Fair-Val 76.7746\n",
      "Epoch 030/50 | Train-Loss 94.3402 | Test-MSE 333.7458 | Regret 0.0548 | Fair-Val 68.8268\n",
      "Epoch 040/50 | Train-Loss 76.5093 | Test-MSE 316.1361 | Regret 0.0565 | Fair-Val 59.6884\n",
      "Epoch 050/50 | Train-Loss 60.5641 | Test-MSE 299.0049 | Regret 0.0601 | Fair-Val 50.4740\n",
      "Training finished in 81.08s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0592 | σ = 0.0008\n",
      "[                 MSE]  μ = 299.7227 | σ = 0.7178\n",
      "[            FAIRNESS]  μ = 51.5715 | σ = 1.0975\n",
      "[       TRAINING_TIME]  μ = 80.9940 | σ = 0.0880\n",
      "[              G0_MSE]  μ = 287.4281 | σ = 0.4562\n",
      "[              G1_MSE]  μ = 390.5712 | σ = 2.6512\n",
      "[     G0_DECISION_OBJ]  μ = 31.9592 | σ = 0.0787\n",
      "[     G1_DECISION_OBJ]  μ = 226.6623 | σ = 1.8718\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 0.8, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 100.7725 | Test-MSE 362.6483 | Regret 0.0013 | Fair-Val 85.7719\n",
      "Epoch 010/50 | Train-Loss 96.5790 | Test-MSE 360.9846 | Regret 0.0012 | Fair-Val 84.5110\n",
      "Epoch 020/50 | Train-Loss 86.7478 | Test-MSE 353.3235 | Regret 0.0011 | Fair-Val 79.4157\n",
      "Epoch 030/50 | Train-Loss 72.7760 | Test-MSE 341.2037 | Regret 0.0010 | Fair-Val 71.6079\n",
      "Epoch 040/50 | Train-Loss 54.5507 | Test-MSE 325.6958 | Regret 0.0011 | Fair-Val 61.9081\n",
      "Epoch 050/50 | Train-Loss 35.3518 | Test-MSE 308.4142 | Regret 0.0011 | Fair-Val 52.0565\n",
      "Training finished in 141.55s.\n",
      "Epoch 001/50 | Train-Loss 100.8308 | Test-MSE 362.6556 | Regret 0.0013 | Fair-Val 85.7718\n",
      "Epoch 010/50 | Train-Loss 95.4343 | Test-MSE 360.3668 | Regret 0.0012 | Fair-Val 83.1680\n",
      "Epoch 020/50 | Train-Loss 85.4692 | Test-MSE 352.4795 | Regret 0.0011 | Fair-Val 77.3396\n",
      "Epoch 030/50 | Train-Loss 72.1870 | Test-MSE 339.6086 | Regret 0.0010 | Fair-Val 69.0104\n",
      "Epoch 040/50 | Train-Loss 54.5515 | Test-MSE 323.5939 | Regret 0.0011 | Fair-Val 59.0926\n",
      "Epoch 050/50 | Train-Loss 36.5949 | Test-MSE 306.4525 | Regret 0.0011 | Fair-Val 48.9921\n",
      "Training finished in 141.98s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0011 | σ = 0.0000\n",
      "[                 MSE]  μ = 307.4334 | σ = 0.9809\n",
      "[            FAIRNESS]  μ = 50.5243 | σ = 1.5322\n",
      "[       TRAINING_TIME]  μ = 141.7627 | σ = 0.2164\n",
      "[              G0_MSE]  μ = 295.3884 | σ = 0.6155\n",
      "[              G1_MSE]  μ = 396.4370 | σ = 3.6799\n",
      "[     G0_DECISION_OBJ]  μ = 19.3113 | σ = 0.0099\n",
      "[     G1_DECISION_OBJ]  μ = 162.8256 | σ = 0.5451\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 1.5, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 103.3621 | Test-MSE 362.6466 | Regret 0.0277 | Fair-Val 85.7722\n",
      "Epoch 010/50 | Train-Loss 98.9614 | Test-MSE 360.8202 | Regret 0.0265 | Fair-Val 84.4559\n",
      "Epoch 020/50 | Train-Loss 88.7518 | Test-MSE 352.6370 | Regret 0.0234 | Fair-Val 79.2658\n",
      "Epoch 030/50 | Train-Loss 74.4501 | Test-MSE 339.8823 | Regret 0.0218 | Fair-Val 71.4214\n",
      "Epoch 040/50 | Train-Loss 56.0502 | Test-MSE 323.8131 | Regret 0.0216 | Fair-Val 61.7675\n",
      "Epoch 050/50 | Train-Loss 37.0459 | Test-MSE 306.5712 | Regret 0.0224 | Fair-Val 52.1358\n",
      "Training finished in 141.94s.\n",
      "Epoch 001/50 | Train-Loss 103.4299 | Test-MSE 362.6549 | Regret 0.0277 | Fair-Val 85.7707\n",
      "Epoch 010/50 | Train-Loss 97.8729 | Test-MSE 360.2896 | Regret 0.0262 | Fair-Val 83.1318\n",
      "Epoch 020/50 | Train-Loss 87.5606 | Test-MSE 352.0525 | Regret 0.0234 | Fair-Val 77.2486\n",
      "Epoch 030/50 | Train-Loss 74.1047 | Test-MSE 338.7481 | Regret 0.0217 | Fair-Val 68.9016\n",
      "Epoch 040/50 | Train-Loss 56.4786 | Test-MSE 322.4149 | Regret 0.0215 | Fair-Val 59.0258\n",
      "Epoch 050/50 | Train-Loss 38.6544 | Test-MSE 304.9899 | Regret 0.0223 | Fair-Val 48.9867\n",
      "Training finished in 141.30s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0224 | σ = 0.0001\n",
      "[                 MSE]  μ = 305.7805 | σ = 0.7906\n",
      "[            FAIRNESS]  μ = 50.5613 | σ = 1.5745\n",
      "[       TRAINING_TIME]  μ = 141.6197 | σ = 0.3194\n",
      "[              G0_MSE]  μ = 293.7267 | σ = 0.4153\n",
      "[              G1_MSE]  μ = 394.8493 | σ = 3.5643\n",
      "[     G0_DECISION_OBJ]  μ = 18.7267 | σ = 0.0081\n",
      "[     G1_DECISION_OBJ]  μ = 59.3680 | σ = 0.0841\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 2, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 177.7844 | Test-MSE 362.5786 | Regret 0.3400 | Fair-Val 85.7373\n",
      "Epoch 010/50 | Train-Loss 163.1409 | Test-MSE 356.4326 | Regret 0.2971 | Fair-Val 83.2486\n",
      "Epoch 020/50 | Train-Loss 142.1414 | Test-MSE 341.9868 | Regret 0.2545 | Fair-Val 77.4398\n",
      "Epoch 030/50 | Train-Loss 123.3932 | Test-MSE 325.3119 | Regret 0.2364 | Fair-Val 69.9184\n",
      "Epoch 040/50 | Train-Loss 105.0525 | Test-MSE 308.7746 | Regret 0.2292 | Fair-Val 61.2169\n",
      "Epoch 050/50 | Train-Loss 88.8287 | Test-MSE 292.6050 | Regret 0.2273 | Fair-Val 52.2871\n",
      "Training finished in 98.99s.\n",
      "Epoch 001/50 | Train-Loss 178.1356 | Test-MSE 362.6313 | Regret 0.3406 | Fair-Val 85.7628\n",
      "Epoch 010/50 | Train-Loss 164.6724 | Test-MSE 357.3383 | Regret 0.3046 | Fair-Val 82.2840\n",
      "Epoch 020/50 | Train-Loss 141.7726 | Test-MSE 342.8721 | Regret 0.2601 | Fair-Val 75.7962\n",
      "Epoch 030/50 | Train-Loss 123.0618 | Test-MSE 325.2904 | Regret 0.2415 | Fair-Val 68.1594\n",
      "Epoch 040/50 | Train-Loss 104.5711 | Test-MSE 308.4074 | Regret 0.2355 | Fair-Val 59.7023\n",
      "Epoch 050/50 | Train-Loss 88.6708 | Test-MSE 292.9642 | Regret 0.2330 | Fair-Val 51.1988\n",
      "Training finished in 98.53s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.2301 | σ = 0.0029\n",
      "[                 MSE]  μ = 292.7846 | σ = 0.1796\n",
      "[            FAIRNESS]  μ = 51.7429 | σ = 0.5441\n",
      "[       TRAINING_TIME]  μ = 98.7613 | σ = 0.2274\n",
      "[              G0_MSE]  μ = 280.4491 | σ = 0.3093\n",
      "[              G1_MSE]  μ = 383.9350 | σ = 0.7789\n",
      "[     G0_DECISION_OBJ]  μ = 19.2839 | σ = 0.0066\n",
      "[     G1_DECISION_OBJ]  μ = 24.9274 | σ = 0.0503\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 0.5, 'Lambda': 0.01, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 30.5302 | Test-MSE 362.5887 | Regret 0.0654 | Fair-Val 85.7599\n",
      "Epoch 010/50 | Train-Loss 28.4265 | Test-MSE 357.4561 | Regret 0.0612 | Fair-Val 83.7107\n",
      "Epoch 020/50 | Train-Loss 24.5270 | Test-MSE 344.3578 | Regret 0.0545 | Fair-Val 78.4044\n",
      "Epoch 030/50 | Train-Loss 22.4722 | Test-MSE 331.1493 | Regret 0.0517 | Fair-Val 72.9861\n",
      "Epoch 040/50 | Train-Loss 20.9242 | Test-MSE 323.0345 | Regret 0.0491 | Fair-Val 69.4550\n",
      "Epoch 050/50 | Train-Loss 19.2484 | Test-MSE 317.9326 | Regret 0.0456 | Fair-Val 67.6840\n",
      "Training finished in 80.89s.\n",
      "Epoch 001/50 | Train-Loss 30.5473 | Test-MSE 362.6439 | Regret 0.0654 | Fair-Val 85.7742\n",
      "Epoch 010/50 | Train-Loss 28.3807 | Test-MSE 358.0689 | Regret 0.0613 | Fair-Val 82.9061\n",
      "Epoch 020/50 | Train-Loss 24.5512 | Test-MSE 344.6929 | Regret 0.0546 | Fair-Val 77.0477\n",
      "Epoch 030/50 | Train-Loss 22.6443 | Test-MSE 331.8593 | Regret 0.0521 | Fair-Val 72.0337\n",
      "Epoch 040/50 | Train-Loss 20.8709 | Test-MSE 324.1760 | Regret 0.0497 | Fair-Val 69.0206\n",
      "Epoch 050/50 | Train-Loss 19.3959 | Test-MSE 319.1070 | Regret 0.0463 | Fair-Val 67.1871\n",
      "Training finished in 80.70s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0460 | σ = 0.0003\n",
      "[                 MSE]  μ = 318.5198 | σ = 0.5872\n",
      "[            FAIRNESS]  μ = 67.4355 | σ = 0.2485\n",
      "[       TRAINING_TIME]  μ = 80.7967 | σ = 0.0941\n",
      "[              G0_MSE]  μ = 302.4432 | σ = 0.6463\n",
      "[              G1_MSE]  μ = 437.3143 | σ = 0.1494\n",
      "[     G0_DECISION_OBJ]  μ = 32.3519 | σ = 0.1255\n",
      "[     G1_DECISION_OBJ]  μ = 204.0447 | σ = 2.5452\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 0.8, 'Lambda': 0.01, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 1.0873 | Test-MSE 362.6430 | Regret 0.0012 | Fair-Val 85.7560\n",
      "Epoch 010/50 | Train-Loss 1.0403 | Test-MSE 360.6640 | Regret 0.0012 | Fair-Val 84.3802\n",
      "Epoch 020/50 | Train-Loss 0.9313 | Test-MSE 352.1153 | Regret 0.0011 | Fair-Val 79.1946\n",
      "Epoch 030/50 | Train-Loss 0.7830 | Test-MSE 339.0504 | Regret 0.0010 | Fair-Val 71.4328\n",
      "Epoch 040/50 | Train-Loss 0.5986 | Test-MSE 322.7804 | Regret 0.0010 | Fair-Val 62.0734\n",
      "Epoch 050/50 | Train-Loss 0.4109 | Test-MSE 305.4284 | Regret 0.0011 | Fair-Val 52.6392\n",
      "Training finished in 141.66s.\n",
      "Epoch 001/50 | Train-Loss 1.0880 | Test-MSE 362.6552 | Regret 0.0013 | Fair-Val 85.7718\n",
      "Epoch 010/50 | Train-Loss 1.0289 | Test-MSE 360.1281 | Regret 0.0012 | Fair-Val 83.0549\n",
      "Epoch 020/50 | Train-Loss 0.9178 | Test-MSE 351.0434 | Regret 0.0011 | Fair-Val 77.0465\n",
      "Epoch 030/50 | Train-Loss 0.7809 | Test-MSE 336.9950 | Regret 0.0010 | Fair-Val 68.8643\n",
      "Epoch 040/50 | Train-Loss 0.5975 | Test-MSE 319.5016 | Regret 0.0010 | Fair-Val 59.1517\n",
      "Epoch 050/50 | Train-Loss 0.4134 | Test-MSE 301.3780 | Regret 0.0011 | Fair-Val 49.2459\n",
      "Training finished in 141.15s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0011 | σ = 0.0000\n",
      "[                 MSE]  μ = 303.4032 | σ = 2.0252\n",
      "[            FAIRNESS]  μ = 50.9425 | σ = 1.6967\n",
      "[       TRAINING_TIME]  μ = 141.4015 | σ = 0.2543\n",
      "[              G0_MSE]  μ = 291.2585 | σ = 1.6207\n",
      "[              G1_MSE]  μ = 393.1436 | σ = 5.0141\n",
      "[     G0_DECISION_OBJ]  μ = 19.3719 | σ = 0.0180\n",
      "[     G1_DECISION_OBJ]  μ = 162.7403 | σ = 0.5003\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 1.5, 'Lambda': 0.01, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 3.6769 | Test-MSE 362.5739 | Regret 0.0277 | Fair-Val 85.7305\n",
      "Epoch 010/50 | Train-Loss 3.2993 | Test-MSE 356.2679 | Regret 0.0245 | Fair-Val 83.2533\n",
      "Epoch 020/50 | Train-Loss 2.8648 | Test-MSE 341.9106 | Regret 0.0213 | Fair-Val 77.6337\n",
      "Epoch 030/50 | Train-Loss 2.5849 | Test-MSE 326.5839 | Regret 0.0199 | Fair-Val 71.1262\n",
      "Epoch 040/50 | Train-Loss 2.3485 | Test-MSE 314.2559 | Regret 0.0188 | Fair-Val 64.7687\n",
      "Epoch 050/50 | Train-Loss 2.1387 | Test-MSE 303.5609 | Regret 0.0178 | Fair-Val 59.0033\n",
      "Training finished in 141.87s.\n",
      "Epoch 001/50 | Train-Loss 3.6871 | Test-MSE 362.6345 | Regret 0.0277 | Fair-Val 85.7645\n",
      "Epoch 010/50 | Train-Loss 3.3577 | Test-MSE 357.2065 | Regret 0.0249 | Fair-Val 82.3102\n",
      "Epoch 020/50 | Train-Loss 2.8775 | Test-MSE 342.6941 | Regret 0.0217 | Fair-Val 76.0623\n",
      "Epoch 030/50 | Train-Loss 2.5942 | Test-MSE 326.7136 | Regret 0.0202 | Fair-Val 69.5661\n",
      "Epoch 040/50 | Train-Loss 2.3618 | Test-MSE 314.2624 | Regret 0.0193 | Fair-Val 63.5351\n",
      "Epoch 050/50 | Train-Loss 2.1584 | Test-MSE 304.0985 | Regret 0.0183 | Fair-Val 58.2374\n",
      "Training finished in 142.41s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0181 | σ = 0.0002\n",
      "[                 MSE]  μ = 303.8297 | σ = 0.2688\n",
      "[            FAIRNESS]  μ = 58.6204 | σ = 0.3829\n",
      "[       TRAINING_TIME]  μ = 142.1434 | σ = 0.2711\n",
      "[              G0_MSE]  μ = 289.8546 | σ = 0.3601\n",
      "[              G1_MSE]  μ = 407.0953 | σ = 0.4058\n",
      "[     G0_DECISION_OBJ]  μ = 18.6516 | σ = 0.0103\n",
      "[     G1_DECISION_OBJ]  μ = 60.0116 | σ = 0.1522\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 2, 'Lambda': 0.01, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 78.0992 | Test-MSE 362.5725 | Regret 0.3399 | Fair-Val 85.7349\n",
      "Epoch 010/50 | Train-Loss 67.8370 | Test-MSE 355.8869 | Regret 0.2944 | Fair-Val 83.3335\n",
      "Epoch 020/50 | Train-Loss 57.2882 | Test-MSE 341.2219 | Regret 0.2517 | Fair-Val 78.1335\n",
      "Epoch 030/50 | Train-Loss 51.3623 | Test-MSE 328.2771 | Regret 0.2309 | Fair-Val 72.7929\n",
      "Epoch 040/50 | Train-Loss 46.5232 | Test-MSE 319.2956 | Regret 0.2163 | Fair-Val 68.7009\n",
      "Epoch 050/50 | Train-Loss 42.0696 | Test-MSE 311.5619 | Regret 0.2009 | Fair-Val 66.0020\n",
      "Training finished in 98.57s.\n",
      "Epoch 001/50 | Train-Loss 78.3927 | Test-MSE 362.6293 | Regret 0.3406 | Fair-Val 85.7641\n",
      "Epoch 010/50 | Train-Loss 69.5922 | Test-MSE 356.7748 | Regret 0.3013 | Fair-Val 82.4002\n",
      "Epoch 020/50 | Train-Loss 58.0174 | Test-MSE 341.9749 | Regret 0.2571 | Fair-Val 76.6342\n",
      "Epoch 030/50 | Train-Loss 52.0906 | Test-MSE 327.3682 | Regret 0.2358 | Fair-Val 71.2918\n",
      "Epoch 040/50 | Train-Loss 47.4411 | Test-MSE 318.4992 | Regret 0.2204 | Fair-Val 67.5297\n",
      "Epoch 050/50 | Train-Loss 42.6931 | Test-MSE 312.0947 | Regret 0.2047 | Fair-Val 65.1797\n",
      "Training finished in 99.16s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.2028 | σ = 0.0019\n",
      "[                 MSE]  μ = 311.8283 | σ = 0.2664\n",
      "[            FAIRNESS]  μ = 65.5909 | σ = 0.4112\n",
      "[       TRAINING_TIME]  μ = 98.8667 | σ = 0.2961\n",
      "[              G0_MSE]  μ = 296.1914 | σ = 0.3644\n",
      "[              G1_MSE]  μ = 427.3732 | σ = 0.4579\n",
      "[     G0_DECISION_OBJ]  μ = 19.3381 | σ = 0.0207\n",
      "[     G1_DECISION_OBJ]  μ = 25.7865 | σ = 0.0988\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 0.5, 'Lambda': 1, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 29.5290 | Test-MSE 362.5895 | Regret 0.0654 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 27.4569 | Test-MSE 357.4233 | Regret 0.0612 | Fair-Val 0.0049\n",
      "Epoch 020/50 | Train-Loss 23.6341 | Test-MSE 344.3476 | Regret 0.0545 | Fair-Val 0.0047\n",
      "Epoch 030/50 | Train-Loss 21.6693 | Test-MSE 331.0603 | Regret 0.0516 | Fair-Val 0.0045\n",
      "Epoch 040/50 | Train-Loss 20.1626 | Test-MSE 323.7416 | Regret 0.0489 | Fair-Val 0.0044\n",
      "Epoch 050/50 | Train-Loss 18.4967 | Test-MSE 319.2120 | Regret 0.0453 | Fair-Val 0.0044\n",
      "Training finished in 81.33s.\n",
      "Epoch 001/50 | Train-Loss 29.5455 | Test-MSE 362.6480 | Regret 0.0654 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 27.4032 | Test-MSE 358.0491 | Regret 0.0612 | Fair-Val 0.0048\n",
      "Epoch 020/50 | Train-Loss 23.6771 | Test-MSE 344.9600 | Regret 0.0546 | Fair-Val 0.0045\n",
      "Epoch 030/50 | Train-Loss 21.8386 | Test-MSE 332.4199 | Regret 0.0520 | Fair-Val 0.0043\n",
      "Epoch 040/50 | Train-Loss 20.1193 | Test-MSE 325.2561 | Regret 0.0494 | Fair-Val 0.0042\n",
      "Epoch 050/50 | Train-Loss 18.6194 | Test-MSE 320.5254 | Regret 0.0459 | Fair-Val 0.0042\n",
      "Training finished in 80.56s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0456 | σ = 0.0003\n",
      "[                 MSE]  μ = 319.8687 | σ = 0.6567\n",
      "[            FAIRNESS]  μ = 0.0043 | σ = 0.0001\n",
      "[       TRAINING_TIME]  μ = 80.9447 | σ = 0.3852\n",
      "[              G0_MSE]  μ = 303.2927 | σ = 0.7689\n",
      "[              G1_MSE]  μ = 442.3526 | σ = 0.1722\n",
      "[     G0_DECISION_OBJ]  μ = 32.4196 | σ = 0.1054\n",
      "[     G1_DECISION_OBJ]  μ = 203.4987 | σ = 2.4547\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 0.8, 'Lambda': 1, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 0.0861 | Test-MSE 362.5832 | Regret 0.0012 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 0.0786 | Test-MSE 357.6303 | Regret 0.0012 | Fair-Val 0.0049\n",
      "Epoch 020/50 | Train-Loss 0.0676 | Test-MSE 345.3650 | Regret 0.0010 | Fair-Val 0.0047\n",
      "Epoch 030/50 | Train-Loss 0.0617 | Test-MSE 333.0560 | Regret 0.0010 | Fair-Val 0.0044\n",
      "Epoch 040/50 | Train-Loss 0.0578 | Test-MSE 324.1263 | Regret 0.0009 | Fair-Val 0.0041\n",
      "Epoch 050/50 | Train-Loss 0.0546 | Test-MSE 316.4451 | Regret 0.0009 | Fair-Val 0.0040\n",
      "Training finished in 140.96s.\n",
      "Epoch 001/50 | Train-Loss 0.0862 | Test-MSE 362.6317 | Regret 0.0012 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 0.0785 | Test-MSE 357.7331 | Regret 0.0012 | Fair-Val 0.0048\n",
      "Epoch 020/50 | Train-Loss 0.0672 | Test-MSE 344.6810 | Regret 0.0010 | Fair-Val 0.0045\n",
      "Epoch 030/50 | Train-Loss 0.0621 | Test-MSE 329.9127 | Regret 0.0010 | Fair-Val 0.0042\n",
      "Epoch 040/50 | Train-Loss 0.0585 | Test-MSE 322.1890 | Regret 0.0009 | Fair-Val 0.0041\n",
      "Epoch 050/50 | Train-Loss 0.0559 | Test-MSE 318.4345 | Regret 0.0009 | Fair-Val 0.0040\n",
      "Training finished in 142.37s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0009 | σ = 0.0000\n",
      "[                 MSE]  μ = 317.4398 | σ = 0.9947\n",
      "[            FAIRNESS]  μ = 0.0040 | σ = 0.0000\n",
      "[       TRAINING_TIME]  μ = 141.6674 | σ = 0.7055\n",
      "[              G0_MSE]  μ = 301.6455 | σ = 0.9431\n",
      "[              G1_MSE]  μ = 434.1478 | σ = 1.3763\n",
      "[     G0_DECISION_OBJ]  μ = 19.4126 | σ = 0.0115\n",
      "[     G1_DECISION_OBJ]  μ = 160.3410 | σ = 0.1203\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 1.5, 'Lambda': 1, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 2.6757 | Test-MSE 362.5724 | Regret 0.0277 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 2.3416 | Test-MSE 356.0780 | Regret 0.0244 | Fair-Val 0.0049\n",
      "Epoch 020/50 | Train-Loss 2.0071 | Test-MSE 341.8538 | Regret 0.0213 | Fair-Val 0.0047\n",
      "Epoch 030/50 | Train-Loss 1.8335 | Test-MSE 328.4389 | Regret 0.0198 | Fair-Val 0.0045\n",
      "Epoch 040/50 | Train-Loss 1.6900 | Test-MSE 319.9103 | Regret 0.0185 | Fair-Val 0.0042\n",
      "Epoch 050/50 | Train-Loss 1.5445 | Test-MSE 315.0999 | Regret 0.0171 | Fair-Val 0.0041\n",
      "Training finished in 142.30s.\n",
      "Epoch 001/50 | Train-Loss 2.6853 | Test-MSE 362.6337 | Regret 0.0277 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 2.4037 | Test-MSE 357.0994 | Regret 0.0249 | Fair-Val 0.0048\n",
      "Epoch 020/50 | Train-Loss 2.0307 | Test-MSE 342.7585 | Regret 0.0216 | Fair-Val 0.0045\n",
      "Epoch 030/50 | Train-Loss 1.8502 | Test-MSE 328.8999 | Regret 0.0200 | Fair-Val 0.0043\n",
      "Epoch 040/50 | Train-Loss 1.7086 | Test-MSE 319.9500 | Regret 0.0188 | Fair-Val 0.0041\n",
      "Epoch 050/50 | Train-Loss 1.5568 | Test-MSE 315.4918 | Regret 0.0174 | Fair-Val 0.0041\n",
      "Training finished in 142.73s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0173 | σ = 0.0001\n",
      "[                 MSE]  μ = 315.2958 | σ = 0.1959\n",
      "[            FAIRNESS]  μ = 0.0041 | σ = 0.0000\n",
      "[       TRAINING_TIME]  μ = 142.5150 | σ = 0.2125\n",
      "[              G0_MSE]  μ = 299.3566 | σ = 0.2546\n",
      "[              G1_MSE]  μ = 433.0751 | σ = 0.2381\n",
      "[     G0_DECISION_OBJ]  μ = 18.6863 | σ = 0.0131\n",
      "[     G1_DECISION_OBJ]  μ = 60.5554 | σ = 0.1880\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 2, 'Lambda': 1, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 77.0980 | Test-MSE 362.5725 | Regret 0.3399 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 66.8870 | Test-MSE 355.8980 | Regret 0.2944 | Fair-Val 0.0049\n",
      "Epoch 020/50 | Train-Loss 56.4075 | Test-MSE 341.4316 | Regret 0.2517 | Fair-Val 0.0047\n",
      "Epoch 030/50 | Train-Loss 50.4344 | Test-MSE 328.5994 | Regret 0.2305 | Fair-Val 0.0045\n",
      "Epoch 040/50 | Train-Loss 45.5905 | Test-MSE 319.6813 | Regret 0.2158 | Fair-Val 0.0042\n",
      "Epoch 050/50 | Train-Loss 41.0735 | Test-MSE 311.9647 | Regret 0.1997 | Fair-Val 0.0041\n",
      "Training finished in 98.99s.\n",
      "Epoch 001/50 | Train-Loss 77.3910 | Test-MSE 362.6294 | Regret 0.3406 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 68.6861 | Test-MSE 356.8179 | Regret 0.3015 | Fair-Val 0.0048\n",
      "Epoch 020/50 | Train-Loss 57.1745 | Test-MSE 342.0374 | Regret 0.2571 | Fair-Val 0.0045\n",
      "Epoch 030/50 | Train-Loss 51.2730 | Test-MSE 327.4864 | Regret 0.2355 | Fair-Val 0.0043\n",
      "Epoch 040/50 | Train-Loss 46.6679 | Test-MSE 318.3195 | Regret 0.2199 | Fair-Val 0.0041\n",
      "Epoch 050/50 | Train-Loss 41.8896 | Test-MSE 312.6265 | Regret 0.2040 | Fair-Val 0.0040\n",
      "Training finished in 98.14s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.2018 | σ = 0.0022\n",
      "[                 MSE]  μ = 312.2956 | σ = 0.3309\n",
      "[            FAIRNESS]  μ = 0.0041 | σ = 0.0001\n",
      "[       TRAINING_TIME]  μ = 98.5636 | σ = 0.4247\n",
      "[              G0_MSE]  μ = 296.5281 | σ = 0.4315\n",
      "[              G1_MSE]  μ = 428.8059 | σ = 0.4122\n",
      "[     G0_DECISION_OBJ]  μ = 19.3409 | σ = 0.0248\n",
      "[     G1_DECISION_OBJ]  μ = 25.8262 | σ = 0.1038\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 0.5, 'Lambda': 10, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 29.5806 | Test-MSE 362.5894 | Regret 0.0654 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 27.5217 | Test-MSE 357.4788 | Regret 0.0612 | Fair-Val 0.0049\n",
      "Epoch 020/50 | Train-Loss 23.7018 | Test-MSE 344.3711 | Regret 0.0545 | Fair-Val 0.0047\n",
      "Epoch 030/50 | Train-Loss 21.7200 | Test-MSE 331.2557 | Regret 0.0516 | Fair-Val 0.0045\n",
      "Epoch 040/50 | Train-Loss 20.2102 | Test-MSE 324.0468 | Regret 0.0489 | Fair-Val 0.0043\n",
      "Epoch 050/50 | Train-Loss 18.5483 | Test-MSE 319.3578 | Regret 0.0454 | Fair-Val 0.0043\n",
      "Training finished in 80.75s.\n",
      "Epoch 001/50 | Train-Loss 29.5971 | Test-MSE 362.6469 | Regret 0.0654 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 27.5017 | Test-MSE 358.2081 | Regret 0.0613 | Fair-Val 0.0048\n",
      "Epoch 020/50 | Train-Loss 23.7570 | Test-MSE 345.1986 | Regret 0.0547 | Fair-Val 0.0045\n",
      "Epoch 030/50 | Train-Loss 21.8875 | Test-MSE 332.5205 | Regret 0.0520 | Fair-Val 0.0043\n",
      "Epoch 040/50 | Train-Loss 20.1413 | Test-MSE 325.0424 | Regret 0.0494 | Fair-Val 0.0042\n",
      "Epoch 050/50 | Train-Loss 18.6347 | Test-MSE 320.2277 | Regret 0.0460 | Fair-Val 0.0042\n",
      "Training finished in 81.16s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0457 | σ = 0.0003\n",
      "[                 MSE]  μ = 319.7928 | σ = 0.4349\n",
      "[            FAIRNESS]  μ = 0.0043 | σ = 0.0001\n",
      "[       TRAINING_TIME]  μ = 80.9586 | σ = 0.2039\n",
      "[              G0_MSE]  μ = 303.2581 | σ = 0.5299\n",
      "[              G1_MSE]  μ = 441.9719 | σ = 0.2668\n",
      "[     G0_DECISION_OBJ]  μ = 32.4184 | σ = 0.1362\n",
      "[     G1_DECISION_OBJ]  μ = 203.5112 | σ = 2.3498\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 0.8, 'Lambda': 10, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 0.1377 | Test-MSE 362.6125 | Regret 0.0012 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 0.1275 | Test-MSE 358.6628 | Regret 0.0012 | Fair-Val 0.0049\n",
      "Epoch 020/50 | Train-Loss 0.1099 | Test-MSE 347.7792 | Regret 0.0010 | Fair-Val 0.0046\n",
      "Epoch 030/50 | Train-Loss 0.0960 | Test-MSE 335.2880 | Regret 0.0010 | Fair-Val 0.0042\n",
      "Epoch 040/50 | Train-Loss 0.0836 | Test-MSE 322.4646 | Regret 0.0010 | Fair-Val 0.0038\n",
      "Epoch 050/50 | Train-Loss 0.0740 | Test-MSE 310.3028 | Regret 0.0009 | Fair-Val 0.0033\n",
      "Training finished in 141.99s.\n",
      "Epoch 001/50 | Train-Loss 0.1378 | Test-MSE 362.6402 | Regret 0.0013 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 0.1274 | Test-MSE 359.2304 | Regret 0.0012 | Fair-Val 0.0048\n",
      "Epoch 020/50 | Train-Loss 0.1089 | Test-MSE 348.3262 | Regret 0.0010 | Fair-Val 0.0044\n",
      "Epoch 030/50 | Train-Loss 0.0959 | Test-MSE 336.0056 | Regret 0.0010 | Fair-Val 0.0040\n",
      "Epoch 040/50 | Train-Loss 0.0831 | Test-MSE 321.1830 | Regret 0.0010 | Fair-Val 0.0036\n",
      "Epoch 050/50 | Train-Loss 0.0740 | Test-MSE 308.5840 | Regret 0.0010 | Fair-Val 0.0032\n",
      "Training finished in 141.25s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0010 | σ = 0.0000\n",
      "[                 MSE]  μ = 309.4434 | σ = 0.8594\n",
      "[            FAIRNESS]  μ = 0.0032 | σ = 0.0001\n",
      "[       TRAINING_TIME]  μ = 141.6192 | σ = 0.3727\n",
      "[              G0_MSE]  μ = 295.7136 | σ = 0.7023\n",
      "[              G1_MSE]  μ = 410.8959 | σ = 2.0203\n",
      "[     G0_DECISION_OBJ]  μ = 19.4264 | σ = 0.0239\n",
      "[     G1_DECISION_OBJ]  μ = 161.9946 | σ = 0.0201\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 1.5, 'Lambda': 10, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 2.7273 | Test-MSE 362.5724 | Regret 0.0277 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 2.3910 | Test-MSE 356.1021 | Regret 0.0244 | Fair-Val 0.0049\n",
      "Epoch 020/50 | Train-Loss 2.0512 | Test-MSE 342.0760 | Regret 0.0213 | Fair-Val 0.0047\n",
      "Epoch 030/50 | Train-Loss 1.8700 | Test-MSE 328.7970 | Regret 0.0197 | Fair-Val 0.0044\n",
      "Epoch 040/50 | Train-Loss 1.7203 | Test-MSE 320.4445 | Regret 0.0185 | Fair-Val 0.0042\n",
      "Epoch 050/50 | Train-Loss 1.5727 | Test-MSE 313.1598 | Regret 0.0171 | Fair-Val 0.0040\n",
      "Training finished in 142.40s.\n",
      "Epoch 001/50 | Train-Loss 2.7369 | Test-MSE 362.6340 | Regret 0.0277 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 2.4498 | Test-MSE 357.0334 | Regret 0.0248 | Fair-Val 0.0048\n",
      "Epoch 020/50 | Train-Loss 2.0729 | Test-MSE 342.5909 | Regret 0.0216 | Fair-Val 0.0045\n",
      "Epoch 030/50 | Train-Loss 1.8906 | Test-MSE 329.2298 | Regret 0.0201 | Fair-Val 0.0043\n",
      "Epoch 040/50 | Train-Loss 1.7485 | Test-MSE 320.6460 | Regret 0.0189 | Fair-Val 0.0041\n",
      "Epoch 050/50 | Train-Loss 1.5972 | Test-MSE 314.3281 | Regret 0.0175 | Fair-Val 0.0040\n",
      "Training finished in 141.63s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0173 | σ = 0.0002\n",
      "[                 MSE]  μ = 313.7439 | σ = 0.5842\n",
      "[            FAIRNESS]  μ = 0.0040 | σ = 0.0000\n",
      "[       TRAINING_TIME]  μ = 142.0141 | σ = 0.3854\n",
      "[              G0_MSE]  μ = 298.0520 | σ = 0.5898\n",
      "[              G1_MSE]  μ = 429.6955 | σ = 0.5423\n",
      "[     G0_DECISION_OBJ]  μ = 18.6747 | σ = 0.0135\n",
      "[     G1_DECISION_OBJ]  μ = 60.4899 | σ = 0.2188\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'finite-diff', 'Alpha': 2, 'Lambda': 10, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 77.1496 | Test-MSE 362.5725 | Regret 0.3399 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 66.9450 | Test-MSE 355.9105 | Regret 0.2944 | Fair-Val 0.0049\n",
      "Epoch 020/50 | Train-Loss 56.4491 | Test-MSE 341.3669 | Regret 0.2517 | Fair-Val 0.0047\n",
      "Epoch 030/50 | Train-Loss 50.5408 | Test-MSE 328.3486 | Regret 0.2307 | Fair-Val 0.0045\n",
      "Epoch 040/50 | Train-Loss 45.7241 | Test-MSE 319.4220 | Regret 0.2160 | Fair-Val 0.0042\n",
      "Epoch 050/50 | Train-Loss 41.2601 | Test-MSE 311.7899 | Regret 0.2002 | Fair-Val 0.0041\n",
      "Training finished in 98.51s.\n",
      "Epoch 001/50 | Train-Loss 77.4425 | Test-MSE 362.6294 | Regret 0.3406 | Fair-Val 0.0050\n",
      "Epoch 010/50 | Train-Loss 68.7362 | Test-MSE 356.8137 | Regret 0.3014 | Fair-Val 0.0048\n",
      "Epoch 020/50 | Train-Loss 57.2165 | Test-MSE 342.0474 | Regret 0.2571 | Fair-Val 0.0045\n",
      "Epoch 030/50 | Train-Loss 51.2337 | Test-MSE 328.1638 | Regret 0.2353 | Fair-Val 0.0043\n",
      "Epoch 040/50 | Train-Loss 46.6095 | Test-MSE 319.0580 | Regret 0.2198 | Fair-Val 0.0041\n",
      "Epoch 050/50 | Train-Loss 41.8230 | Test-MSE 312.4857 | Regret 0.2037 | Fair-Val 0.0040\n",
      "Training finished in 99.26s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.2020 | σ = 0.0018\n",
      "[                 MSE]  μ = 312.1378 | σ = 0.3479\n",
      "[            FAIRNESS]  μ = 0.0041 | σ = 0.0000\n",
      "[       TRAINING_TIME]  μ = 98.8833 | σ = 0.3782\n",
      "[              G0_MSE]  μ = 296.3928 | σ = 0.4328\n",
      "[              G1_MSE]  μ = 428.4815 | σ = 0.2800\n",
      "[     G0_DECISION_OBJ]  μ = 19.3359 | σ = 0.0230\n",
      "[     G1_DECISION_OBJ]  μ = 25.8115 | σ = 0.1082\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 0.5, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 3484.1250 | Test-MSE 362.6414 | Regret 0.1304 | Fair-Val 500.9474\n",
      "Epoch 010/50 | Train-Loss 3481.1992 | Test-MSE 362.2736 | Regret 0.1301 | Fair-Val 500.4165\n",
      "Epoch 020/50 | Train-Loss 3436.1738 | Test-MSE 360.3734 | Regret 0.1279 | Fair-Val 497.7166\n",
      "Epoch 030/50 | Train-Loss 3392.9707 | Test-MSE 358.2683 | Regret 0.1257 | Fair-Val 494.7364\n",
      "Epoch 040/50 | Train-Loss 3344.1855 | Test-MSE 355.1143 | Regret 0.1233 | Fair-Val 490.2549\n",
      "Epoch 050/50 | Train-Loss 3282.2812 | Test-MSE 351.6589 | Regret 0.1209 | Fair-Val 485.3162\n",
      "Training finished in 2.57s.\n",
      "Epoch 001/50 | Train-Loss 3488.4980 | Test-MSE 362.6854 | Regret 0.1304 | Fair-Val 501.0144\n",
      "Epoch 010/50 | Train-Loss 3475.3027 | Test-MSE 361.8093 | Regret 0.1293 | Fair-Val 499.7548\n",
      "Epoch 020/50 | Train-Loss 3450.2812 | Test-MSE 360.5168 | Regret 0.1276 | Fair-Val 497.9164\n",
      "Epoch 030/50 | Train-Loss 3417.4043 | Test-MSE 358.5854 | Regret 0.1259 | Fair-Val 495.1836\n",
      "Epoch 040/50 | Train-Loss 3360.7324 | Test-MSE 355.6608 | Regret 0.1237 | Fair-Val 491.0551\n",
      "Epoch 050/50 | Train-Loss 3323.9395 | Test-MSE 352.7563 | Regret 0.1219 | Fair-Val 486.8796\n",
      "Training finished in 2.45s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.1214 | σ = 0.0005\n",
      "[                 MSE]  μ = 352.2076 | σ = 0.5487\n",
      "[            FAIRNESS]  μ = 486.0979 | σ = 0.7817\n",
      "[       TRAINING_TIME]  μ = 2.5095 | σ = 0.0644\n",
      "[              G0_MSE]  μ = 333.0872 | σ = 0.5852\n",
      "[              G1_MSE]  μ = 493.4936 | σ = 0.2789\n",
      "[     G0_DECISION_OBJ]  μ = 36.5983 | σ = 0.1099\n",
      "[     G1_DECISION_OBJ]  μ = 60.9883 | σ = 0.7397\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 0.8, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 146.7539 | Test-MSE 362.6259 | Regret 0.0064 | Fair-Val 500.9229\n",
      "Epoch 010/50 | Train-Loss 143.6875 | Test-MSE 361.4810 | Regret 0.0063 | Fair-Val 499.3077\n",
      "Epoch 020/50 | Train-Loss 139.0723 | Test-MSE 358.7428 | Regret 0.0061 | Fair-Val 495.4354\n",
      "Epoch 030/50 | Train-Loss 133.2617 | Test-MSE 354.9843 | Regret 0.0059 | Fair-Val 490.1050\n",
      "Epoch 040/50 | Train-Loss 127.8652 | Test-MSE 350.7501 | Regret 0.0056 | Fair-Val 484.0417\n",
      "Epoch 050/50 | Train-Loss 121.6875 | Test-MSE 345.5766 | Regret 0.0054 | Fair-Val 476.5579\n",
      "Training finished in 2.55s.\n",
      "Epoch 001/50 | Train-Loss 147.0547 | Test-MSE 362.6788 | Regret 0.0064 | Fair-Val 501.0052\n",
      "Epoch 010/50 | Train-Loss 144.4062 | Test-MSE 361.3517 | Regret 0.0063 | Fair-Val 499.0985\n",
      "Epoch 020/50 | Train-Loss 139.7578 | Test-MSE 358.8647 | Regret 0.0061 | Fair-Val 495.6393\n",
      "Epoch 030/50 | Train-Loss 136.0156 | Test-MSE 355.9258 | Regret 0.0059 | Fair-Val 491.4556\n",
      "Epoch 040/50 | Train-Loss 130.7910 | Test-MSE 351.9167 | Regret 0.0057 | Fair-Val 485.7068\n",
      "Epoch 050/50 | Train-Loss 124.7676 | Test-MSE 346.7641 | Regret 0.0055 | Fair-Val 478.2675\n",
      "Training finished in 2.54s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0054 | σ = 0.0000\n",
      "[                 MSE]  μ = 346.1704 | σ = 0.5937\n",
      "[            FAIRNESS]  μ = 477.4127 | σ = 0.8548\n",
      "[       TRAINING_TIME]  μ = 2.5452 | σ = 0.0018\n",
      "[              G0_MSE]  μ = 327.4625 | σ = 0.6569\n",
      "[              G1_MSE]  μ = 484.4075 | σ = 0.1275\n",
      "[     G0_DECISION_OBJ]  μ = 28.4443 | σ = 0.0003\n",
      "[     G1_DECISION_OBJ]  μ = 45.7645 | σ = 0.0897\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 1.5, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 81.1167 | Test-MSE 362.6613 | Regret 0.0561 | Fair-Val 500.9788\n",
      "Epoch 010/50 | Train-Loss 78.1714 | Test-MSE 360.9979 | Regret 0.0542 | Fair-Val 498.9757\n",
      "Epoch 020/50 | Train-Loss 71.7758 | Test-MSE 353.2081 | Regret 0.0503 | Fair-Val 490.5750\n",
      "Epoch 030/50 | Train-Loss 75.2107 | Test-MSE 343.7810 | Regret 0.0527 | Fair-Val 481.1404\n",
      "Epoch 040/50 | Train-Loss 86.0432 | Test-MSE 335.3230 | Regret 0.0595 | Fair-Val 472.6032\n",
      "Epoch 050/50 | Train-Loss 98.5634 | Test-MSE 328.5008 | Regret 0.0672 | Fair-Val 464.6288\n",
      "Training finished in 2.55s.\n",
      "Epoch 001/50 | Train-Loss 81.3793 | Test-MSE 362.7001 | Regret 0.0562 | Fair-Val 501.0388\n",
      "Epoch 010/50 | Train-Loss 79.5596 | Test-MSE 361.3694 | Regret 0.0549 | Fair-Val 499.6854\n",
      "Epoch 020/50 | Train-Loss 75.5957 | Test-MSE 354.6548 | Regret 0.0521 | Fair-Val 492.7235\n",
      "Epoch 030/50 | Train-Loss 78.5220 | Test-MSE 345.4840 | Regret 0.0538 | Fair-Val 483.5052\n",
      "Epoch 040/50 | Train-Loss 87.9640 | Test-MSE 336.8737 | Regret 0.0597 | Fair-Val 474.7084\n",
      "Epoch 050/50 | Train-Loss 100.2896 | Test-MSE 330.1516 | Regret 0.0676 | Fair-Val 466.8882\n",
      "Training finished in 2.45s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0674 | σ = 0.0002\n",
      "[                 MSE]  μ = 329.3262 | σ = 0.8254\n",
      "[            FAIRNESS]  μ = 465.7585 | σ = 1.1297\n",
      "[       TRAINING_TIME]  μ = 2.5016 | σ = 0.0522\n",
      "[              G0_MSE]  μ = 310.3242 | σ = 1.0815\n",
      "[              G1_MSE]  μ = 469.7374 | σ = 1.0666\n",
      "[     G0_DECISION_OBJ]  μ = 21.1028 | σ = 0.0272\n",
      "[     G1_DECISION_OBJ]  μ = 30.5253 | σ = 0.1266\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 2, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 77.0923 | Test-MSE 362.6006 | Regret 0.3403 | Fair-Val 500.8942\n",
      "Epoch 010/50 | Train-Loss 68.6615 | Test-MSE 357.4160 | Regret 0.3032 | Fair-Val 494.2075\n",
      "Epoch 020/50 | Train-Loss 60.5106 | Test-MSE 344.6001 | Regret 0.2683 | Fair-Val 478.9455\n",
      "Epoch 030/50 | Train-Loss 62.4353 | Test-MSE 332.3436 | Regret 0.2788 | Fair-Val 465.5102\n",
      "Epoch 040/50 | Train-Loss 70.9525 | Test-MSE 323.0895 | Regret 0.3154 | Fair-Val 455.7652\n",
      "Epoch 050/50 | Train-Loss 78.8211 | Test-MSE 315.9119 | Regret 0.3477 | Fair-Val 447.5601\n",
      "Training finished in 2.54s.\n",
      "Epoch 001/50 | Train-Loss 77.3852 | Test-MSE 362.6745 | Regret 0.3412 | Fair-Val 501.0034\n",
      "Epoch 010/50 | Train-Loss 71.1480 | Test-MSE 358.5545 | Regret 0.3118 | Fair-Val 495.8124\n",
      "Epoch 020/50 | Train-Loss 61.8084 | Test-MSE 346.3418 | Regret 0.2756 | Fair-Val 481.2627\n",
      "Epoch 030/50 | Train-Loss 61.9149 | Test-MSE 333.7208 | Regret 0.2788 | Fair-Val 467.1066\n",
      "Epoch 040/50 | Train-Loss 68.8438 | Test-MSE 323.8809 | Regret 0.3068 | Fair-Val 456.6439\n",
      "Epoch 050/50 | Train-Loss 77.4274 | Test-MSE 316.3334 | Regret 0.3409 | Fair-Val 448.0480\n",
      "Training finished in 2.58s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.3443 | σ = 0.0034\n",
      "[                 MSE]  μ = 316.1227 | σ = 0.2108\n",
      "[            FAIRNESS]  μ = 447.8040 | σ = 0.2440\n",
      "[       TRAINING_TIME]  μ = 2.5612 | σ = 0.0170\n",
      "[              G0_MSE]  μ = 298.4520 | σ = 0.4777\n",
      "[              G1_MSE]  μ = 446.6959 | σ = 1.7614\n",
      "[     G0_DECISION_OBJ]  μ = 18.7704 | σ = 0.0191\n",
      "[     G1_DECISION_OBJ]  μ = 25.8805 | σ = 0.0969\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 0.5, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 4014.4792 | Test-MSE 362.6400 | Regret 0.1303 | Fair-Val 500.9454\n",
      "Epoch 010/50 | Train-Loss 4007.9062 | Test-MSE 362.1891 | Regret 0.1300 | Fair-Val 500.2964\n",
      "Epoch 020/50 | Train-Loss 3959.1533 | Test-MSE 360.2401 | Regret 0.1278 | Fair-Val 497.5286\n",
      "Epoch 030/50 | Train-Loss 3915.5613 | Test-MSE 358.2193 | Regret 0.1257 | Fair-Val 494.6686\n",
      "Epoch 040/50 | Train-Loss 3852.2710 | Test-MSE 354.6702 | Regret 0.1229 | Fair-Val 489.6397\n",
      "Epoch 050/50 | Train-Loss 3786.2278 | Test-MSE 351.1391 | Regret 0.1205 | Fair-Val 484.5764\n",
      "Training finished in 2.47s.\n",
      "Epoch 001/50 | Train-Loss 4019.0820 | Test-MSE 362.6852 | Regret 0.1304 | Fair-Val 501.0140\n",
      "Epoch 010/50 | Train-Loss 4003.9775 | Test-MSE 361.8149 | Regret 0.1293 | Fair-Val 499.7623\n",
      "Epoch 020/50 | Train-Loss 3977.6655 | Test-MSE 360.5142 | Regret 0.1276 | Fair-Val 497.9114\n",
      "Epoch 030/50 | Train-Loss 3934.5286 | Test-MSE 358.2383 | Regret 0.1256 | Fair-Val 494.6989\n",
      "Epoch 040/50 | Train-Loss 3875.5720 | Test-MSE 355.3830 | Regret 0.1235 | Fair-Val 490.6764\n",
      "Epoch 050/50 | Train-Loss 3831.1660 | Test-MSE 352.2267 | Regret 0.1215 | Fair-Val 486.1409\n",
      "Training finished in 2.58s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.1210 | σ = 0.0005\n",
      "[                 MSE]  μ = 351.6829 | σ = 0.5438\n",
      "[            FAIRNESS]  μ = 485.3586 | σ = 0.7823\n",
      "[       TRAINING_TIME]  μ = 2.5285 | σ = 0.0536\n",
      "[              G0_MSE]  μ = 332.6284 | σ = 0.5777\n",
      "[              G1_MSE]  μ = 492.4815 | σ = 0.2934\n",
      "[     G0_DECISION_OBJ]  μ = 36.7818 | σ = 0.1487\n",
      "[     G1_DECISION_OBJ]  μ = 61.4132 | σ = 0.9478\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 0.8, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 677.1081 | Test-MSE 362.6176 | Regret 0.0064 | Fair-Val 500.9119\n",
      "Epoch 010/50 | Train-Loss 669.8983 | Test-MSE 361.0181 | Regret 0.0063 | Fair-Val 498.6731\n",
      "Epoch 020/50 | Train-Loss 658.5507 | Test-MSE 357.7584 | Regret 0.0060 | Fair-Val 494.0699\n",
      "Epoch 030/50 | Train-Loss 644.4033 | Test-MSE 353.2069 | Regret 0.0058 | Fair-Val 487.6477\n",
      "Epoch 040/50 | Train-Loss 628.8154 | Test-MSE 347.5128 | Regret 0.0055 | Fair-Val 479.5417\n",
      "Epoch 050/50 | Train-Loss 610.6207 | Test-MSE 340.8615 | Regret 0.0053 | Fair-Val 470.0108\n",
      "Training finished in 2.56s.\n",
      "Epoch 001/50 | Train-Loss 677.6386 | Test-MSE 362.6769 | Regret 0.0064 | Fair-Val 501.0025\n",
      "Epoch 010/50 | Train-Loss 671.0871 | Test-MSE 360.8791 | Regret 0.0063 | Fair-Val 498.4463\n",
      "Epoch 020/50 | Train-Loss 661.1863 | Test-MSE 357.9244 | Regret 0.0060 | Fair-Val 494.3260\n",
      "Epoch 030/50 | Train-Loss 649.4090 | Test-MSE 353.7999 | Regret 0.0058 | Fair-Val 488.4861\n",
      "Epoch 040/50 | Train-Loss 633.9946 | Test-MSE 348.2827 | Regret 0.0056 | Fair-Val 480.6089\n",
      "Epoch 050/50 | Train-Loss 616.1694 | Test-MSE 341.3468 | Regret 0.0053 | Fair-Val 470.6949\n",
      "Training finished in 2.54s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0053 | σ = 0.0000\n",
      "[                 MSE]  μ = 341.1041 | σ = 0.2427\n",
      "[            FAIRNESS]  μ = 470.3528 | σ = 0.3420\n",
      "[       TRAINING_TIME]  μ = 2.5531 | σ = 0.0084\n",
      "[              G0_MSE]  μ = 323.0016 | σ = 0.3346\n",
      "[              G1_MSE]  μ = 474.8685 | σ = 0.4364\n",
      "[     G0_DECISION_OBJ]  μ = 28.5258 | σ = 0.0063\n",
      "[     G1_DECISION_OBJ]  μ = 46.0259 | σ = 0.0819\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 1.5, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 611.4709 | Test-MSE 362.5887 | Regret 0.0560 | Fair-Val 500.8776\n",
      "Epoch 010/50 | Train-Loss 593.4802 | Test-MSE 356.6353 | Regret 0.0499 | Fair-Val 493.1053\n",
      "Epoch 020/50 | Train-Loss 562.4342 | Test-MSE 341.0488 | Regret 0.0437 | Fair-Val 473.8741\n",
      "Epoch 030/50 | Train-Loss 532.1184 | Test-MSE 320.7731 | Regret 0.0431 | Fair-Val 449.1631\n",
      "Epoch 040/50 | Train-Loss 505.9128 | Test-MSE 299.4971 | Regret 0.0466 | Fair-Val 422.7597\n",
      "Epoch 050/50 | Train-Loss 481.5191 | Test-MSE 278.9139 | Regret 0.0519 | Fair-Val 395.3827\n",
      "Training finished in 2.47s.\n",
      "Epoch 001/50 | Train-Loss 611.9632 | Test-MSE 362.6438 | Regret 0.0561 | Fair-Val 500.9587\n",
      "Epoch 010/50 | Train-Loss 597.8909 | Test-MSE 357.6589 | Regret 0.0510 | Fair-Val 494.5033\n",
      "Epoch 020/50 | Train-Loss 566.7557 | Test-MSE 342.8155 | Regret 0.0446 | Fair-Val 476.1708\n",
      "Epoch 030/50 | Train-Loss 535.9580 | Test-MSE 322.4157 | Regret 0.0432 | Fair-Val 451.0157\n",
      "Epoch 040/50 | Train-Loss 506.0085 | Test-MSE 300.0065 | Regret 0.0454 | Fair-Val 422.9078\n",
      "Epoch 050/50 | Train-Loss 479.0292 | Test-MSE 278.0536 | Regret 0.0497 | Fair-Val 393.8415\n",
      "Training finished in 2.55s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0508 | σ = 0.0011\n",
      "[                 MSE]  μ = 278.4838 | σ = 0.4302\n",
      "[            FAIRNESS]  μ = 394.6121 | σ = 0.7706\n",
      "[       TRAINING_TIME]  μ = 2.5128 | σ = 0.0386\n",
      "[              G0_MSE]  μ = 264.4440 | σ = 0.0047\n",
      "[              G1_MSE]  μ = 382.2274 | σ = 3.5742\n",
      "[     G0_DECISION_OBJ]  μ = 20.9931 | σ = 0.0476\n",
      "[     G1_DECISION_OBJ]  μ = 29.6984 | σ = 0.1587\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 2, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 607.4465 | Test-MSE 362.5714 | Regret 0.3399 | Fair-Val 500.8536\n",
      "Epoch 010/50 | Train-Loss 587.4289 | Test-MSE 355.9027 | Regret 0.2950 | Fair-Val 492.1368\n",
      "Epoch 020/50 | Train-Loss 553.4020 | Test-MSE 338.8700 | Regret 0.2536 | Fair-Val 470.8798\n",
      "Epoch 030/50 | Train-Loss 518.3022 | Test-MSE 315.8453 | Regret 0.2477 | Fair-Val 442.1220\n",
      "Epoch 040/50 | Train-Loss 484.4910 | Test-MSE 290.1938 | Regret 0.2666 | Fair-Val 409.4536\n",
      "Epoch 050/50 | Train-Loss 452.4846 | Test-MSE 265.0390 | Regret 0.2990 | Fair-Val 375.5843\n",
      "Training finished in 2.55s.\n",
      "Epoch 001/50 | Train-Loss 607.9691 | Test-MSE 362.6252 | Regret 0.3405 | Fair-Val 500.9315\n",
      "Epoch 010/50 | Train-Loss 590.6306 | Test-MSE 356.5790 | Regret 0.3003 | Fair-Val 493.0231\n",
      "Epoch 020/50 | Train-Loss 555.7096 | Test-MSE 339.9457 | Regret 0.2577 | Fair-Val 472.1521\n",
      "Epoch 030/50 | Train-Loss 520.2523 | Test-MSE 316.9056 | Regret 0.2484 | Fair-Val 443.1462\n",
      "Epoch 040/50 | Train-Loss 484.9293 | Test-MSE 290.9703 | Regret 0.2632 | Fair-Val 410.0052\n",
      "Epoch 050/50 | Train-Loss 452.8621 | Test-MSE 265.5673 | Regret 0.2937 | Fair-Val 375.9044\n",
      "Training finished in 2.47s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.2963 | σ = 0.0026\n",
      "[                 MSE]  μ = 265.3031 | σ = 0.2642\n",
      "[            FAIRNESS]  μ = 375.7444 | σ = 0.1601\n",
      "[       TRAINING_TIME]  μ = 2.5080 | σ = 0.0425\n",
      "[              G0_MSE]  μ = 252.3965 | σ = 0.5278\n",
      "[              G1_MSE]  μ = 360.6736 | σ = 1.6836\n",
      "[     G0_DECISION_OBJ]  μ = 19.1004 | σ = 0.0250\n",
      "[     G1_DECISION_OBJ]  μ = 25.9174 | σ = 0.0765\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 0.5, 'Lambda': 0.01, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 3489.4285 | Test-MSE 362.6414 | Regret 0.1304 | Fair-Val 500.9474\n",
      "Epoch 010/50 | Train-Loss 3486.4802 | Test-MSE 362.2730 | Regret 0.1301 | Fair-Val 500.4157\n",
      "Epoch 020/50 | Train-Loss 3441.3674 | Test-MSE 360.3709 | Regret 0.1279 | Fair-Val 497.7131\n",
      "Epoch 030/50 | Train-Loss 3398.0581 | Test-MSE 358.2622 | Regret 0.1257 | Fair-Val 494.7278\n",
      "Epoch 040/50 | Train-Loss 3349.1270 | Test-MSE 355.1071 | Regret 0.1233 | Fair-Val 490.2448\n",
      "Epoch 050/50 | Train-Loss 3285.2444 | Test-MSE 351.5754 | Regret 0.1208 | Fair-Val 485.2000\n",
      "Training finished in 2.56s.\n",
      "Epoch 001/50 | Train-Loss 3493.8040 | Test-MSE 362.6854 | Regret 0.1304 | Fair-Val 501.0144\n",
      "Epoch 010/50 | Train-Loss 3480.5393 | Test-MSE 361.8061 | Regret 0.1293 | Fair-Val 499.7501\n",
      "Epoch 020/50 | Train-Loss 3457.2878 | Test-MSE 360.5742 | Regret 0.1277 | Fair-Val 497.9951\n",
      "Epoch 030/50 | Train-Loss 3421.1558 | Test-MSE 358.5132 | Regret 0.1258 | Fair-Val 495.0865\n",
      "Epoch 040/50 | Train-Loss 3362.1780 | Test-MSE 355.5448 | Regret 0.1235 | Fair-Val 490.9011\n",
      "Epoch 050/50 | Train-Loss 3328.1306 | Test-MSE 352.6148 | Regret 0.1217 | Fair-Val 486.6805\n",
      "Training finished in 2.57s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.1213 | σ = 0.0004\n",
      "[                 MSE]  μ = 352.0951 | σ = 0.5197\n",
      "[            FAIRNESS]  μ = 485.9402 | σ = 0.7403\n",
      "[       TRAINING_TIME]  μ = 2.5631 | σ = 0.0047\n",
      "[              G0_MSE]  μ = 332.9896 | σ = 0.5573\n",
      "[              G1_MSE]  μ = 493.2709 | σ = 0.2420\n",
      "[     G0_DECISION_OBJ]  μ = 36.5933 | σ = 0.1377\n",
      "[     G1_DECISION_OBJ]  μ = 61.2274 | σ = 0.9257\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 0.8, 'Lambda': 0.01, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 152.0574 | Test-MSE 362.6259 | Regret 0.0064 | Fair-Val 500.9229\n",
      "Epoch 010/50 | Train-Loss 149.0188 | Test-MSE 361.4857 | Regret 0.0063 | Fair-Val 499.3129\n",
      "Epoch 020/50 | Train-Loss 144.2434 | Test-MSE 358.7103 | Regret 0.0061 | Fair-Val 495.3899\n",
      "Epoch 030/50 | Train-Loss 138.4500 | Test-MSE 355.0478 | Regret 0.0059 | Fair-Val 490.1936\n",
      "Epoch 040/50 | Train-Loss 133.0273 | Test-MSE 350.7934 | Regret 0.0056 | Fair-Val 484.1012\n",
      "Epoch 050/50 | Train-Loss 126.8374 | Test-MSE 345.6668 | Regret 0.0054 | Fair-Val 476.6837\n",
      "Training finished in 2.57s.\n",
      "Epoch 001/50 | Train-Loss 152.3605 | Test-MSE 362.6788 | Regret 0.0064 | Fair-Val 501.0052\n",
      "Epoch 010/50 | Train-Loss 149.6657 | Test-MSE 361.3387 | Regret 0.0063 | Fair-Val 499.0808\n",
      "Epoch 020/50 | Train-Loss 144.9907 | Test-MSE 358.8668 | Regret 0.0061 | Fair-Val 495.6436\n",
      "Epoch 030/50 | Train-Loss 141.1295 | Test-MSE 355.9170 | Regret 0.0059 | Fair-Val 491.4397\n",
      "Epoch 040/50 | Train-Loss 135.7160 | Test-MSE 351.7208 | Regret 0.0057 | Fair-Val 485.4401\n",
      "Epoch 050/50 | Train-Loss 129.7320 | Test-MSE 346.6581 | Regret 0.0055 | Fair-Val 478.1182\n",
      "Training finished in 2.46s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0054 | σ = 0.0000\n",
      "[                 MSE]  μ = 346.1625 | σ = 0.4957\n",
      "[            FAIRNESS]  μ = 477.4009 | σ = 0.7173\n",
      "[       TRAINING_TIME]  μ = 2.5173 | σ = 0.0537\n",
      "[              G0_MSE]  μ = 327.4688 | σ = 0.5690\n",
      "[              G1_MSE]  μ = 484.2948 | σ = 0.0463\n",
      "[     G0_DECISION_OBJ]  μ = 28.4416 | σ = 0.0020\n",
      "[     G1_DECISION_OBJ]  μ = 45.7411 | σ = 0.0949\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 1.5, 'Lambda': 0.01, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 86.4202 | Test-MSE 362.6604 | Regret 0.0561 | Fair-Val 500.9775\n",
      "Epoch 010/50 | Train-Loss 83.3624 | Test-MSE 360.9453 | Regret 0.0541 | Fair-Val 498.9068\n",
      "Epoch 020/50 | Train-Loss 76.8403 | Test-MSE 353.0631 | Regret 0.0502 | Fair-Val 490.3913\n",
      "Epoch 030/50 | Train-Loss 80.1352 | Test-MSE 343.5601 | Regret 0.0526 | Fair-Val 480.8597\n",
      "Epoch 040/50 | Train-Loss 90.7954 | Test-MSE 335.0229 | Regret 0.0594 | Fair-Val 472.2241\n",
      "Epoch 050/50 | Train-Loss 103.1610 | Test-MSE 328.1651 | Regret 0.0671 | Fair-Val 464.2056\n",
      "Training finished in 2.57s.\n",
      "Epoch 001/50 | Train-Loss 86.6851 | Test-MSE 362.7001 | Regret 0.0562 | Fair-Val 501.0388\n",
      "Epoch 010/50 | Train-Loss 84.8383 | Test-MSE 361.3617 | Regret 0.0549 | Fair-Val 499.6753\n",
      "Epoch 020/50 | Train-Loss 80.7496 | Test-MSE 354.6092 | Regret 0.0520 | Fair-Val 492.6638\n",
      "Epoch 030/50 | Train-Loss 83.5566 | Test-MSE 345.3977 | Regret 0.0538 | Fair-Val 483.3935\n",
      "Epoch 040/50 | Train-Loss 92.8440 | Test-MSE 336.7273 | Regret 0.0597 | Fair-Val 474.5214\n",
      "Epoch 050/50 | Train-Loss 105.0586 | Test-MSE 329.9615 | Regret 0.0675 | Fair-Val 466.6438\n",
      "Training finished in 2.55s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0673 | σ = 0.0002\n",
      "[                 MSE]  μ = 329.0633 | σ = 0.8982\n",
      "[            FAIRNESS]  μ = 465.4247 | σ = 1.2191\n",
      "[       TRAINING_TIME]  μ = 2.5576 | σ = 0.0108\n",
      "[              G0_MSE]  μ = 310.0833 | σ = 1.1500\n",
      "[              G1_MSE]  μ = 469.3114 | σ = 0.9625\n",
      "[     G0_DECISION_OBJ]  μ = 21.1028 | σ = 0.0275\n",
      "[     G1_DECISION_OBJ]  μ = 30.5169 | σ = 0.1242\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 2, 'Lambda': 0.01, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 82.3959 | Test-MSE 362.5999 | Regret 0.3402 | Fair-Val 500.8932\n",
      "Epoch 010/50 | Train-Loss 73.8331 | Test-MSE 357.3694 | Regret 0.3029 | Fair-Val 494.1446\n",
      "Epoch 020/50 | Train-Loss 65.4242 | Test-MSE 344.4025 | Regret 0.2677 | Fair-Val 478.6615\n",
      "Epoch 030/50 | Train-Loss 66.9885 | Test-MSE 331.8704 | Regret 0.2773 | Fair-Val 464.8297\n",
      "Epoch 040/50 | Train-Loss 75.1935 | Test-MSE 322.3130 | Regret 0.3131 | Fair-Val 454.6666\n",
      "Epoch 050/50 | Train-Loss 82.8341 | Test-MSE 314.7815 | Regret 0.3448 | Fair-Val 445.9679\n",
      "Training finished in 2.46s.\n",
      "Epoch 001/50 | Train-Loss 82.6911 | Test-MSE 362.6708 | Regret 0.3412 | Fair-Val 500.9981\n",
      "Epoch 010/50 | Train-Loss 76.2688 | Test-MSE 358.4729 | Regret 0.3113 | Fair-Val 495.6983\n",
      "Epoch 020/50 | Train-Loss 66.7062 | Test-MSE 346.0848 | Regret 0.2747 | Fair-Val 480.8956\n",
      "Epoch 030/50 | Train-Loss 66.4827 | Test-MSE 333.2071 | Regret 0.2773 | Fair-Val 466.3661\n",
      "Epoch 040/50 | Train-Loss 73.0435 | Test-MSE 323.0071 | Regret 0.3043 | Fair-Val 455.3906\n",
      "Epoch 050/50 | Train-Loss 81.2584 | Test-MSE 315.0166 | Regret 0.3373 | Fair-Val 446.1644\n",
      "Training finished in 2.55s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.3411 | σ = 0.0037\n",
      "[                 MSE]  μ = 314.8991 | σ = 0.1175\n",
      "[            FAIRNESS]  μ = 446.0661 | σ = 0.0983\n",
      "[       TRAINING_TIME]  μ = 2.5038 | σ = 0.0440\n",
      "[              G0_MSE]  μ = 297.3194 | σ = 0.3967\n",
      "[              G1_MSE]  μ = 444.7993 | σ = 1.9453\n",
      "[     G0_DECISION_OBJ]  μ = 18.7673 | σ = 0.0202\n",
      "[     G1_DECISION_OBJ]  μ = 25.8515 | σ = 0.1049\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 0.5, 'Lambda': 1, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 3484.7598 | Test-MSE 362.6414 | Regret 0.1304 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 3481.8318 | Test-MSE 362.2736 | Regret 0.1301 | Fair-Val 0.6370\n",
      "Epoch 020/50 | Train-Loss 3436.8057 | Test-MSE 360.3734 | Regret 0.1279 | Fair-Val 0.6364\n",
      "Epoch 030/50 | Train-Loss 3393.6018 | Test-MSE 358.2682 | Regret 0.1257 | Fair-Val 0.6358\n",
      "Epoch 040/50 | Train-Loss 3344.8137 | Test-MSE 355.1141 | Regret 0.1233 | Fair-Val 0.6349\n",
      "Epoch 050/50 | Train-Loss 3282.9080 | Test-MSE 351.6588 | Regret 0.1209 | Fair-Val 0.6339\n",
      "Training finished in 2.58s.\n",
      "Epoch 001/50 | Train-Loss 3489.1328 | Test-MSE 362.6854 | Regret 0.1304 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 3475.9373 | Test-MSE 361.8093 | Regret 0.1293 | Fair-Val 0.6368\n",
      "Epoch 020/50 | Train-Loss 3450.9133 | Test-MSE 360.5167 | Regret 0.1276 | Fair-Val 0.6364\n",
      "Epoch 030/50 | Train-Loss 3418.0356 | Test-MSE 358.5852 | Regret 0.1259 | Fair-Val 0.6358\n",
      "Epoch 040/50 | Train-Loss 3361.3589 | Test-MSE 355.6607 | Regret 0.1237 | Fair-Val 0.6350\n",
      "Epoch 050/50 | Train-Loss 3324.5669 | Test-MSE 352.7562 | Regret 0.1219 | Fair-Val 0.6341\n",
      "Training finished in 2.55s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.1214 | σ = 0.0005\n",
      "[                 MSE]  μ = 352.2075 | σ = 0.5487\n",
      "[            FAIRNESS]  μ = 0.6340 | σ = 0.0001\n",
      "[       TRAINING_TIME]  μ = 2.5642 | σ = 0.0163\n",
      "[              G0_MSE]  μ = 333.0871 | σ = 0.5852\n",
      "[              G1_MSE]  μ = 493.4933 | σ = 0.2789\n",
      "[     G0_DECISION_OBJ]  μ = 36.5983 | σ = 0.1099\n",
      "[     G1_DECISION_OBJ]  μ = 60.9883 | σ = 0.7398\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 0.8, 'Lambda': 1, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 147.3887 | Test-MSE 362.6259 | Regret 0.0064 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 144.3198 | Test-MSE 361.4809 | Regret 0.0063 | Fair-Val 0.6367\n",
      "Epoch 020/50 | Train-Loss 139.7055 | Test-MSE 358.7422 | Regret 0.0061 | Fair-Val 0.6360\n",
      "Epoch 030/50 | Train-Loss 133.8937 | Test-MSE 354.9828 | Regret 0.0059 | Fair-Val 0.6350\n",
      "Epoch 040/50 | Train-Loss 128.4919 | Test-MSE 350.7477 | Regret 0.0056 | Fair-Val 0.6338\n",
      "Epoch 050/50 | Train-Loss 122.3124 | Test-MSE 345.5699 | Regret 0.0054 | Fair-Val 0.6324\n",
      "Training finished in 2.46s.\n",
      "Epoch 001/50 | Train-Loss 147.6895 | Test-MSE 362.6788 | Regret 0.0064 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 145.0406 | Test-MSE 361.3516 | Regret 0.0063 | Fair-Val 0.6366\n",
      "Epoch 020/50 | Train-Loss 140.3912 | Test-MSE 358.8639 | Regret 0.0061 | Fair-Val 0.6360\n",
      "Epoch 030/50 | Train-Loss 136.6344 | Test-MSE 355.9185 | Regret 0.0059 | Fair-Val 0.6351\n",
      "Epoch 040/50 | Train-Loss 131.4572 | Test-MSE 351.9515 | Regret 0.0057 | Fair-Val 0.6340\n",
      "Epoch 050/50 | Train-Loss 125.4791 | Test-MSE 346.8723 | Regret 0.0055 | Fair-Val 0.6326\n",
      "Training finished in 2.58s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0054 | σ = 0.0000\n",
      "[                 MSE]  μ = 346.2211 | σ = 0.6512\n",
      "[            FAIRNESS]  μ = 0.6325 | σ = 0.0001\n",
      "[       TRAINING_TIME]  μ = 2.5212 | σ = 0.0584\n",
      "[              G0_MSE]  μ = 327.5159 | σ = 0.7166\n",
      "[              G1_MSE]  μ = 484.4388 | σ = 0.1674\n",
      "[     G0_DECISION_OBJ]  μ = 28.4429 | σ = 0.0011\n",
      "[     G1_DECISION_OBJ]  μ = 45.7674 | σ = 0.0927\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 1.5, 'Lambda': 1, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 81.7515 | Test-MSE 362.6613 | Regret 0.0561 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 78.8051 | Test-MSE 360.9972 | Regret 0.0542 | Fair-Val 0.6374\n",
      "Epoch 020/50 | Train-Loss 72.4124 | Test-MSE 353.2060 | Regret 0.0503 | Fair-Val 0.6426\n",
      "Epoch 030/50 | Train-Loss 75.8573 | Test-MSE 343.7781 | Regret 0.0527 | Fair-Val 0.6535\n",
      "Epoch 040/50 | Train-Loss 86.6981 | Test-MSE 335.3200 | Regret 0.0595 | Fair-Val 0.6618\n",
      "Epoch 050/50 | Train-Loss 99.2185 | Test-MSE 328.4984 | Regret 0.0672 | Fair-Val 0.6619\n",
      "Training finished in 2.54s.\n",
      "Epoch 001/50 | Train-Loss 82.0141 | Test-MSE 362.7001 | Regret 0.0562 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 80.1948 | Test-MSE 361.3693 | Regret 0.0549 | Fair-Val 0.6379\n",
      "Epoch 020/50 | Train-Loss 76.2347 | Test-MSE 354.6541 | Regret 0.0521 | Fair-Val 0.6431\n",
      "Epoch 030/50 | Train-Loss 79.1700 | Test-MSE 345.4833 | Regret 0.0538 | Fair-Val 0.6529\n",
      "Epoch 040/50 | Train-Loss 88.6195 | Test-MSE 336.8721 | Regret 0.0597 | Fair-Val 0.6611\n",
      "Epoch 050/50 | Train-Loss 100.9475 | Test-MSE 330.1509 | Regret 0.0676 | Fair-Val 0.6625\n",
      "Training finished in 2.56s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0674 | σ = 0.0002\n",
      "[                 MSE]  μ = 329.3247 | σ = 0.8263\n",
      "[            FAIRNESS]  μ = 0.6622 | σ = 0.0003\n",
      "[       TRAINING_TIME]  μ = 2.5506 | σ = 0.0061\n",
      "[              G0_MSE]  μ = 310.3227 | σ = 1.0822\n",
      "[              G1_MSE]  μ = 469.7349 | σ = 1.0648\n",
      "[     G0_DECISION_OBJ]  μ = 21.1028 | σ = 0.0272\n",
      "[     G1_DECISION_OBJ]  μ = 30.5253 | σ = 0.1267\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 2, 'Lambda': 1, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 77.7271 | Test-MSE 362.6006 | Regret 0.3403 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 69.2943 | Test-MSE 357.4149 | Regret 0.3032 | Fair-Val 0.6371\n",
      "Epoch 020/50 | Train-Loss 61.1446 | Test-MSE 344.5964 | Regret 0.2683 | Fair-Val 0.6415\n",
      "Epoch 030/50 | Train-Loss 63.0669 | Test-MSE 332.3326 | Regret 0.2787 | Fair-Val 0.6513\n",
      "Epoch 040/50 | Train-Loss 71.5759 | Test-MSE 323.0721 | Regret 0.3153 | Fair-Val 0.6602\n",
      "Epoch 050/50 | Train-Loss 79.4322 | Test-MSE 315.8927 | Regret 0.3474 | Fair-Val 0.6633\n",
      "Training finished in 2.44s.\n",
      "Epoch 001/50 | Train-Loss 78.0201 | Test-MSE 362.6744 | Regret 0.3412 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 71.7812 | Test-MSE 358.5528 | Regret 0.3118 | Fair-Val 0.6373\n",
      "Epoch 020/50 | Train-Loss 62.4455 | Test-MSE 346.3407 | Regret 0.2756 | Fair-Val 0.6407\n",
      "Epoch 030/50 | Train-Loss 62.5600 | Test-MSE 333.7190 | Regret 0.2788 | Fair-Val 0.6492\n",
      "Epoch 040/50 | Train-Loss 69.4911 | Test-MSE 323.8727 | Regret 0.3067 | Fair-Val 0.6579\n",
      "Epoch 050/50 | Train-Loss 78.0588 | Test-MSE 316.3122 | Regret 0.3408 | Fair-Val 0.6624\n",
      "Training finished in 2.55s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.3441 | σ = 0.0033\n",
      "[                 MSE]  μ = 316.1024 | σ = 0.2097\n",
      "[            FAIRNESS]  μ = 0.6629 | σ = 0.0005\n",
      "[       TRAINING_TIME]  μ = 2.4938 | σ = 0.0543\n",
      "[              G0_MSE]  μ = 298.4326 | σ = 0.4767\n",
      "[              G1_MSE]  μ = 446.6695 | σ = 1.7631\n",
      "[     G0_DECISION_OBJ]  μ = 18.7699 | σ = 0.0188\n",
      "[     G1_DECISION_OBJ]  μ = 25.8786 | σ = 0.0955\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 0.5, 'Lambda': 10, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 3490.4729 | Test-MSE 362.6414 | Regret 0.1304 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 3487.5410 | Test-MSE 362.2734 | Regret 0.1301 | Fair-Val 0.6370\n",
      "Epoch 020/50 | Train-Loss 3442.4941 | Test-MSE 360.3729 | Regret 0.1279 | Fair-Val 0.6364\n",
      "Epoch 030/50 | Train-Loss 3399.2793 | Test-MSE 358.2674 | Regret 0.1257 | Fair-Val 0.6358\n",
      "Epoch 040/50 | Train-Loss 3350.4761 | Test-MSE 355.1128 | Regret 0.1233 | Fair-Val 0.6349\n",
      "Epoch 050/50 | Train-Loss 3288.5530 | Test-MSE 351.6570 | Regret 0.1209 | Fair-Val 0.6339\n",
      "Training finished in 2.56s.\n",
      "Epoch 001/50 | Train-Loss 3494.8467 | Test-MSE 362.6854 | Regret 0.1304 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 3481.6458 | Test-MSE 361.8092 | Regret 0.1293 | Fair-Val 0.6368\n",
      "Epoch 020/50 | Train-Loss 3456.6077 | Test-MSE 360.5162 | Regret 0.1276 | Fair-Val 0.6364\n",
      "Epoch 030/50 | Train-Loss 3423.7378 | Test-MSE 358.5852 | Regret 0.1259 | Fair-Val 0.6358\n",
      "Epoch 040/50 | Train-Loss 3367.6277 | Test-MSE 355.6840 | Regret 0.1237 | Fair-Val 0.6350\n",
      "Epoch 050/50 | Train-Loss 3329.9614 | Test-MSE 352.7168 | Regret 0.1219 | Fair-Val 0.6341\n",
      "Training finished in 2.45s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.1214 | σ = 0.0005\n",
      "[                 MSE]  μ = 352.1869 | σ = 0.5299\n",
      "[            FAIRNESS]  μ = 0.6340 | σ = 0.0001\n",
      "[       TRAINING_TIME]  μ = 2.5029 | σ = 0.0552\n",
      "[              G0_MSE]  μ = 333.0704 | σ = 0.5701\n",
      "[              G1_MSE]  μ = 493.4440 | σ = 0.2325\n",
      "[     G0_DECISION_OBJ]  μ = 36.6015 | σ = 0.1071\n",
      "[     G1_DECISION_OBJ]  μ = 61.0196 | σ = 0.7706\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 0.8, 'Lambda': 10, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 153.1018 | Test-MSE 362.6259 | Regret 0.0064 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 150.0922 | Test-MSE 361.4904 | Regret 0.0063 | Fair-Val 0.6367\n",
      "Epoch 020/50 | Train-Loss 145.3436 | Test-MSE 358.7110 | Regret 0.0061 | Fair-Val 0.6360\n",
      "Epoch 030/50 | Train-Loss 139.6419 | Test-MSE 355.0814 | Regret 0.0059 | Fair-Val 0.6350\n",
      "Epoch 040/50 | Train-Loss 134.2530 | Test-MSE 350.8412 | Regret 0.0057 | Fair-Val 0.6339\n",
      "Epoch 050/50 | Train-Loss 128.2262 | Test-MSE 345.7831 | Regret 0.0054 | Fair-Val 0.6325\n",
      "Training finished in 2.55s.\n",
      "Epoch 001/50 | Train-Loss 153.4033 | Test-MSE 362.6788 | Regret 0.0064 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 150.7494 | Test-MSE 361.3507 | Regret 0.0063 | Fair-Val 0.6366\n",
      "Epoch 020/50 | Train-Loss 146.2326 | Test-MSE 358.8739 | Regret 0.0061 | Fair-Val 0.6360\n",
      "Epoch 030/50 | Train-Loss 142.3129 | Test-MSE 355.9744 | Regret 0.0059 | Fair-Val 0.6351\n",
      "Epoch 040/50 | Train-Loss 136.8503 | Test-MSE 351.6523 | Regret 0.0057 | Fair-Val 0.6339\n",
      "Epoch 050/50 | Train-Loss 130.8269 | Test-MSE 346.6896 | Regret 0.0055 | Fair-Val 0.6325\n",
      "Training finished in 2.55s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0054 | σ = 0.0000\n",
      "[                 MSE]  μ = 346.2363 | σ = 0.4533\n",
      "[            FAIRNESS]  μ = 0.6325 | σ = 0.0000\n",
      "[       TRAINING_TIME]  μ = 2.5500 | σ = 0.0022\n",
      "[              G0_MSE]  μ = 327.5271 | σ = 0.5207\n",
      "[              G1_MSE]  μ = 484.4836 | σ = 0.0447\n",
      "[     G0_DECISION_OBJ]  μ = 28.4431 | σ = 0.0035\n",
      "[     G1_DECISION_OBJ]  μ = 45.7461 | σ = 0.0928\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 1.5, 'Lambda': 10, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 87.4646 | Test-MSE 362.6607 | Regret 0.0561 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 84.4892 | Test-MSE 360.9782 | Regret 0.0542 | Fair-Val 0.6374\n",
      "Epoch 020/50 | Train-Loss 78.1193 | Test-MSE 353.1682 | Regret 0.0503 | Fair-Val 0.6426\n",
      "Epoch 030/50 | Train-Loss 81.6416 | Test-MSE 343.7260 | Regret 0.0527 | Fair-Val 0.6535\n",
      "Epoch 040/50 | Train-Loss 92.5502 | Test-MSE 335.2580 | Regret 0.0595 | Fair-Val 0.6618\n",
      "Epoch 050/50 | Train-Loss 105.0854 | Test-MSE 328.4500 | Regret 0.0672 | Fair-Val 0.6619\n",
      "Training finished in 2.56s.\n",
      "Epoch 001/50 | Train-Loss 87.7279 | Test-MSE 362.7001 | Regret 0.0562 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 85.9121 | Test-MSE 361.3680 | Regret 0.0549 | Fair-Val 0.6379\n",
      "Epoch 020/50 | Train-Loss 81.9851 | Test-MSE 354.6468 | Regret 0.0521 | Fair-Val 0.6431\n",
      "Epoch 030/50 | Train-Loss 85.0346 | Test-MSE 345.4805 | Regret 0.0538 | Fair-Val 0.6529\n",
      "Epoch 040/50 | Train-Loss 94.5614 | Test-MSE 336.8644 | Regret 0.0597 | Fair-Val 0.6611\n",
      "Epoch 050/50 | Train-Loss 106.8693 | Test-MSE 330.1329 | Regret 0.0676 | Fair-Val 0.6625\n",
      "Training finished in 2.47s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0674 | σ = 0.0002\n",
      "[                 MSE]  μ = 329.2915 | σ = 0.8414\n",
      "[            FAIRNESS]  μ = 0.6622 | σ = 0.0003\n",
      "[       TRAINING_TIME]  μ = 2.5124 | σ = 0.0468\n",
      "[              G0_MSE]  μ = 310.2936 | σ = 1.0946\n",
      "[              G1_MSE]  μ = 469.6719 | σ = 1.0296\n",
      "[     G0_DECISION_OBJ]  μ = 21.1027 | σ = 0.0269\n",
      "[     G1_DECISION_OBJ]  μ = 30.5245 | σ = 0.1242\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'closed-form', 'Alpha': 2, 'Lambda': 10, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 83.4402 | Test-MSE 362.6007 | Regret 0.3403 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 74.9909 | Test-MSE 357.4051 | Regret 0.3031 | Fair-Val 0.6371\n",
      "Epoch 020/50 | Train-Loss 66.8540 | Test-MSE 344.5592 | Regret 0.2682 | Fair-Val 0.6415\n",
      "Epoch 030/50 | Train-Loss 68.8062 | Test-MSE 332.2467 | Regret 0.2783 | Fair-Val 0.6513\n",
      "Epoch 040/50 | Train-Loss 77.3404 | Test-MSE 322.9499 | Regret 0.3147 | Fair-Val 0.6601\n",
      "Epoch 050/50 | Train-Loss 85.2022 | Test-MSE 315.7438 | Regret 0.3467 | Fair-Val 0.6633\n",
      "Training finished in 2.55s.\n",
      "Epoch 001/50 | Train-Loss 83.7338 | Test-MSE 362.6741 | Regret 0.3412 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 77.4749 | Test-MSE 358.5383 | Regret 0.3118 | Fair-Val 0.6373\n",
      "Epoch 020/50 | Train-Loss 68.1361 | Test-MSE 346.2967 | Regret 0.2754 | Fair-Val 0.6407\n",
      "Epoch 030/50 | Train-Loss 68.2643 | Test-MSE 333.6204 | Regret 0.2783 | Fair-Val 0.6491\n",
      "Epoch 040/50 | Train-Loss 75.2123 | Test-MSE 323.7209 | Regret 0.3060 | Fair-Val 0.6578\n",
      "Epoch 050/50 | Train-Loss 83.7494 | Test-MSE 316.0986 | Regret 0.3397 | Fair-Val 0.6623\n",
      "Training finished in 2.56s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.3432 | σ = 0.0035\n",
      "[                 MSE]  μ = 315.9212 | σ = 0.1774\n",
      "[            FAIRNESS]  μ = 0.6628 | σ = 0.0005\n",
      "[       TRAINING_TIME]  μ = 2.5562 | σ = 0.0027\n",
      "[              G0_MSE]  μ = 298.2644 | σ = 0.4471\n",
      "[              G1_MSE]  μ = 446.3917 | σ = 1.8152\n",
      "[     G0_DECISION_OBJ]  μ = 18.7690 | σ = 0.0193\n",
      "[     G1_DECISION_OBJ]  μ = 25.8718 | σ = 0.0987\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 0.5, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 3484.1250 | Test-MSE 362.6039 | Regret 0.1304 | Fair-Val 500.8986\n",
      "Epoch 010/50 | Train-Loss 3281.2852 | Test-MSE 358.0934 | Regret 0.1229 | Fair-Val 494.9246\n",
      "Epoch 020/50 | Train-Loss 2872.8320 | Test-MSE 345.0862 | Regret 0.1079 | Fair-Val 478.5816\n",
      "Epoch 030/50 | Train-Loss 2627.1465 | Test-MSE 331.4829 | Regret 0.1003 | Fair-Val 461.6180\n",
      "Epoch 040/50 | Train-Loss 2440.0176 | Test-MSE 323.0461 | Regret 0.0952 | Fair-Val 450.5429\n",
      "Epoch 050/50 | Train-Loss 2253.7461 | Test-MSE 318.2284 | Regret 0.0895 | Fair-Val 443.5828\n",
      "Training finished in 26.71s.\n",
      "Epoch 001/50 | Train-Loss 3488.4980 | Test-MSE 362.6949 | Regret 0.1304 | Fair-Val 501.0302\n",
      "Epoch 010/50 | Train-Loss 3329.4199 | Test-MSE 358.9094 | Regret 0.1238 | Fair-Val 496.1117\n",
      "Epoch 020/50 | Train-Loss 2916.8301 | Test-MSE 345.6421 | Regret 0.1092 | Fair-Val 479.5013\n",
      "Epoch 030/50 | Train-Loss 2688.6094 | Test-MSE 332.0039 | Regret 0.1022 | Fair-Val 462.0697\n",
      "Epoch 040/50 | Train-Loss 2493.2129 | Test-MSE 323.8124 | Regret 0.0976 | Fair-Val 451.1194\n",
      "Epoch 050/50 | Train-Loss 2319.8477 | Test-MSE 318.9091 | Regret 0.0927 | Fair-Val 444.2465\n",
      "Training finished in 26.83s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0911 | σ = 0.0016\n",
      "[                 MSE]  μ = 318.5687 | σ = 0.3403\n",
      "[            FAIRNESS]  μ = 443.9146 | σ = 0.3318\n",
      "[       TRAINING_TIME]  μ = 26.7715 | σ = 0.0626\n",
      "[              G0_MSE]  μ = 302.0091 | σ = 0.4077\n",
      "[              G1_MSE]  μ = 440.9322 | σ = 0.1574\n",
      "[     G0_DECISION_OBJ]  μ = 43.2723 | σ = 0.0323\n",
      "[     G1_DECISION_OBJ]  μ = 87.8747 | σ = 0.2735\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 0.8, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 146.7539 | Test-MSE 362.6438 | Regret 0.0064 | Fair-Val 500.9504\n",
      "Epoch 010/50 | Train-Loss 146.1133 | Test-MSE 362.4742 | Regret 0.0064 | Fair-Val 500.7302\n",
      "Epoch 020/50 | Train-Loss 141.6660 | Test-MSE 360.8026 | Regret 0.0062 | Fair-Val 498.4998\n",
      "Epoch 030/50 | Train-Loss 133.2031 | Test-MSE 358.3059 | Regret 0.0060 | Fair-Val 495.1714\n",
      "Epoch 040/50 | Train-Loss 132.4238 | Test-MSE 357.3708 | Regret 0.0059 | Fair-Val 493.9005\n",
      "Epoch 050/50 | Train-Loss 118.5781 | Test-MSE 348.6112 | Regret 0.0053 | Fair-Val 482.7157\n",
      "Training finished in 47.37s.\n",
      "Epoch 001/50 | Train-Loss 147.0547 | Test-MSE 362.6839 | Regret 0.0064 | Fair-Val 501.0124\n",
      "Epoch 010/50 | Train-Loss 142.3594 | Test-MSE 360.6770 | Regret 0.0062 | Fair-Val 498.2828\n",
      "Epoch 020/50 | Train-Loss 127.9512 | Test-MSE 353.2209 | Regret 0.0056 | Fair-Val 488.6959\n",
      "Epoch 030/50 | Train-Loss 118.9355 | Test-MSE 346.7365 | Regret 0.0053 | Fair-Val 480.4532\n",
      "Epoch 040/50 | Train-Loss 117.1426 | Test-MSE 345.4813 | Regret 0.0052 | Fair-Val 478.6350\n",
      "Epoch 050/50 | Train-Loss 116.8340 | Test-MSE 346.0250 | Regret 0.0052 | Fair-Val 479.1946\n",
      "Training finished in 47.22s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0053 | σ = 0.0000\n",
      "[                 MSE]  μ = 347.3181 | σ = 1.2931\n",
      "[            FAIRNESS]  μ = 480.9552 | σ = 1.7605\n",
      "[       TRAINING_TIME]  μ = 47.2914 | σ = 0.0750\n",
      "[              G0_MSE]  μ = 328.3932 | σ = 0.8489\n",
      "[              G1_MSE]  μ = 487.1590 | σ = 4.5759\n",
      "[     G0_DECISION_OBJ]  μ = 28.7404 | σ = 0.0038\n",
      "[     G1_DECISION_OBJ]  μ = 46.9977 | σ = 0.2389\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 1.5, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 81.1167 | Test-MSE 362.5714 | Regret 0.0560 | Fair-Val 500.8536\n",
      "Epoch 010/50 | Train-Loss 71.7729 | Test-MSE 356.3380 | Regret 0.0496 | Fair-Val 492.6686\n",
      "Epoch 020/50 | Train-Loss 61.5361 | Test-MSE 342.5908 | Regret 0.0429 | Fair-Val 475.3158\n",
      "Epoch 030/50 | Train-Loss 55.8290 | Test-MSE 329.9543 | Regret 0.0394 | Fair-Val 459.0866\n",
      "Epoch 040/50 | Train-Loss 51.5771 | Test-MSE 319.2857 | Regret 0.0370 | Fair-Val 445.0949\n",
      "Epoch 050/50 | Train-Loss 47.9740 | Test-MSE 316.3683 | Regret 0.0350 | Fair-Val 440.4606\n",
      "Training finished in 47.04s.\n",
      "Epoch 001/50 | Train-Loss 81.3793 | Test-MSE 362.6340 | Regret 0.0561 | Fair-Val 500.9431\n",
      "Epoch 010/50 | Train-Loss 73.3188 | Test-MSE 356.9395 | Regret 0.0504 | Fair-Val 493.3991\n",
      "Epoch 020/50 | Train-Loss 62.6066 | Test-MSE 343.7097 | Regret 0.0437 | Fair-Val 476.5517\n",
      "Epoch 030/50 | Train-Loss 56.8523 | Test-MSE 331.5863 | Regret 0.0402 | Fair-Val 460.9908\n",
      "Epoch 040/50 | Train-Loss 52.6807 | Test-MSE 323.2789 | Regret 0.0378 | Fair-Val 449.8603\n",
      "Epoch 050/50 | Train-Loss 48.4944 | Test-MSE 316.7315 | Regret 0.0354 | Fair-Val 440.8589\n",
      "Training finished in 47.13s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0352 | σ = 0.0002\n",
      "[                 MSE]  μ = 316.5499 | σ = 0.1816\n",
      "[            FAIRNESS]  μ = 440.6598 | σ = 0.1992\n",
      "[       TRAINING_TIME]  μ = 47.0840 | σ = 0.0462\n",
      "[              G0_MSE]  μ = 300.3609 | σ = 0.1784\n",
      "[              G1_MSE]  μ = 436.1747 | σ = 0.2054\n",
      "[     G0_DECISION_OBJ]  μ = 21.3745 | σ = 0.0055\n",
      "[     G1_DECISION_OBJ]  μ = 30.0966 | σ = 0.1151\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 2, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 77.0923 | Test-MSE 362.5725 | Regret 0.3399 | Fair-Val 500.8557\n",
      "Epoch 010/50 | Train-Loss 66.9267 | Test-MSE 355.9334 | Regret 0.2946 | Fair-Val 492.1762\n",
      "Epoch 020/50 | Train-Loss 56.4447 | Test-MSE 341.2778 | Regret 0.2518 | Fair-Val 473.8071\n",
      "Epoch 030/50 | Train-Loss 50.5717 | Test-MSE 328.4065 | Regret 0.2309 | Fair-Val 457.2383\n",
      "Epoch 040/50 | Train-Loss 45.7794 | Test-MSE 319.4331 | Regret 0.2163 | Fair-Val 445.1350\n",
      "Epoch 050/50 | Train-Loss 41.4057 | Test-MSE 313.0395 | Regret 0.2009 | Fair-Val 436.1967\n",
      "Training finished in 33.17s.\n",
      "Epoch 001/50 | Train-Loss 77.3852 | Test-MSE 362.6294 | Regret 0.3406 | Fair-Val 500.9367\n",
      "Epoch 010/50 | Train-Loss 68.6532 | Test-MSE 356.7874 | Regret 0.3013 | Fair-Val 493.2130\n",
      "Epoch 020/50 | Train-Loss 57.2095 | Test-MSE 342.2584 | Regret 0.2572 | Fair-Val 474.8153\n",
      "Epoch 030/50 | Train-Loss 51.1599 | Test-MSE 328.3399 | Regret 0.2351 | Fair-Val 456.9344\n",
      "Epoch 040/50 | Train-Loss 46.4873 | Test-MSE 319.7385 | Regret 0.2196 | Fair-Val 445.2231\n",
      "Epoch 050/50 | Train-Loss 41.7491 | Test-MSE 314.3628 | Regret 0.2036 | Fair-Val 437.4348\n",
      "Training finished in 32.86s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.2022 | σ = 0.0013\n",
      "[                 MSE]  μ = 313.7012 | σ = 0.6617\n",
      "[            FAIRNESS]  μ = 436.8157 | σ = 0.6191\n",
      "[       TRAINING_TIME]  μ = 33.0150 | σ = 0.1511\n",
      "[              G0_MSE]  μ = 297.8490 | σ = 0.7126\n",
      "[              G1_MSE]  μ = 430.8374 | σ = 0.2854\n",
      "[     G0_DECISION_OBJ]  μ = 19.3615 | σ = 0.0246\n",
      "[     G1_DECISION_OBJ]  μ = 25.8415 | σ = 0.1113\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 0.5, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 4014.4792 | Test-MSE 362.5973 | Regret 0.1303 | Fair-Val 500.8890\n",
      "Epoch 010/50 | Train-Loss 3793.3530 | Test-MSE 357.7389 | Regret 0.1225 | Fair-Val 494.4456\n",
      "Epoch 020/50 | Train-Loss 3366.9331 | Test-MSE 344.3366 | Regret 0.1078 | Fair-Val 477.5715\n",
      "Epoch 030/50 | Train-Loss 3105.7610 | Test-MSE 330.5349 | Regret 0.1003 | Fair-Val 460.2931\n",
      "Epoch 040/50 | Train-Loss 2907.1704 | Test-MSE 322.0304 | Regret 0.0954 | Fair-Val 449.0112\n",
      "Epoch 050/50 | Train-Loss 2719.8770 | Test-MSE 316.5427 | Regret 0.0900 | Fair-Val 441.2208\n",
      "Training finished in 26.77s.\n",
      "Epoch 001/50 | Train-Loss 4019.0820 | Test-MSE 362.6916 | Regret 0.1304 | Fair-Val 501.0255\n",
      "Epoch 010/50 | Train-Loss 3856.5430 | Test-MSE 359.1036 | Regret 0.1240 | Fair-Val 496.3641\n",
      "Epoch 020/50 | Train-Loss 3421.6011 | Test-MSE 345.6957 | Regret 0.1091 | Fair-Val 479.5870\n",
      "Epoch 030/50 | Train-Loss 3177.1233 | Test-MSE 330.9165 | Regret 0.1023 | Fair-Val 460.7380\n",
      "Epoch 040/50 | Train-Loss 2972.6931 | Test-MSE 322.0964 | Regret 0.0980 | Fair-Val 448.9248\n",
      "Epoch 050/50 | Train-Loss 2794.5142 | Test-MSE 316.8386 | Regret 0.0933 | Fair-Val 441.4510\n",
      "Training finished in 26.72s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0916 | σ = 0.0016\n",
      "[                 MSE]  μ = 316.6906 | σ = 0.1479\n",
      "[            FAIRNESS]  μ = 441.3359 | σ = 0.1151\n",
      "[       TRAINING_TIME]  μ = 26.7441 | σ = 0.0283\n",
      "[              G0_MSE]  μ = 300.4429 | σ = 0.2449\n",
      "[              G1_MSE]  μ = 436.7495 | σ = 0.5682\n",
      "[     G0_DECISION_OBJ]  μ = 43.8281 | σ = 0.1706\n",
      "[     G1_DECISION_OBJ]  μ = 88.5215 | σ = 0.4519\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 0.8, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 677.1081 | Test-MSE 362.5767 | Regret 0.0064 | Fair-Val 500.8600\n",
      "Epoch 010/50 | Train-Loss 667.2501 | Test-MSE 361.0417 | Regret 0.0062 | Fair-Val 498.7526\n",
      "Epoch 020/50 | Train-Loss 659.0533 | Test-MSE 358.6193 | Regret 0.0060 | Fair-Val 495.4588\n",
      "Epoch 030/50 | Train-Loss 645.1010 | Test-MSE 354.4778 | Regret 0.0057 | Fair-Val 489.9058\n",
      "Epoch 040/50 | Train-Loss 626.5168 | Test-MSE 348.2057 | Regret 0.0054 | Fair-Val 481.6455\n",
      "Epoch 050/50 | Train-Loss 610.6481 | Test-MSE 342.8670 | Regret 0.0051 | Fair-Val 474.3896\n",
      "Training finished in 47.14s.\n",
      "Epoch 001/50 | Train-Loss 677.6386 | Test-MSE 362.6400 | Regret 0.0064 | Fair-Val 500.9515\n",
      "Epoch 010/50 | Train-Loss 664.4007 | Test-MSE 359.4561 | Regret 0.0061 | Fair-Val 496.5825\n",
      "Epoch 020/50 | Train-Loss 645.5490 | Test-MSE 353.9536 | Regret 0.0057 | Fair-Val 489.2741\n",
      "Epoch 030/50 | Train-Loss 631.0878 | Test-MSE 349.0413 | Regret 0.0055 | Fair-Val 482.7664\n",
      "Epoch 040/50 | Train-Loss 620.3022 | Test-MSE 344.6176 | Regret 0.0053 | Fair-Val 476.8703\n",
      "Epoch 050/50 | Train-Loss 603.0703 | Test-MSE 337.3511 | Regret 0.0050 | Fair-Val 467.3075\n",
      "Training finished in 47.40s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0051 | σ = 0.0000\n",
      "[                 MSE]  μ = 340.1091 | σ = 2.7580\n",
      "[            FAIRNESS]  μ = 470.8485 | σ = 3.5411\n",
      "[       TRAINING_TIME]  μ = 47.2687 | σ = 0.1331\n",
      "[              G0_MSE]  μ = 322.1686 | σ = 2.2410\n",
      "[              G1_MSE]  μ = 472.6757 | σ = 6.5782\n",
      "[     G0_DECISION_OBJ]  μ = 28.7897 | σ = 0.0647\n",
      "[     G1_DECISION_OBJ]  μ = 47.1343 | σ = 0.4070\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 1.5, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 611.4709 | Test-MSE 362.5716 | Regret 0.0560 | Fair-Val 500.8539\n",
      "Epoch 010/50 | Train-Loss 591.6332 | Test-MSE 355.8854 | Regret 0.0493 | Fair-Val 492.0948\n",
      "Epoch 020/50 | Train-Loss 557.5786 | Test-MSE 339.2158 | Regret 0.0426 | Fair-Val 471.1812\n",
      "Epoch 030/50 | Train-Loss 522.5773 | Test-MSE 318.0738 | Regret 0.0402 | Fair-Val 444.3843\n",
      "Epoch 040/50 | Train-Loss 487.5009 | Test-MSE 295.4932 | Regret 0.0399 | Fair-Val 415.3718\n",
      "Epoch 050/50 | Train-Loss 453.1749 | Test-MSE 273.0007 | Regret 0.0407 | Fair-Val 385.6894\n",
      "Training finished in 47.13s.\n",
      "Epoch 001/50 | Train-Loss 611.9632 | Test-MSE 362.6330 | Regret 0.0561 | Fair-Val 500.9417\n",
      "Epoch 010/50 | Train-Loss 595.9182 | Test-MSE 356.9669 | Regret 0.0504 | Fair-Val 493.4203\n",
      "Epoch 020/50 | Train-Loss 561.2744 | Test-MSE 340.9600 | Regret 0.0434 | Fair-Val 473.1380\n",
      "Epoch 030/50 | Train-Loss 525.4189 | Test-MSE 319.3387 | Regret 0.0407 | Fair-Val 445.6795\n",
      "Epoch 040/50 | Train-Loss 488.0993 | Test-MSE 294.4716 | Regret 0.0409 | Fair-Val 413.8745\n",
      "Epoch 050/50 | Train-Loss 452.3070 | Test-MSE 269.9661 | Regret 0.0424 | Fair-Val 381.4578\n",
      "Training finished in 47.11s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0415 | σ = 0.0009\n",
      "[                 MSE]  μ = 271.4834 | σ = 1.5173\n",
      "[            FAIRNESS]  μ = 383.5736 | σ = 2.1158\n",
      "[       TRAINING_TIME]  μ = 47.1230 | σ = 0.0100\n",
      "[              G0_MSE]  μ = 259.0132 | σ = 1.2973\n",
      "[              G1_MSE]  μ = 363.6284 | σ = 3.1432\n",
      "[     G0_DECISION_OBJ]  μ = 21.2025 | σ = 0.0005\n",
      "[     G1_DECISION_OBJ]  μ = 29.7071 | σ = 0.0095\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 2, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 607.4465 | Test-MSE 362.5724 | Regret 0.3399 | Fair-Val 500.8553\n",
      "Epoch 010/50 | Train-Loss 587.0597 | Test-MSE 355.8434 | Regret 0.2944 | Fair-Val 492.0500\n",
      "Epoch 020/50 | Train-Loss 552.5988 | Test-MSE 339.1643 | Regret 0.2517 | Fair-Val 471.1362\n",
      "Epoch 030/50 | Train-Loss 516.6914 | Test-MSE 317.2779 | Regret 0.2389 | Fair-Val 443.4965\n",
      "Epoch 040/50 | Train-Loss 480.5297 | Test-MSE 293.1634 | Regret 0.2424 | Fair-Val 412.6492\n",
      "Epoch 050/50 | Train-Loss 445.0822 | Test-MSE 269.2859 | Regret 0.2538 | Fair-Val 380.9242\n",
      "Training finished in 33.04s.\n",
      "Epoch 001/50 | Train-Loss 607.9691 | Test-MSE 362.6300 | Regret 0.3406 | Fair-Val 500.9376\n",
      "Epoch 010/50 | Train-Loss 590.9078 | Test-MSE 356.7569 | Regret 0.3014 | Fair-Val 493.1680\n",
      "Epoch 020/50 | Train-Loss 555.5944 | Test-MSE 340.4618 | Regret 0.2572 | Fair-Val 472.5525\n",
      "Epoch 030/50 | Train-Loss 519.2245 | Test-MSE 318.2266 | Regret 0.2429 | Fair-Val 444.3847\n",
      "Epoch 040/50 | Train-Loss 482.3157 | Test-MSE 293.5640 | Regret 0.2469 | Fair-Val 412.7674\n",
      "Epoch 050/50 | Train-Loss 447.0982 | Test-MSE 269.7176 | Regret 0.2582 | Fair-Val 381.1286\n",
      "Training finished in 33.17s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.2560 | σ = 0.0022\n",
      "[                 MSE]  μ = 269.5017 | σ = 0.2158\n",
      "[            FAIRNESS]  μ = 381.0264 | σ = 0.1022\n",
      "[       TRAINING_TIME]  μ = 33.1049 | σ = 0.0651\n",
      "[              G0_MSE]  μ = 257.1794 | σ = 0.3987\n",
      "[              G1_MSE]  μ = 360.5544 | σ = 1.1352\n",
      "[     G0_DECISION_OBJ]  μ = 19.1606 | σ = 0.0175\n",
      "[     G1_DECISION_OBJ]  μ = 25.6710 | σ = 0.0021\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 0.5, 'Lambda': 0.01, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 3489.4285 | Test-MSE 362.6042 | Regret 0.1304 | Fair-Val 500.8991\n",
      "Epoch 010/50 | Train-Loss 3278.3765 | Test-MSE 357.7361 | Regret 0.1225 | Fair-Val 494.4449\n",
      "Epoch 020/50 | Train-Loss 2871.7559 | Test-MSE 344.5834 | Regret 0.1079 | Fair-Val 477.9135\n",
      "Epoch 030/50 | Train-Loss 2628.3237 | Test-MSE 331.0890 | Regret 0.1003 | Fair-Val 461.0938\n",
      "Epoch 040/50 | Train-Loss 2440.4053 | Test-MSE 322.4749 | Regret 0.0952 | Fair-Val 449.8033\n",
      "Epoch 050/50 | Train-Loss 2255.4436 | Test-MSE 317.8300 | Regret 0.0895 | Fair-Val 442.9916\n",
      "Training finished in 26.81s.\n",
      "Epoch 001/50 | Train-Loss 3493.8040 | Test-MSE 362.6949 | Regret 0.1304 | Fair-Val 501.0302\n",
      "Epoch 010/50 | Train-Loss 3326.5066 | Test-MSE 358.6817 | Regret 0.1235 | Fair-Val 495.8076\n",
      "Epoch 020/50 | Train-Loss 2914.5481 | Test-MSE 345.3899 | Regret 0.1091 | Fair-Val 479.2207\n",
      "Epoch 030/50 | Train-Loss 2695.6169 | Test-MSE 332.0632 | Regret 0.1023 | Fair-Val 462.2491\n",
      "Epoch 040/50 | Train-Loss 2503.4854 | Test-MSE 324.3114 | Regret 0.0977 | Fair-Val 451.9295\n",
      "Epoch 050/50 | Train-Loss 2327.1501 | Test-MSE 319.3383 | Regret 0.0927 | Fair-Val 444.9029\n",
      "Training finished in 26.79s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0911 | σ = 0.0016\n",
      "[                 MSE]  μ = 318.5841 | σ = 0.7542\n",
      "[            FAIRNESS]  μ = 443.9472 | σ = 0.9556\n",
      "[       TRAINING_TIME]  μ = 26.8046 | σ = 0.0101\n",
      "[              G0_MSE]  μ = 302.0558 | σ = 0.8187\n",
      "[              G1_MSE]  μ = 440.7160 | σ = 0.2773\n",
      "[     G0_DECISION_OBJ]  μ = 43.3651 | σ = 0.0709\n",
      "[     G1_DECISION_OBJ]  μ = 88.0161 | σ = 0.2878\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 0.8, 'Lambda': 0.01, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 152.0574 | Test-MSE 362.6281 | Regret 0.0064 | Fair-Val 500.9293\n",
      "Epoch 010/50 | Train-Loss 149.1886 | Test-MSE 361.6919 | Regret 0.0063 | Fair-Val 499.6317\n",
      "Epoch 020/50 | Train-Loss 136.2334 | Test-MSE 355.8088 | Regret 0.0058 | Fair-Val 491.8738\n",
      "Epoch 030/50 | Train-Loss 126.0649 | Test-MSE 349.0585 | Regret 0.0053 | Fair-Val 483.2936\n",
      "Epoch 040/50 | Train-Loss 119.4031 | Test-MSE 341.7682 | Regret 0.0051 | Fair-Val 474.2429\n",
      "Epoch 050/50 | Train-Loss 116.2824 | Test-MSE 338.9649 | Regret 0.0049 | Fair-Val 470.4768\n",
      "Training finished in 47.37s.\n",
      "Epoch 001/50 | Train-Loss 152.3605 | Test-MSE 362.6714 | Regret 0.0064 | Fair-Val 500.9954\n",
      "Epoch 010/50 | Train-Loss 152.4585 | Test-MSE 362.7267 | Regret 0.0064 | Fair-Val 501.0738\n",
      "Epoch 020/50 | Train-Loss 152.3723 | Test-MSE 362.7266 | Regret 0.0064 | Fair-Val 501.0757\n",
      "Epoch 030/50 | Train-Loss 152.3089 | Test-MSE 362.7315 | Regret 0.0064 | Fair-Val 501.0823\n",
      "Epoch 040/50 | Train-Loss 152.2283 | Test-MSE 362.7294 | Regret 0.0064 | Fair-Val 501.0790\n",
      "Epoch 050/50 | Train-Loss 152.2041 | Test-MSE 362.7185 | Regret 0.0064 | Fair-Val 501.0623\n",
      "Training finished in 47.27s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0057 | σ = 0.0007\n",
      "[                 MSE]  μ = 350.8417 | σ = 11.8768\n",
      "[            FAIRNESS]  μ = 485.7695 | σ = 15.2927\n",
      "[       TRAINING_TIME]  μ = 47.3229 | σ = 0.0514\n",
      "[              G0_MSE]  μ = 331.3625 | σ = 10.9008\n",
      "[              G1_MSE]  μ = 494.7790 | σ = 19.0883\n",
      "[     G0_DECISION_OBJ]  μ = 28.6086 | σ = 0.3258\n",
      "[     G1_DECISION_OBJ]  μ = 46.3003 | σ = 0.8459\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 1.5, 'Lambda': 0.01, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 86.4202 | Test-MSE 362.5714 | Regret 0.0560 | Fair-Val 500.8535\n",
      "Epoch 010/50 | Train-Loss 76.9834 | Test-MSE 356.3124 | Regret 0.0496 | Fair-Val 492.6373\n",
      "Epoch 020/50 | Train-Loss 66.7637 | Test-MSE 342.6775 | Regret 0.0430 | Fair-Val 475.4243\n",
      "Epoch 030/50 | Train-Loss 61.4385 | Test-MSE 329.3341 | Regret 0.0397 | Fair-Val 458.5151\n",
      "Epoch 040/50 | Train-Loss 57.1363 | Test-MSE 320.5163 | Regret 0.0375 | Fair-Val 446.7692\n",
      "Epoch 050/50 | Train-Loss 53.2022 | Test-MSE 312.8791 | Regret 0.0352 | Fair-Val 436.4084\n",
      "Training finished in 47.20s.\n",
      "Epoch 001/50 | Train-Loss 86.6851 | Test-MSE 362.6339 | Regret 0.0561 | Fair-Val 500.9431\n",
      "Epoch 010/50 | Train-Loss 79.0827 | Test-MSE 357.4666 | Regret 0.0508 | Fair-Val 494.0437\n",
      "Epoch 020/50 | Train-Loss 67.7124 | Test-MSE 343.8501 | Regret 0.0437 | Fair-Val 476.6892\n",
      "Epoch 030/50 | Train-Loss 61.4646 | Test-MSE 330.9388 | Regret 0.0401 | Fair-Val 460.0937\n",
      "Epoch 040/50 | Train-Loss 56.9825 | Test-MSE 321.8091 | Regret 0.0376 | Fair-Val 447.8821\n",
      "Epoch 050/50 | Train-Loss 52.4767 | Test-MSE 313.8459 | Regret 0.0350 | Fair-Val 437.0841\n",
      "Training finished in 47.06s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0351 | σ = 0.0001\n",
      "[                 MSE]  μ = 313.3625 | σ = 0.4834\n",
      "[            FAIRNESS]  μ = 436.7462 | σ = 0.3379\n",
      "[       TRAINING_TIME]  μ = 47.1312 | σ = 0.0732\n",
      "[              G0_MSE]  μ = 297.3912 | σ = 0.5549\n",
      "[              G1_MSE]  μ = 431.3783 | σ = 0.0453\n",
      "[     G0_DECISION_OBJ]  μ = 21.3419 | σ = 0.0237\n",
      "[     G1_DECISION_OBJ]  μ = 30.0523 | σ = 0.0871\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 2, 'Lambda': 0.01, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 82.3959 | Test-MSE 362.5725 | Regret 0.3399 | Fair-Val 500.8557\n",
      "Epoch 010/50 | Train-Loss 72.1083 | Test-MSE 355.9136 | Regret 0.2945 | Fair-Val 492.1524\n",
      "Epoch 020/50 | Train-Loss 61.3891 | Test-MSE 341.3394 | Regret 0.2517 | Fair-Val 473.8680\n",
      "Epoch 030/50 | Train-Loss 55.2558 | Test-MSE 328.4468 | Regret 0.2308 | Fair-Val 457.2510\n",
      "Epoch 040/50 | Train-Loss 50.3271 | Test-MSE 319.4652 | Regret 0.2162 | Fair-Val 445.0965\n",
      "Epoch 050/50 | Train-Loss 45.7572 | Test-MSE 312.3730 | Regret 0.2004 | Fair-Val 435.2948\n",
      "Training finished in 32.90s.\n",
      "Epoch 001/50 | Train-Loss 82.6911 | Test-MSE 362.6293 | Regret 0.3406 | Fair-Val 500.9367\n",
      "Epoch 010/50 | Train-Loss 73.8588 | Test-MSE 356.7862 | Regret 0.3013 | Fair-Val 493.2169\n",
      "Epoch 020/50 | Train-Loss 62.1570 | Test-MSE 341.9884 | Regret 0.2571 | Fair-Val 474.5046\n",
      "Epoch 030/50 | Train-Loss 56.0395 | Test-MSE 327.7422 | Regret 0.2355 | Fair-Val 456.2224\n",
      "Epoch 040/50 | Train-Loss 51.3042 | Test-MSE 318.3126 | Regret 0.2202 | Fair-Val 443.4914\n",
      "Epoch 050/50 | Train-Loss 46.5120 | Test-MSE 311.9406 | Regret 0.2047 | Fair-Val 434.4656\n",
      "Training finished in 33.25s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.2026 | σ = 0.0021\n",
      "[                 MSE]  μ = 312.1568 | σ = 0.2162\n",
      "[            FAIRNESS]  μ = 434.8802 | σ = 0.4146\n",
      "[       TRAINING_TIME]  μ = 33.0746 | σ = 0.1717\n",
      "[              G0_MSE]  μ = 296.4515 | σ = 0.0690\n",
      "[              G1_MSE]  μ = 428.2074 | σ = 1.3035\n",
      "[     G0_DECISION_OBJ]  μ = 19.3492 | σ = 0.0161\n",
      "[     G1_DECISION_OBJ]  μ = 25.8095 | σ = 0.0781\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 0.5, 'Lambda': 1, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 3484.7598 | Test-MSE 362.6043 | Regret 0.1304 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 3280.8291 | Test-MSE 357.9985 | Regret 0.1230 | Fair-Val 0.6365\n",
      "Epoch 020/50 | Train-Loss 2879.5557 | Test-MSE 344.7477 | Regret 0.1080 | Fair-Val 0.6376\n",
      "Epoch 030/50 | Train-Loss 2626.8643 | Test-MSE 330.8213 | Regret 0.1002 | Fair-Val 0.6402\n",
      "Epoch 040/50 | Train-Loss 2440.8623 | Test-MSE 323.0164 | Regret 0.0952 | Fair-Val 0.6399\n",
      "Epoch 050/50 | Train-Loss 2259.4861 | Test-MSE 318.3794 | Regret 0.0898 | Fair-Val 0.6385\n",
      "Training finished in 26.78s.\n",
      "Epoch 001/50 | Train-Loss 3489.1328 | Test-MSE 362.6949 | Regret 0.1304 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 3338.7751 | Test-MSE 359.3275 | Regret 0.1243 | Fair-Val 0.6370\n",
      "Epoch 020/50 | Train-Loss 2925.3777 | Test-MSE 346.2148 | Regret 0.1094 | Fair-Val 0.6386\n",
      "Epoch 030/50 | Train-Loss 2694.2771 | Test-MSE 332.4736 | Regret 0.1024 | Fair-Val 0.6399\n",
      "Epoch 040/50 | Train-Loss 2497.5725 | Test-MSE 324.4709 | Regret 0.0978 | Fair-Val 0.6387\n",
      "Epoch 050/50 | Train-Loss 2325.6946 | Test-MSE 319.9332 | Regret 0.0929 | Fair-Val 0.6375\n",
      "Training finished in 26.90s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0913 | σ = 0.0016\n",
      "[                 MSE]  μ = 319.1563 | σ = 0.7769\n",
      "[            FAIRNESS]  μ = 0.6380 | σ = 0.0005\n",
      "[       TRAINING_TIME]  μ = 26.8384 | σ = 0.0610\n",
      "[              G0_MSE]  μ = 302.6050 | σ = 0.8333\n",
      "[              G1_MSE]  μ = 441.4578 | σ = 0.3602\n",
      "[     G0_DECISION_OBJ]  μ = 43.1713 | σ = 0.0888\n",
      "[     G1_DECISION_OBJ]  μ = 87.7375 | σ = 0.1166\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 0.8, 'Lambda': 1, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 147.3887 | Test-MSE 362.6260 | Regret 0.0064 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 145.2048 | Test-MSE 362.2499 | Regret 0.0064 | Fair-Val 0.6370\n",
      "Epoch 020/50 | Train-Loss 146.4608 | Test-MSE 362.4838 | Regret 0.0064 | Fair-Val 0.6370\n",
      "Epoch 030/50 | Train-Loss 143.7358 | Test-MSE 361.8066 | Regret 0.0063 | Fair-Val 0.6369\n",
      "Epoch 040/50 | Train-Loss 141.3195 | Test-MSE 360.5800 | Regret 0.0062 | Fair-Val 0.6366\n",
      "Epoch 050/50 | Train-Loss 137.2723 | Test-MSE 359.1167 | Regret 0.0061 | Fair-Val 0.6364\n",
      "Training finished in 47.27s.\n",
      "Epoch 001/50 | Train-Loss 147.6895 | Test-MSE 362.6733 | Regret 0.0064 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 147.6329 | Test-MSE 362.7145 | Regret 0.0064 | Fair-Val 0.6371\n",
      "Epoch 020/50 | Train-Loss 146.3222 | Test-MSE 362.2889 | Regret 0.0064 | Fair-Val 0.6370\n",
      "Epoch 030/50 | Train-Loss 136.7060 | Test-MSE 357.6283 | Regret 0.0060 | Fair-Val 0.6363\n",
      "Epoch 040/50 | Train-Loss 122.4398 | Test-MSE 348.4113 | Regret 0.0054 | Fair-Val 0.6362\n",
      "Epoch 050/50 | Train-Loss 121.3183 | Test-MSE 348.7927 | Regret 0.0054 | Fair-Val 0.6356\n",
      "Training finished in 47.18s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0057 | σ = 0.0003\n",
      "[                 MSE]  μ = 353.9547 | σ = 5.1620\n",
      "[            FAIRNESS]  μ = 0.6360 | σ = 0.0004\n",
      "[       TRAINING_TIME]  μ = 47.2291 | σ = 0.0445\n",
      "[              G0_MSE]  μ = 334.4505 | σ = 4.5687\n",
      "[              G1_MSE]  μ = 498.0763 | σ = 9.5459\n",
      "[     G0_DECISION_OBJ]  μ = 28.5288 | σ = 0.1585\n",
      "[     G1_DECISION_OBJ]  μ = 46.2132 | σ = 0.4855\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 1.5, 'Lambda': 1, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 81.7515 | Test-MSE 362.5714 | Regret 0.0560 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 72.4623 | Test-MSE 356.3532 | Regret 0.0496 | Fair-Val 0.6367\n",
      "Epoch 020/50 | Train-Loss 62.6889 | Test-MSE 343.9731 | Regret 0.0433 | Fair-Val 0.6376\n",
      "Epoch 030/50 | Train-Loss 56.7855 | Test-MSE 330.0533 | Regret 0.0395 | Fair-Val 0.6394\n",
      "Epoch 040/50 | Train-Loss 52.3162 | Test-MSE 318.8893 | Regret 0.0370 | Fair-Val 0.6395\n",
      "Epoch 050/50 | Train-Loss 48.4828 | Test-MSE 313.6570 | Regret 0.0349 | Fair-Val 0.6376\n",
      "Training finished in 47.13s.\n",
      "Epoch 001/50 | Train-Loss 82.0141 | Test-MSE 362.6340 | Regret 0.0561 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 74.0735 | Test-MSE 357.0517 | Regret 0.0504 | Fair-Val 0.6365\n",
      "Epoch 020/50 | Train-Loss 63.2282 | Test-MSE 343.3232 | Regret 0.0437 | Fair-Val 0.6374\n",
      "Epoch 030/50 | Train-Loss 57.6657 | Test-MSE 329.5454 | Regret 0.0403 | Fair-Val 0.6392\n",
      "Epoch 040/50 | Train-Loss 53.6072 | Test-MSE 320.1583 | Regret 0.0378 | Fair-Val 0.6387\n",
      "Epoch 050/50 | Train-Loss 49.6220 | Test-MSE 318.1145 | Regret 0.0357 | Fair-Val 0.6355\n",
      "Training finished in 47.49s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0353 | σ = 0.0004\n",
      "[                 MSE]  μ = 315.8857 | σ = 2.2288\n",
      "[            FAIRNESS]  μ = 0.6365 | σ = 0.0010\n",
      "[       TRAINING_TIME]  μ = 47.3115 | σ = 0.1785\n",
      "[              G0_MSE]  μ = 299.8009 | σ = 2.1475\n",
      "[              G1_MSE]  μ = 434.7404 | σ = 2.8292\n",
      "[     G0_DECISION_OBJ]  μ = 21.3708 | σ = 0.0404\n",
      "[     G1_DECISION_OBJ]  μ = 30.0354 | σ = 0.1516\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 2, 'Lambda': 1, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 77.7271 | Test-MSE 362.5725 | Regret 0.3399 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 67.5537 | Test-MSE 355.9166 | Regret 0.2945 | Fair-Val 0.6368\n",
      "Epoch 020/50 | Train-Loss 57.1065 | Test-MSE 341.2440 | Regret 0.2518 | Fair-Val 0.6387\n",
      "Epoch 030/50 | Train-Loss 51.2329 | Test-MSE 328.6317 | Regret 0.2311 | Fair-Val 0.6393\n",
      "Epoch 040/50 | Train-Loss 46.4362 | Test-MSE 319.3802 | Regret 0.2162 | Fair-Val 0.6383\n",
      "Epoch 050/50 | Train-Loss 42.0284 | Test-MSE 313.0508 | Regret 0.2007 | Fair-Val 0.6370\n",
      "Training finished in 33.22s.\n",
      "Epoch 001/50 | Train-Loss 78.0201 | Test-MSE 362.6293 | Regret 0.3406 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 69.3269 | Test-MSE 356.8070 | Regret 0.3014 | Fair-Val 0.6365\n",
      "Epoch 020/50 | Train-Loss 57.8503 | Test-MSE 342.1476 | Regret 0.2572 | Fair-Val 0.6378\n",
      "Epoch 030/50 | Train-Loss 51.8812 | Test-MSE 327.8453 | Regret 0.2353 | Fair-Val 0.6393\n",
      "Epoch 040/50 | Train-Loss 47.2501 | Test-MSE 318.5032 | Regret 0.2196 | Fair-Val 0.6382\n",
      "Epoch 050/50 | Train-Loss 42.4679 | Test-MSE 312.4862 | Regret 0.2037 | Fair-Val 0.6363\n",
      "Training finished in 33.05s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.2022 | σ = 0.0015\n",
      "[                 MSE]  μ = 312.7685 | σ = 0.2823\n",
      "[            FAIRNESS]  μ = 0.6366 | σ = 0.0003\n",
      "[       TRAINING_TIME]  μ = 33.1353 | σ = 0.0836\n",
      "[              G0_MSE]  μ = 296.9744 | σ = 0.1574\n",
      "[              G1_MSE]  μ = 429.4753 | σ = 1.2050\n",
      "[     G0_DECISION_OBJ]  μ = 19.3479 | σ = 0.0109\n",
      "[     G1_DECISION_OBJ]  μ = 25.8229 | σ = 0.0923\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 0.5, 'Lambda': 10, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 3490.4729 | Test-MSE 362.6043 | Regret 0.1304 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 3280.0054 | Test-MSE 357.6872 | Regret 0.1225 | Fair-Val 0.6366\n",
      "Epoch 020/50 | Train-Loss 2872.3733 | Test-MSE 344.2163 | Regret 0.1078 | Fair-Val 0.6380\n",
      "Epoch 030/50 | Train-Loss 2633.8367 | Test-MSE 330.5254 | Regret 0.1003 | Fair-Val 0.6404\n",
      "Epoch 040/50 | Train-Loss 2448.6770 | Test-MSE 322.9870 | Regret 0.0954 | Fair-Val 0.6400\n",
      "Epoch 050/50 | Train-Loss 2268.6936 | Test-MSE 318.3096 | Regret 0.0899 | Fair-Val 0.6386\n",
      "Training finished in 26.63s.\n",
      "Epoch 001/50 | Train-Loss 3494.8467 | Test-MSE 362.6949 | Regret 0.1304 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 3333.7961 | Test-MSE 358.8811 | Regret 0.1238 | Fair-Val 0.6369\n",
      "Epoch 020/50 | Train-Loss 2922.0986 | Test-MSE 345.7181 | Regret 0.1092 | Fair-Val 0.6385\n",
      "Epoch 030/50 | Train-Loss 2698.8667 | Test-MSE 332.3011 | Regret 0.1023 | Fair-Val 0.6401\n",
      "Epoch 040/50 | Train-Loss 2504.5151 | Test-MSE 323.8446 | Regret 0.0977 | Fair-Val 0.6391\n",
      "Epoch 050/50 | Train-Loss 2330.8889 | Test-MSE 318.9022 | Regret 0.0927 | Fair-Val 0.6379\n",
      "Training finished in 26.79s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0913 | σ = 0.0014\n",
      "[                 MSE]  μ = 318.6059 | σ = 0.2963\n",
      "[            FAIRNESS]  μ = 0.6382 | σ = 0.0003\n",
      "[       TRAINING_TIME]  μ = 26.7112 | σ = 0.0819\n",
      "[              G0_MSE]  μ = 302.0587 | σ = 0.3887\n",
      "[              G1_MSE]  μ = 440.8779 | σ = 0.3866\n",
      "[     G0_DECISION_OBJ]  μ = 43.2749 | σ = 0.0571\n",
      "[     G1_DECISION_OBJ]  μ = 87.7353 | σ = 0.3105\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 0.8, 'Lambda': 10, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 153.1018 | Test-MSE 362.6274 | Regret 0.0064 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 152.2688 | Test-MSE 362.3932 | Regret 0.0064 | Fair-Val 0.6370\n",
      "Epoch 020/50 | Train-Loss 141.8788 | Test-MSE 358.0606 | Regret 0.0059 | Fair-Val 0.6369\n",
      "Epoch 030/50 | Train-Loss 132.9768 | Test-MSE 353.7003 | Regret 0.0056 | Fair-Val 0.6367\n",
      "Epoch 040/50 | Train-Loss 129.2799 | Test-MSE 351.3766 | Regret 0.0055 | Fair-Val 0.6365\n",
      "Epoch 050/50 | Train-Loss 129.1000 | Test-MSE 351.9117 | Regret 0.0055 | Fair-Val 0.6361\n",
      "Training finished in 47.51s.\n",
      "Epoch 001/50 | Train-Loss 153.4033 | Test-MSE 362.6718 | Regret 0.0064 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 152.7323 | Test-MSE 362.5467 | Regret 0.0064 | Fair-Val 0.6371\n",
      "Epoch 020/50 | Train-Loss 151.9885 | Test-MSE 362.3593 | Regret 0.0064 | Fair-Val 0.6370\n",
      "Epoch 030/50 | Train-Loss 149.1088 | Test-MSE 361.2869 | Regret 0.0063 | Fair-Val 0.6370\n",
      "Epoch 040/50 | Train-Loss 144.0506 | Test-MSE 359.4178 | Regret 0.0061 | Fair-Val 0.6369\n",
      "Epoch 050/50 | Train-Loss 139.2262 | Test-MSE 356.9792 | Regret 0.0059 | Fair-Val 0.6367\n",
      "Training finished in 47.34s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0057 | σ = 0.0002\n",
      "[                 MSE]  μ = 354.4455 | σ = 2.5337\n",
      "[            FAIRNESS]  μ = 0.6364 | σ = 0.0003\n",
      "[       TRAINING_TIME]  μ = 47.4242 | σ = 0.0879\n",
      "[              G0_MSE]  μ = 335.0184 | σ = 2.5690\n",
      "[              G1_MSE]  μ = 497.9979 | σ = 2.2731\n",
      "[     G0_DECISION_OBJ]  μ = 28.5268 | σ = 0.0726\n",
      "[     G1_DECISION_OBJ]  μ = 46.4479 | σ = 0.0962\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 1.5, 'Lambda': 10, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 87.4646 | Test-MSE 362.5714 | Regret 0.0560 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 78.1282 | Test-MSE 356.3479 | Regret 0.0496 | Fair-Val 0.6366\n",
      "Epoch 020/50 | Train-Loss 68.1179 | Test-MSE 342.9775 | Regret 0.0430 | Fair-Val 0.6380\n",
      "Epoch 030/50 | Train-Loss 62.6601 | Test-MSE 331.6877 | Regret 0.0398 | Fair-Val 0.6386\n",
      "Epoch 040/50 | Train-Loss 58.4704 | Test-MSE 322.6144 | Regret 0.0374 | Fair-Val 0.6383\n",
      "Epoch 050/50 | Train-Loss 54.6296 | Test-MSE 315.8568 | Regret 0.0352 | Fair-Val 0.6372\n",
      "Training finished in 47.30s.\n",
      "Epoch 001/50 | Train-Loss 87.7279 | Test-MSE 362.6340 | Regret 0.0561 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 79.7798 | Test-MSE 357.1113 | Regret 0.0505 | Fair-Val 0.6365\n",
      "Epoch 020/50 | Train-Loss 68.9765 | Test-MSE 343.8828 | Regret 0.0437 | Fair-Val 0.6372\n",
      "Epoch 030/50 | Train-Loss 62.9180 | Test-MSE 330.5881 | Regret 0.0400 | Fair-Val 0.6386\n",
      "Epoch 040/50 | Train-Loss 58.7991 | Test-MSE 320.3552 | Regret 0.0376 | Fair-Val 0.6390\n",
      "Epoch 050/50 | Train-Loss 54.3071 | Test-MSE 313.0080 | Regret 0.0350 | Fair-Val 0.6377\n",
      "Training finished in 47.19s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0351 | σ = 0.0001\n",
      "[                 MSE]  μ = 314.4324 | σ = 1.4244\n",
      "[            FAIRNESS]  μ = 0.6374 | σ = 0.0003\n",
      "[       TRAINING_TIME]  μ = 47.2436 | σ = 0.0526\n",
      "[              G0_MSE]  μ = 298.3928 | σ = 1.2775\n",
      "[              G1_MSE]  μ = 432.9533 | σ = 2.5101\n",
      "[     G0_DECISION_OBJ]  μ = 21.3509 | σ = 0.0031\n",
      "[     G1_DECISION_OBJ]  μ = 30.0531 | σ = 0.0553\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Grad Method': 'finite-diff', 'Alpha': 2, 'Lambda': 10, 'Fairness': 'atkinson'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 83.4402 | Test-MSE 362.5726 | Regret 0.3399 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 73.2405 | Test-MSE 355.9210 | Regret 0.2945 | Fair-Val 0.6367\n",
      "Epoch 020/50 | Train-Loss 62.7407 | Test-MSE 341.2552 | Regret 0.2516 | Fair-Val 0.6386\n",
      "Epoch 030/50 | Train-Loss 56.8586 | Test-MSE 328.2843 | Regret 0.2307 | Fair-Val 0.6394\n",
      "Epoch 040/50 | Train-Loss 52.0651 | Test-MSE 319.4492 | Regret 0.2161 | Fair-Val 0.6382\n",
      "Epoch 050/50 | Train-Loss 47.6311 | Test-MSE 312.9024 | Regret 0.2004 | Fair-Val 0.6370\n",
      "Training finished in 33.11s.\n",
      "Epoch 001/50 | Train-Loss 83.7338 | Test-MSE 362.6293 | Regret 0.3406 | Fair-Val 0.6371\n",
      "Epoch 010/50 | Train-Loss 75.0632 | Test-MSE 356.8482 | Regret 0.3016 | Fair-Val 0.6365\n",
      "Epoch 020/50 | Train-Loss 63.5261 | Test-MSE 342.0879 | Regret 0.2572 | Fair-Val 0.6378\n",
      "Epoch 030/50 | Train-Loss 57.6270 | Test-MSE 327.9438 | Regret 0.2355 | Fair-Val 0.6392\n",
      "Epoch 040/50 | Train-Loss 53.0244 | Test-MSE 318.7910 | Regret 0.2202 | Fair-Val 0.6380\n",
      "Epoch 050/50 | Train-Loss 48.3334 | Test-MSE 313.4145 | Regret 0.2047 | Fair-Val 0.6358\n",
      "Training finished in 33.11s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.2026 | σ = 0.0021\n",
      "[                 MSE]  μ = 313.1584 | σ = 0.2561\n",
      "[            FAIRNESS]  μ = 0.6364 | σ = 0.0006\n",
      "[       TRAINING_TIME]  μ = 33.1122 | σ = 0.0026\n",
      "[              G0_MSE]  μ = 297.3667 | σ = 0.3604\n",
      "[              G1_MSE]  μ = 429.8478 | σ = 0.5149\n",
      "[     G0_DECISION_OBJ]  μ = 19.3559 | σ = 0.0212\n",
      "[     G1_DECISION_OBJ]  μ = 25.8281 | σ = 0.0974\n",
      "\n",
      "==========================================================================================\n",
      "                           GRID SEARCH COMPLETE\n",
      "==========================================================================================\n",
      "    Group  Grad Method  Alpha  Lambda  Fairness  G0_decision_obj  G0_decision_obj_std      G0_mse  G0_mse_std  G1_decision_obj  G1_decision_obj_std      G1_mse  G1_mse_std    fairness  fairness_std         mse    mse_std    regret    regret_std  training_time  training_time_std\n",
      "0    True  closed-form    0.5    0.00       mad        30.127992             0.153557  311.283081    1.147400       216.172003             4.117578  439.731506    0.287384   64.224213      0.430008  326.594147   1.044861  0.048962  3.146672e-04     356.810428          89.168719\n",
      "1    True  closed-form    0.8    0.00       mad        18.736695             0.000107  342.274979    0.000748       155.419681             0.000162  513.964661    0.000000   85.844841      0.000374  362.740448   0.000641  0.001252  1.377687e-08     413.292534          50.974407\n",
      "2    True  closed-form    1.5    0.00       mad        18.673939             0.008606  298.204025    0.077560        60.478945             0.157337  431.358139    0.945847   66.577057      0.434143  314.076004   0.181046  0.017142  1.828126e-04     347.617205           5.024435\n",
      "3    True  closed-form    2.0    0.00       mad        19.348098             0.017038  297.031342    0.132141        25.811116             0.093376  429.459763    0.805038   66.214211      0.468590  312.816849   0.020432  0.201981  1.943001e-03     335.318513          67.203998\n",
      "4    True  closed-form    0.5    1.00       mad        29.889186             0.103751  295.401215    0.622772       226.688633             5.046424  396.442627    3.691589   50.520706      1.534409  307.445358   0.988571  0.064356  4.577051e-04     321.379383          25.349991\n",
      "5    True  closed-form    0.8    1.00       mad        19.311031             0.009944  295.394150    0.617813       162.825313             0.547032  396.417847    3.681122   50.511848      1.531654  307.436203   0.982956  0.001125  8.560902e-08     302.020265          22.758087\n",
      "6    True  closed-form    1.5    1.00       mad        18.727104             0.008132  293.750702    0.426697        59.363848             0.082239  394.835510    3.570374   50.542404      1.571838  305.799973   0.801437  0.022357  6.729694e-05     282.713362          14.016997\n",
      "7    True  closed-form    2.0    1.00       mad        19.286027             0.000333  280.367828    0.023926        24.922992             0.071382  383.752075    1.057556   51.692123      0.516815  292.691208   0.147141  0.230112  3.025425e-03     268.356308           0.093494\n",
      "8    True  closed-form    0.5    0.01       mad        30.165503             0.051542  294.031555    0.528442       227.147262             4.819997  395.928284    3.834045   50.948364      1.652802  306.177658   0.922470  0.063454  6.089461e-04     342.780732          76.314265\n",
      "9    True  closed-form    0.8    0.01       mad        19.310260             0.007055  295.294022    0.378342       162.814421             0.557808  396.257584    3.403702   50.481781      1.512680  307.328873   0.738968  0.001124  2.145584e-07     351.243889          10.698356\n",
      "10   True  closed-form    1.5    0.01       mad        18.652487             0.002613  289.200348    0.277222        59.964769             0.182072  405.662308    1.130753   58.230980      0.426765  303.082657   0.378983  0.018023  2.780843e-04     327.246849          57.976078\n",
      "11   True  closed-form    2.0    0.01       mad        19.347841             0.015813  296.602280    0.120560        25.784118             0.094009  428.011185    0.771469   65.704453      0.446014  312.266235   0.014221  0.202373  1.932792e-03     333.824822          60.981295\n",
      "12   True  closed-form    0.5    1.00  atkinson        29.809692             0.058314  308.655197    0.585587       217.915773             4.086658  430.420212    0.699692    0.003282      0.000074  323.169586   0.432373  0.050238  1.608174e-04     381.653873          94.935365\n",
      "13   True  closed-form    0.8    1.00  atkinson        19.176494             0.056167  307.678177    2.168442       162.534878             0.362062  416.077728    5.337860    0.002674      0.000108  320.599426   2.546234  0.001082  4.403082e-06     260.855617           0.072362\n",
      "14   True  closed-form    1.5    1.00  atkinson        18.673904             0.008324  298.133179    0.074707        60.475925             0.159315  431.089371    0.932663    0.004087      0.000045  313.981567   0.176971  0.017153  1.893657e-04     261.676541           0.758362\n",
      "15   True  closed-form    2.0    1.00  atkinson        19.348125             0.017037  297.027100    0.132355        25.810999             0.093254  429.447754    0.804718    0.004085      0.000055  312.811661   0.020676  0.201980  1.944783e-03     260.208532           0.624724\n",
      "16   True  closed-form    0.5   10.00  atkinson        29.137515             0.120807  305.296234    0.593170       222.646105             2.865524  415.780457    2.777954    0.002807      0.000091  318.465958   0.853622  0.055865  2.887389e-04     260.161036           0.332182\n",
      "17   True  closed-form    0.8   10.00  atkinson        19.131445             0.021126  309.930969    0.367737       162.991428             0.409647  415.221207    2.590073    0.002502      0.000091  322.481567   0.632599  0.001107  3.107693e-06     334.887659          74.053387\n",
      "18   True  closed-form    1.5   10.00  atkinson        18.675130             0.008058  297.537277    0.078384        60.422764             0.161879  428.581924    0.816055    0.003997      0.000038  313.157822   0.166336  0.017206  1.855059e-04     483.574435          16.782740\n",
      "19   True  closed-form    2.0   10.00  atkinson        19.348245             0.016890  297.002625    0.127319        25.808597             0.093372  429.343567    0.804291    0.004081      0.000054  312.777664   0.016251  0.202003  1.940883e-03     289.190846          30.093752\n",
      "20   True  finite-diff    0.5    0.00       mad        32.440074             0.137797  303.461411    0.562363       203.282172             2.346007  442.677536    0.257492   69.608063      0.409927  320.055984   0.464645  0.045673  2.835083e-04      80.025470           0.503780\n",
      "21   True  finite-diff    0.8    0.00       mad        19.440755             0.009630  302.568237    1.382599       160.538770             0.017561  439.033661    2.739502   68.232712      0.678452  318.834930   1.544342  0.000890  8.397202e-06     141.071180           0.142780\n",
      "22   True  finite-diff    1.5    0.00       mad        18.668154             0.003082  298.675995    0.428436        60.443449             0.104977  431.609497    1.928741   66.466751      0.750153  314.521652   0.607285  0.017362  2.160916e-04     141.901960           0.357591\n",
      "23   True  finite-diff    2.0    0.00       mad        19.349076             0.020656  297.284485    0.269043        25.826922             0.086134  429.909637    0.700714   66.312576      0.484879  313.093399   0.153458  0.202229  2.292502e-03      98.594478           0.206692\n",
      "24   True  finite-diff    0.5    1.00       mad        31.959222             0.078717  287.428085    0.456161       226.662278             1.871826  390.571167    2.651245   51.571541      1.097542  299.722748   0.717834  0.059232  8.418922e-04      80.993968           0.087995\n",
      "25   True  finite-diff    0.8    1.00       mad        19.311278             0.009858  295.388367    0.615509       162.825643             0.545056  396.436951    3.679932   50.524292      1.532211  307.433365   0.980850  0.001124  1.757366e-07     141.762731           0.216416\n",
      "26   True  finite-diff    1.5    1.00       mad        18.726662             0.008144  293.726746    0.415253        59.368047             0.084134  394.849258    3.564346   50.561256      1.574547  305.780548   0.790619  0.022363  6.879554e-05     141.619686           0.319366\n",
      "27   True  finite-diff    2.0    1.00       mad        19.283873             0.006623  280.449066    0.309326        24.927426             0.050312  383.934952    0.778946   51.742943      0.544136  292.784622   0.179611  0.230130  2.877340e-03      98.761334           0.227441\n",
      "28   True  finite-diff    0.5    0.01       mad        32.351941             0.125518  302.443192    0.646347       204.044674             2.545227  437.314285    0.149429   67.435547      0.248459  318.519806   0.587158  0.045953  3.445241e-04      80.796718           0.094068\n",
      "29   True  finite-diff    0.8    0.01       mad        19.371889             0.017987  291.258530    1.620743       162.740349             0.500327  393.143570    5.014053   50.942520      1.696655  303.403214   2.025223  0.001103  4.763031e-07     141.401492           0.254311\n",
      "30   True  finite-diff    1.5    0.01       mad        18.651559             0.010322  289.854599    0.360092        60.011604             0.152243  407.095322    0.405777   58.620361      0.382935  303.829697   0.268814  0.018091  2.493663e-04     142.143440           0.271122\n",
      "31   True  finite-diff    2.0    0.01       mad        19.338137             0.020689  296.191422    0.364395        25.786531             0.098800  427.373199    0.457916   65.590889      0.411156  311.828278   0.266388  0.202774  1.900362e-03      98.866663           0.296128\n",
      "32   True  finite-diff    0.5    1.00  atkinson        32.419620             0.105356  303.292740    0.768906       203.498687             2.454729  442.352600    0.172241    0.004294      0.000071  319.868683   0.656708  0.045622  3.170972e-04      80.944730           0.385182\n",
      "33   True  finite-diff    0.8    1.00  atkinson        19.412646             0.011505  301.645523    0.943069       160.341040             0.120336  434.147797    1.376282    0.003979      0.000001  317.439835   0.994705  0.000896  9.881984e-06     141.667355           0.705469\n",
      "34   True  finite-diff    1.5    1.00  atkinson        18.686272             0.013149  299.356598    0.254639        60.555445             0.188008  433.075058    0.238052    0.004099      0.000033  315.295837   0.195923  0.017271  1.255547e-04     142.515020           0.212499\n",
      "35   True  finite-diff    2.0    1.00  atkinson        19.340920             0.024802  296.528076    0.431519        25.826178             0.103793  428.805893    0.412216    0.004089      0.000057  312.295593   0.330933  0.201826  2.174092e-03      98.563629           0.424727\n",
      "36   True  finite-diff    0.5   10.00  atkinson        32.418371             0.136208  303.258102    0.529892       203.511159             2.349788  441.971878    0.266800    0.004276      0.000057  319.792786   0.434937  0.045663  3.069763e-04      80.958567           0.203918\n",
      "37   True  finite-diff    0.8   10.00  atkinson        19.426416             0.023904  295.713593    0.702301       161.994648             0.020136  410.895859    2.020340    0.003207      0.000053  309.443359   0.859406  0.000955  1.085271e-05     141.619197           0.372659\n",
      "38   True  finite-diff    1.5   10.00  atkinson        18.674688             0.013530  298.052032    0.589844        60.489886             0.218788  429.695496    0.542267    0.004018      0.000017  313.743942   0.584183  0.017303  1.879011e-04     142.014107           0.385367\n",
      "39   True  finite-diff    2.0   10.00  atkinson        19.335897             0.023009  296.392838    0.432846        25.811462             0.108224  428.481461    0.279953    0.004082      0.000050  312.137772   0.347885  0.201960  1.777925e-03      98.883320           0.378155\n",
      "40  False  closed-form    0.5    0.00       mad        36.598267             0.109877  333.087189    0.585205        60.988266             0.739748  493.493607    0.278946  486.097916      0.781723  352.207642   0.548706  0.121414  4.971881e-04       2.509469           0.064448\n",
      "41  False  closed-form    0.8    0.00       mad        28.444286             0.000333  327.462524    0.656860        45.764526             0.089727  484.407455    0.127518  477.412704      0.854843  346.170364   0.593735  0.005420  4.573330e-05       2.545181           0.001844\n",
      "42  False  closed-form    1.5    0.00       mad        21.102806             0.027165  310.324188    1.081451        30.525312             0.126638  469.737442    1.066605  465.758530      1.129715  329.326218   0.825424  0.067431  1.956726e-04       2.501578           0.052179\n",
      "43  False  closed-form    2.0    0.00       mad        18.770414             0.019123  298.451950    0.477707        25.880526             0.096912  446.695877    1.761429  447.804047      0.243958  316.122650   0.210785  0.344271  3.403127e-03       2.561180           0.016961\n",
      "44  False  closed-form    0.5    1.00       mad        36.781822             0.148672  332.628403    0.577682        61.413235             0.947800  492.481491    0.293411  485.358627      0.782272  351.682892   0.543823  0.121016  4.780038e-04       2.528471           0.053580\n",
      "45  False  closed-form    0.8    1.00       mad        28.525837             0.006259  323.001602    0.334579        46.025856             0.081877  474.868469    0.436432  470.352844      0.342041  341.104126   0.242676  0.005293  3.565796e-05       2.553082           0.008437\n",
      "46  False  closed-form    1.5    1.00       mad        20.993080             0.047569  264.444016    0.004684        29.698412             0.158728  382.227402    3.574173  394.612091      0.770569  278.483765   0.430176  0.050811  1.129728e-03       2.512772           0.038588\n",
      "47  False  closed-form    2.0    1.00       mad        19.100410             0.025008  252.396515    0.527786        25.917364             0.076517  360.673645    1.683624  375.744370      0.160080  265.303131   0.264160  0.296348  2.606729e-03       2.507960           0.042485\n",
      "48  False  closed-form    0.5    0.01       mad        36.593300             0.137661  332.989578    0.557297        61.227383             0.925735  493.270874    0.241974  485.940231      0.740280  352.095139   0.519699  0.121288  4.382541e-04       2.563147           0.004748\n",
      "49  False  closed-form    0.8    0.01       mad        28.441631             0.001994  327.468781    0.569000        45.741135             0.094915  484.294830    0.046295  477.400925      0.717270  346.162460   0.495651  0.005424  3.903101e-05       2.517341           0.053730\n",
      "50  False  closed-form    1.5    0.01       mad        21.102755             0.027454  310.083267    1.150009        30.516937             0.124204  469.311386    0.962509  465.424698      1.219101  329.063278   0.898209  0.067303  2.233762e-04       2.557584           0.010811\n",
      "51  False  closed-form    2.0    0.01       mad        18.767330             0.020170  297.319443    0.396713        25.851515             0.104918  444.799347    1.945312  446.066132      0.098267  314.899063   0.117538  0.341072  3.724342e-03       2.503787           0.044005\n",
      "52  False  closed-form    0.5    1.00  atkinson        36.598312             0.109871  333.087051    0.585220        60.988346             0.739761  493.493271    0.278915    0.634029      0.000083  352.207474   0.548691  0.121414  4.971508e-04       2.564164           0.016310\n",
      "53  False  closed-form    0.8    1.00  atkinson        28.442904             0.001122  327.515900    0.716644        45.767368             0.092682  484.438843    0.167450    0.632510      0.000062  346.221085   0.651199  0.005423  4.906255e-05       2.521153           0.058431\n",
      "54  False  closed-form    1.5    1.00  atkinson        21.102829             0.027195  310.322723    1.082214        30.525337             0.126676  469.734924    1.064789    0.662214      0.000318  329.324661   0.826279  0.067430  1.955415e-04       2.550607           0.006051\n",
      "55  False  closed-form    2.0    1.00  atkinson        18.769909             0.018841  298.432587    0.476685        25.878639             0.095505  446.669479    1.763077    0.662871      0.000457  316.102448   0.209717  0.344073  3.320705e-03       2.493789           0.054321\n",
      "56  False  closed-form    0.5   10.00  atkinson        36.601532             0.107121  333.070389    0.570145        61.019650             0.770554  493.444031    0.232452    0.634024      0.000078  352.186920   0.529877  0.121399  4.837516e-04       2.502850           0.055165\n",
      "57  False  closed-form    0.8   10.00  atkinson        28.443111             0.003550  327.527130    0.520721        45.746078             0.092823  484.483597    0.044724    0.632505      0.000010  346.236343   0.453293  0.005426  3.684072e-05       2.550021           0.002191\n",
      "58  False  closed-form    1.5   10.00  atkinson        21.102715             0.026946  310.293579    1.094604        30.524523             0.124210  469.671875    1.029572    0.662211      0.000308  329.291458   0.841415  0.067415  2.042371e-04       2.512364           0.046802\n",
      "59  False  closed-form    2.0   10.00  atkinson        18.768955             0.019339  298.264435    0.447083        25.871799             0.098711  446.391724    1.815186    0.662802      0.000482  315.921204   0.177429  0.343235  3.493884e-03       2.556151           0.002696\n",
      "60  False  finite-diff    0.5    0.00       mad        43.272316             0.032328  302.009094    0.407684        87.874710             0.273499  440.932175    0.157425  443.914642      0.331848  318.568741   0.340347  0.091086  1.576737e-03      26.771478           0.062646\n",
      "61  False  finite-diff    0.8    0.00       mad        28.740372             0.003816  328.393219    0.848877        46.997711             0.238913  487.158951    4.575882  480.955154      1.760544  347.318100   1.293137  0.005267  2.418083e-05      47.291440           0.074991\n",
      "62  False  finite-diff    1.5    0.00       mad        21.374504             0.005454  300.360855    0.178391        30.096571             0.115139  436.174744    0.205383  440.659775      0.199173  316.549896   0.181641  0.035195  1.611524e-04      47.084040           0.046245\n",
      "63  False  finite-diff    2.0    0.00       mad        19.361546             0.024570  297.848953    0.712570        25.841549             0.111259  430.837448    0.285416  436.815735      0.619080  313.701172   0.661652  0.202247  1.343552e-03      33.014986           0.151070\n",
      "64  False  finite-diff    0.5    1.00       mad        43.828075             0.170609  300.442856    0.244858        88.521492             0.451897  436.749481    0.568207  441.335892      0.115097  316.690628   0.147934  0.091646  1.630446e-03      26.744072           0.028293\n",
      "65  False  finite-diff    0.8    1.00       mad        28.789730             0.064712  322.168610    2.240997        47.134285             0.406988  472.675735    6.578201  470.848526      3.541061  340.109070   2.757965  0.005091  4.214122e-05      47.268677           0.133146\n",
      "66  False  finite-diff    1.5    1.00       mad        21.202452             0.000547  259.013245    1.297272        29.707054             0.009546  363.628418    3.143250  383.573578      2.115814  271.483368   1.517303  0.041537  8.780361e-04      47.122964           0.010001\n",
      "67  False  finite-diff    2.0    1.00       mad        19.160568             0.017468  257.179398    0.398697        25.670982             0.002129  360.554443    1.135223  381.026382      0.102219  269.501724   0.215836  0.256005  2.227670e-03      33.104889           0.065147\n",
      "68  False  finite-diff    0.5    0.01       mad        43.365128             0.070877  302.055847    0.818726        88.016129             0.287792  440.716003    0.277283  443.947235      0.955627  318.584122   0.754166  0.091111  1.563412e-03      26.804620           0.010089\n",
      "69  False  finite-diff    0.8    0.01       mad        28.608627             0.325810  331.362488   10.900848        46.300278             0.845861  494.779007   19.088303  485.769547     15.292709  350.841736  11.876801  0.005675  7.422024e-04      47.322918           0.051368\n",
      "70  False  finite-diff    1.5    0.01       mad        21.341911             0.023690  297.391190    0.554947        30.052258             0.087053  431.378311    0.045334  436.746231      0.337875  313.362488   0.483398  0.035136  1.067067e-04      47.131187           0.073202\n",
      "71  False  finite-diff    2.0    0.01       mad        19.349205             0.016148  296.451477    0.069031        25.809513             0.078086  428.207397    1.303467  434.880203      0.414597  312.156784   0.216202  0.202565  2.133664e-03      33.074575           0.171733\n",
      "72  False  finite-diff    0.5    1.00  atkinson        43.171268             0.088779  302.605026    0.833328        87.737457             0.116615  441.457794    0.360168    0.638020      0.000483  319.156281   0.776917  0.091319  1.562069e-03      26.838426           0.061031\n",
      "73  False  finite-diff    0.8    1.00  atkinson        28.528835             0.158525  334.450500    4.568726        46.213173             0.485506  498.076324    9.545898    0.636037      0.000399  353.954697   5.162003  0.005736  3.182057e-04      47.229113           0.044526\n",
      "74  False  finite-diff    1.5    1.00  atkinson        21.370831             0.040446  299.800934    2.147522        30.035378             0.151629  434.740448    2.829193    0.636537      0.001033  315.885727   2.228775  0.035283  4.189177e-04      47.311483           0.178460\n",
      "75  False  finite-diff    2.0    1.00  atkinson        19.347893             0.010860  296.974442    0.157425        25.822910             0.092262  429.475281    1.204956    0.636616      0.000342  312.768509   0.282303  0.202192  1.480711e-03      33.135343           0.083633\n",
      "76  False  finite-diff    0.5   10.00  atkinson        43.274914             0.057114  302.058655    0.388702        87.735321             0.310474  440.877945    0.386581    0.638234      0.000325  318.605896   0.296265  0.091336  1.401652e-03      26.711233           0.081861\n",
      "77  False  finite-diff    0.8   10.00  atkinson        28.526802             0.072583  335.018356    2.569016        46.447853             0.096189  497.997879    2.273087    0.636384      0.000318  354.445465   2.533722  0.005681  1.798668e-04      47.424220           0.087940\n",
      "78  False  finite-diff    1.5   10.00  atkinson        21.350918             0.003082  298.392761    1.277496        30.053055             0.055346  432.953278    2.510071    0.637423      0.000267  314.432404   1.424408  0.035097  7.935272e-05      47.243608           0.052626\n",
      "79  False  finite-diff    2.0   10.00  atkinson        19.355927             0.021216  297.366684    0.360397        25.828056             0.097358  429.847809    0.514923    0.636420      0.000576  313.158447   0.256073  0.202568  2.123141e-03      33.112170           0.002609\n",
      "\n",
      "--- LaTeX Table Output ---\n",
      "\\begin{table}\n",
      "\\caption{Averaged Experimental Results Across Different Parameters.}\n",
      "\\label{tab:avg_exp_results_expanded}\n",
      "\\begin{tabular}{rlrrlrrrrrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "Group & Grad Method & Alpha & Lambda & Fairness & G0_decision_obj & G0_decision_obj_std & G0_mse & G0_mse_std & G1_decision_obj & G1_decision_obj_std & G1_mse & G1_mse_std & fairness & fairness_std & mse & mse_std & regret & regret_std & training_time & training_time_std \\\\\n",
      "\\midrule\n",
      "True & closed-form & 0.5000 & 0.0000 & mad & 30.1280 & 0.1536 & 311.2831 & 1.1474 & 216.1720 & 4.1176 & 439.7315 & 0.2874 & 64.2242 & 0.4300 & 326.5941 & 1.0449 & 0.0490 & 0.0003 & 356.8104 & 89.1687 \\\\\n",
      "True & closed-form & 0.8000 & 0.0000 & mad & 18.7367 & 0.0001 & 342.2750 & 0.0007 & 155.4197 & 0.0002 & 513.9647 & 0.0000 & 85.8448 & 0.0004 & 362.7404 & 0.0006 & 0.0013 & 0.0000 & 413.2925 & 50.9744 \\\\\n",
      "True & closed-form & 1.5000 & 0.0000 & mad & 18.6739 & 0.0086 & 298.2040 & 0.0776 & 60.4789 & 0.1573 & 431.3581 & 0.9458 & 66.5771 & 0.4341 & 314.0760 & 0.1810 & 0.0171 & 0.0002 & 347.6172 & 5.0244 \\\\\n",
      "True & closed-form & 2.0000 & 0.0000 & mad & 19.3481 & 0.0170 & 297.0313 & 0.1321 & 25.8111 & 0.0934 & 429.4598 & 0.8050 & 66.2142 & 0.4686 & 312.8168 & 0.0204 & 0.2020 & 0.0019 & 335.3185 & 67.2040 \\\\\n",
      "True & closed-form & 0.5000 & 1.0000 & mad & 29.8892 & 0.1038 & 295.4012 & 0.6228 & 226.6886 & 5.0464 & 396.4426 & 3.6916 & 50.5207 & 1.5344 & 307.4454 & 0.9886 & 0.0644 & 0.0005 & 321.3794 & 25.3500 \\\\\n",
      "True & closed-form & 0.8000 & 1.0000 & mad & 19.3110 & 0.0099 & 295.3941 & 0.6178 & 162.8253 & 0.5470 & 396.4178 & 3.6811 & 50.5118 & 1.5317 & 307.4362 & 0.9830 & 0.0011 & 0.0000 & 302.0203 & 22.7581 \\\\\n",
      "True & closed-form & 1.5000 & 1.0000 & mad & 18.7271 & 0.0081 & 293.7507 & 0.4267 & 59.3638 & 0.0822 & 394.8355 & 3.5704 & 50.5424 & 1.5718 & 305.8000 & 0.8014 & 0.0224 & 0.0001 & 282.7134 & 14.0170 \\\\\n",
      "True & closed-form & 2.0000 & 1.0000 & mad & 19.2860 & 0.0003 & 280.3678 & 0.0239 & 24.9230 & 0.0714 & 383.7521 & 1.0576 & 51.6921 & 0.5168 & 292.6912 & 0.1471 & 0.2301 & 0.0030 & 268.3563 & 0.0935 \\\\\n",
      "True & closed-form & 0.5000 & 0.0100 & mad & 30.1655 & 0.0515 & 294.0316 & 0.5284 & 227.1473 & 4.8200 & 395.9283 & 3.8340 & 50.9484 & 1.6528 & 306.1777 & 0.9225 & 0.0635 & 0.0006 & 342.7807 & 76.3143 \\\\\n",
      "True & closed-form & 0.8000 & 0.0100 & mad & 19.3103 & 0.0071 & 295.2940 & 0.3783 & 162.8144 & 0.5578 & 396.2576 & 3.4037 & 50.4818 & 1.5127 & 307.3289 & 0.7390 & 0.0011 & 0.0000 & 351.2439 & 10.6984 \\\\\n",
      "True & closed-form & 1.5000 & 0.0100 & mad & 18.6525 & 0.0026 & 289.2003 & 0.2772 & 59.9648 & 0.1821 & 405.6623 & 1.1308 & 58.2310 & 0.4268 & 303.0827 & 0.3790 & 0.0180 & 0.0003 & 327.2468 & 57.9761 \\\\\n",
      "True & closed-form & 2.0000 & 0.0100 & mad & 19.3478 & 0.0158 & 296.6023 & 0.1206 & 25.7841 & 0.0940 & 428.0112 & 0.7715 & 65.7045 & 0.4460 & 312.2662 & 0.0142 & 0.2024 & 0.0019 & 333.8248 & 60.9813 \\\\\n",
      "True & closed-form & 0.5000 & 1.0000 & atkinson & 29.8097 & 0.0583 & 308.6552 & 0.5856 & 217.9158 & 4.0867 & 430.4202 & 0.6997 & 0.0033 & 0.0001 & 323.1696 & 0.4324 & 0.0502 & 0.0002 & 381.6539 & 94.9354 \\\\\n",
      "True & closed-form & 0.8000 & 1.0000 & atkinson & 19.1765 & 0.0562 & 307.6782 & 2.1684 & 162.5349 & 0.3621 & 416.0777 & 5.3379 & 0.0027 & 0.0001 & 320.5994 & 2.5462 & 0.0011 & 0.0000 & 260.8556 & 0.0724 \\\\\n",
      "True & closed-form & 1.5000 & 1.0000 & atkinson & 18.6739 & 0.0083 & 298.1332 & 0.0747 & 60.4759 & 0.1593 & 431.0894 & 0.9327 & 0.0041 & 0.0000 & 313.9816 & 0.1770 & 0.0172 & 0.0002 & 261.6765 & 0.7584 \\\\\n",
      "True & closed-form & 2.0000 & 1.0000 & atkinson & 19.3481 & 0.0170 & 297.0271 & 0.1324 & 25.8110 & 0.0933 & 429.4478 & 0.8047 & 0.0041 & 0.0001 & 312.8117 & 0.0207 & 0.2020 & 0.0019 & 260.2085 & 0.6247 \\\\\n",
      "True & closed-form & 0.5000 & 10.0000 & atkinson & 29.1375 & 0.1208 & 305.2962 & 0.5932 & 222.6461 & 2.8655 & 415.7805 & 2.7780 & 0.0028 & 0.0001 & 318.4660 & 0.8536 & 0.0559 & 0.0003 & 260.1610 & 0.3322 \\\\\n",
      "True & closed-form & 0.8000 & 10.0000 & atkinson & 19.1314 & 0.0211 & 309.9310 & 0.3677 & 162.9914 & 0.4096 & 415.2212 & 2.5901 & 0.0025 & 0.0001 & 322.4816 & 0.6326 & 0.0011 & 0.0000 & 334.8877 & 74.0534 \\\\\n",
      "True & closed-form & 1.5000 & 10.0000 & atkinson & 18.6751 & 0.0081 & 297.5373 & 0.0784 & 60.4228 & 0.1619 & 428.5819 & 0.8161 & 0.0040 & 0.0000 & 313.1578 & 0.1663 & 0.0172 & 0.0002 & 483.5744 & 16.7827 \\\\\n",
      "True & closed-form & 2.0000 & 10.0000 & atkinson & 19.3482 & 0.0169 & 297.0026 & 0.1273 & 25.8086 & 0.0934 & 429.3436 & 0.8043 & 0.0041 & 0.0001 & 312.7777 & 0.0163 & 0.2020 & 0.0019 & 289.1908 & 30.0938 \\\\\n",
      "True & finite-diff & 0.5000 & 0.0000 & mad & 32.4401 & 0.1378 & 303.4614 & 0.5624 & 203.2822 & 2.3460 & 442.6775 & 0.2575 & 69.6081 & 0.4099 & 320.0560 & 0.4646 & 0.0457 & 0.0003 & 80.0255 & 0.5038 \\\\\n",
      "True & finite-diff & 0.8000 & 0.0000 & mad & 19.4408 & 0.0096 & 302.5682 & 1.3826 & 160.5388 & 0.0176 & 439.0337 & 2.7395 & 68.2327 & 0.6785 & 318.8349 & 1.5443 & 0.0009 & 0.0000 & 141.0712 & 0.1428 \\\\\n",
      "True & finite-diff & 1.5000 & 0.0000 & mad & 18.6682 & 0.0031 & 298.6760 & 0.4284 & 60.4434 & 0.1050 & 431.6095 & 1.9287 & 66.4668 & 0.7502 & 314.5217 & 0.6073 & 0.0174 & 0.0002 & 141.9020 & 0.3576 \\\\\n",
      "True & finite-diff & 2.0000 & 0.0000 & mad & 19.3491 & 0.0207 & 297.2845 & 0.2690 & 25.8269 & 0.0861 & 429.9096 & 0.7007 & 66.3126 & 0.4849 & 313.0934 & 0.1535 & 0.2022 & 0.0023 & 98.5945 & 0.2067 \\\\\n",
      "True & finite-diff & 0.5000 & 1.0000 & mad & 31.9592 & 0.0787 & 287.4281 & 0.4562 & 226.6623 & 1.8718 & 390.5712 & 2.6512 & 51.5715 & 1.0975 & 299.7227 & 0.7178 & 0.0592 & 0.0008 & 80.9940 & 0.0880 \\\\\n",
      "True & finite-diff & 0.8000 & 1.0000 & mad & 19.3113 & 0.0099 & 295.3884 & 0.6155 & 162.8256 & 0.5451 & 396.4370 & 3.6799 & 50.5243 & 1.5322 & 307.4334 & 0.9809 & 0.0011 & 0.0000 & 141.7627 & 0.2164 \\\\\n",
      "True & finite-diff & 1.5000 & 1.0000 & mad & 18.7267 & 0.0081 & 293.7267 & 0.4153 & 59.3680 & 0.0841 & 394.8493 & 3.5643 & 50.5613 & 1.5745 & 305.7805 & 0.7906 & 0.0224 & 0.0001 & 141.6197 & 0.3194 \\\\\n",
      "True & finite-diff & 2.0000 & 1.0000 & mad & 19.2839 & 0.0066 & 280.4491 & 0.3093 & 24.9274 & 0.0503 & 383.9350 & 0.7789 & 51.7429 & 0.5441 & 292.7846 & 0.1796 & 0.2301 & 0.0029 & 98.7613 & 0.2274 \\\\\n",
      "True & finite-diff & 0.5000 & 0.0100 & mad & 32.3519 & 0.1255 & 302.4432 & 0.6463 & 204.0447 & 2.5452 & 437.3143 & 0.1494 & 67.4355 & 0.2485 & 318.5198 & 0.5872 & 0.0460 & 0.0003 & 80.7967 & 0.0941 \\\\\n",
      "True & finite-diff & 0.8000 & 0.0100 & mad & 19.3719 & 0.0180 & 291.2585 & 1.6207 & 162.7403 & 0.5003 & 393.1436 & 5.0141 & 50.9425 & 1.6967 & 303.4032 & 2.0252 & 0.0011 & 0.0000 & 141.4015 & 0.2543 \\\\\n",
      "True & finite-diff & 1.5000 & 0.0100 & mad & 18.6516 & 0.0103 & 289.8546 & 0.3601 & 60.0116 & 0.1522 & 407.0953 & 0.4058 & 58.6204 & 0.3829 & 303.8297 & 0.2688 & 0.0181 & 0.0002 & 142.1434 & 0.2711 \\\\\n",
      "True & finite-diff & 2.0000 & 0.0100 & mad & 19.3381 & 0.0207 & 296.1914 & 0.3644 & 25.7865 & 0.0988 & 427.3732 & 0.4579 & 65.5909 & 0.4112 & 311.8283 & 0.2664 & 0.2028 & 0.0019 & 98.8667 & 0.2961 \\\\\n",
      "True & finite-diff & 0.5000 & 1.0000 & atkinson & 32.4196 & 0.1054 & 303.2927 & 0.7689 & 203.4987 & 2.4547 & 442.3526 & 0.1722 & 0.0043 & 0.0001 & 319.8687 & 0.6567 & 0.0456 & 0.0003 & 80.9447 & 0.3852 \\\\\n",
      "True & finite-diff & 0.8000 & 1.0000 & atkinson & 19.4126 & 0.0115 & 301.6455 & 0.9431 & 160.3410 & 0.1203 & 434.1478 & 1.3763 & 0.0040 & 0.0000 & 317.4398 & 0.9947 & 0.0009 & 0.0000 & 141.6674 & 0.7055 \\\\\n",
      "True & finite-diff & 1.5000 & 1.0000 & atkinson & 18.6863 & 0.0131 & 299.3566 & 0.2546 & 60.5554 & 0.1880 & 433.0751 & 0.2381 & 0.0041 & 0.0000 & 315.2958 & 0.1959 & 0.0173 & 0.0001 & 142.5150 & 0.2125 \\\\\n",
      "True & finite-diff & 2.0000 & 1.0000 & atkinson & 19.3409 & 0.0248 & 296.5281 & 0.4315 & 25.8262 & 0.1038 & 428.8059 & 0.4122 & 0.0041 & 0.0001 & 312.2956 & 0.3309 & 0.2018 & 0.0022 & 98.5636 & 0.4247 \\\\\n",
      "True & finite-diff & 0.5000 & 10.0000 & atkinson & 32.4184 & 0.1362 & 303.2581 & 0.5299 & 203.5112 & 2.3498 & 441.9719 & 0.2668 & 0.0043 & 0.0001 & 319.7928 & 0.4349 & 0.0457 & 0.0003 & 80.9586 & 0.2039 \\\\\n",
      "True & finite-diff & 0.8000 & 10.0000 & atkinson & 19.4264 & 0.0239 & 295.7136 & 0.7023 & 161.9946 & 0.0201 & 410.8959 & 2.0203 & 0.0032 & 0.0001 & 309.4434 & 0.8594 & 0.0010 & 0.0000 & 141.6192 & 0.3727 \\\\\n",
      "True & finite-diff & 1.5000 & 10.0000 & atkinson & 18.6747 & 0.0135 & 298.0520 & 0.5898 & 60.4899 & 0.2188 & 429.6955 & 0.5423 & 0.0040 & 0.0000 & 313.7439 & 0.5842 & 0.0173 & 0.0002 & 142.0141 & 0.3854 \\\\\n",
      "True & finite-diff & 2.0000 & 10.0000 & atkinson & 19.3359 & 0.0230 & 296.3928 & 0.4328 & 25.8115 & 0.1082 & 428.4815 & 0.2800 & 0.0041 & 0.0000 & 312.1378 & 0.3479 & 0.2020 & 0.0018 & 98.8833 & 0.3782 \\\\\n",
      "False & closed-form & 0.5000 & 0.0000 & mad & 36.5983 & 0.1099 & 333.0872 & 0.5852 & 60.9883 & 0.7397 & 493.4936 & 0.2789 & 486.0979 & 0.7817 & 352.2076 & 0.5487 & 0.1214 & 0.0005 & 2.5095 & 0.0644 \\\\\n",
      "False & closed-form & 0.8000 & 0.0000 & mad & 28.4443 & 0.0003 & 327.4625 & 0.6569 & 45.7645 & 0.0897 & 484.4075 & 0.1275 & 477.4127 & 0.8548 & 346.1704 & 0.5937 & 0.0054 & 0.0000 & 2.5452 & 0.0018 \\\\\n",
      "False & closed-form & 1.5000 & 0.0000 & mad & 21.1028 & 0.0272 & 310.3242 & 1.0815 & 30.5253 & 0.1266 & 469.7374 & 1.0666 & 465.7585 & 1.1297 & 329.3262 & 0.8254 & 0.0674 & 0.0002 & 2.5016 & 0.0522 \\\\\n",
      "False & closed-form & 2.0000 & 0.0000 & mad & 18.7704 & 0.0191 & 298.4520 & 0.4777 & 25.8805 & 0.0969 & 446.6959 & 1.7614 & 447.8040 & 0.2440 & 316.1227 & 0.2108 & 0.3443 & 0.0034 & 2.5612 & 0.0170 \\\\\n",
      "False & closed-form & 0.5000 & 1.0000 & mad & 36.7818 & 0.1487 & 332.6284 & 0.5777 & 61.4132 & 0.9478 & 492.4815 & 0.2934 & 485.3586 & 0.7823 & 351.6829 & 0.5438 & 0.1210 & 0.0005 & 2.5285 & 0.0536 \\\\\n",
      "False & closed-form & 0.8000 & 1.0000 & mad & 28.5258 & 0.0063 & 323.0016 & 0.3346 & 46.0259 & 0.0819 & 474.8685 & 0.4364 & 470.3528 & 0.3420 & 341.1041 & 0.2427 & 0.0053 & 0.0000 & 2.5531 & 0.0084 \\\\\n",
      "False & closed-form & 1.5000 & 1.0000 & mad & 20.9931 & 0.0476 & 264.4440 & 0.0047 & 29.6984 & 0.1587 & 382.2274 & 3.5742 & 394.6121 & 0.7706 & 278.4838 & 0.4302 & 0.0508 & 0.0011 & 2.5128 & 0.0386 \\\\\n",
      "False & closed-form & 2.0000 & 1.0000 & mad & 19.1004 & 0.0250 & 252.3965 & 0.5278 & 25.9174 & 0.0765 & 360.6736 & 1.6836 & 375.7444 & 0.1601 & 265.3031 & 0.2642 & 0.2963 & 0.0026 & 2.5080 & 0.0425 \\\\\n",
      "False & closed-form & 0.5000 & 0.0100 & mad & 36.5933 & 0.1377 & 332.9896 & 0.5573 & 61.2274 & 0.9257 & 493.2709 & 0.2420 & 485.9402 & 0.7403 & 352.0951 & 0.5197 & 0.1213 & 0.0004 & 2.5631 & 0.0047 \\\\\n",
      "False & closed-form & 0.8000 & 0.0100 & mad & 28.4416 & 0.0020 & 327.4688 & 0.5690 & 45.7411 & 0.0949 & 484.2948 & 0.0463 & 477.4009 & 0.7173 & 346.1625 & 0.4957 & 0.0054 & 0.0000 & 2.5173 & 0.0537 \\\\\n",
      "False & closed-form & 1.5000 & 0.0100 & mad & 21.1028 & 0.0275 & 310.0833 & 1.1500 & 30.5169 & 0.1242 & 469.3114 & 0.9625 & 465.4247 & 1.2191 & 329.0633 & 0.8982 & 0.0673 & 0.0002 & 2.5576 & 0.0108 \\\\\n",
      "False & closed-form & 2.0000 & 0.0100 & mad & 18.7673 & 0.0202 & 297.3194 & 0.3967 & 25.8515 & 0.1049 & 444.7993 & 1.9453 & 446.0661 & 0.0983 & 314.8991 & 0.1175 & 0.3411 & 0.0037 & 2.5038 & 0.0440 \\\\\n",
      "False & closed-form & 0.5000 & 1.0000 & atkinson & 36.5983 & 0.1099 & 333.0871 & 0.5852 & 60.9883 & 0.7398 & 493.4933 & 0.2789 & 0.6340 & 0.0001 & 352.2075 & 0.5487 & 0.1214 & 0.0005 & 2.5642 & 0.0163 \\\\\n",
      "False & closed-form & 0.8000 & 1.0000 & atkinson & 28.4429 & 0.0011 & 327.5159 & 0.7166 & 45.7674 & 0.0927 & 484.4388 & 0.1674 & 0.6325 & 0.0001 & 346.2211 & 0.6512 & 0.0054 & 0.0000 & 2.5212 & 0.0584 \\\\\n",
      "False & closed-form & 1.5000 & 1.0000 & atkinson & 21.1028 & 0.0272 & 310.3227 & 1.0822 & 30.5253 & 0.1267 & 469.7349 & 1.0648 & 0.6622 & 0.0003 & 329.3247 & 0.8263 & 0.0674 & 0.0002 & 2.5506 & 0.0061 \\\\\n",
      "False & closed-form & 2.0000 & 1.0000 & atkinson & 18.7699 & 0.0188 & 298.4326 & 0.4767 & 25.8786 & 0.0955 & 446.6695 & 1.7631 & 0.6629 & 0.0005 & 316.1024 & 0.2097 & 0.3441 & 0.0033 & 2.4938 & 0.0543 \\\\\n",
      "False & closed-form & 0.5000 & 10.0000 & atkinson & 36.6015 & 0.1071 & 333.0704 & 0.5701 & 61.0196 & 0.7706 & 493.4440 & 0.2325 & 0.6340 & 0.0001 & 352.1869 & 0.5299 & 0.1214 & 0.0005 & 2.5029 & 0.0552 \\\\\n",
      "False & closed-form & 0.8000 & 10.0000 & atkinson & 28.4431 & 0.0035 & 327.5271 & 0.5207 & 45.7461 & 0.0928 & 484.4836 & 0.0447 & 0.6325 & 0.0000 & 346.2363 & 0.4533 & 0.0054 & 0.0000 & 2.5500 & 0.0022 \\\\\n",
      "False & closed-form & 1.5000 & 10.0000 & atkinson & 21.1027 & 0.0269 & 310.2936 & 1.0946 & 30.5245 & 0.1242 & 469.6719 & 1.0296 & 0.6622 & 0.0003 & 329.2915 & 0.8414 & 0.0674 & 0.0002 & 2.5124 & 0.0468 \\\\\n",
      "False & closed-form & 2.0000 & 10.0000 & atkinson & 18.7690 & 0.0193 & 298.2644 & 0.4471 & 25.8718 & 0.0987 & 446.3917 & 1.8152 & 0.6628 & 0.0005 & 315.9212 & 0.1774 & 0.3432 & 0.0035 & 2.5562 & 0.0027 \\\\\n",
      "False & finite-diff & 0.5000 & 0.0000 & mad & 43.2723 & 0.0323 & 302.0091 & 0.4077 & 87.8747 & 0.2735 & 440.9322 & 0.1574 & 443.9146 & 0.3318 & 318.5687 & 0.3403 & 0.0911 & 0.0016 & 26.7715 & 0.0626 \\\\\n",
      "False & finite-diff & 0.8000 & 0.0000 & mad & 28.7404 & 0.0038 & 328.3932 & 0.8489 & 46.9977 & 0.2389 & 487.1590 & 4.5759 & 480.9552 & 1.7605 & 347.3181 & 1.2931 & 0.0053 & 0.0000 & 47.2914 & 0.0750 \\\\\n",
      "False & finite-diff & 1.5000 & 0.0000 & mad & 21.3745 & 0.0055 & 300.3609 & 0.1784 & 30.0966 & 0.1151 & 436.1747 & 0.2054 & 440.6598 & 0.1992 & 316.5499 & 0.1816 & 0.0352 & 0.0002 & 47.0840 & 0.0462 \\\\\n",
      "False & finite-diff & 2.0000 & 0.0000 & mad & 19.3615 & 0.0246 & 297.8490 & 0.7126 & 25.8415 & 0.1113 & 430.8374 & 0.2854 & 436.8157 & 0.6191 & 313.7012 & 0.6617 & 0.2022 & 0.0013 & 33.0150 & 0.1511 \\\\\n",
      "False & finite-diff & 0.5000 & 1.0000 & mad & 43.8281 & 0.1706 & 300.4429 & 0.2449 & 88.5215 & 0.4519 & 436.7495 & 0.5682 & 441.3359 & 0.1151 & 316.6906 & 0.1479 & 0.0916 & 0.0016 & 26.7441 & 0.0283 \\\\\n",
      "False & finite-diff & 0.8000 & 1.0000 & mad & 28.7897 & 0.0647 & 322.1686 & 2.2410 & 47.1343 & 0.4070 & 472.6757 & 6.5782 & 470.8485 & 3.5411 & 340.1091 & 2.7580 & 0.0051 & 0.0000 & 47.2687 & 0.1331 \\\\\n",
      "False & finite-diff & 1.5000 & 1.0000 & mad & 21.2025 & 0.0005 & 259.0132 & 1.2973 & 29.7071 & 0.0095 & 363.6284 & 3.1432 & 383.5736 & 2.1158 & 271.4834 & 1.5173 & 0.0415 & 0.0009 & 47.1230 & 0.0100 \\\\\n",
      "False & finite-diff & 2.0000 & 1.0000 & mad & 19.1606 & 0.0175 & 257.1794 & 0.3987 & 25.6710 & 0.0021 & 360.5544 & 1.1352 & 381.0264 & 0.1022 & 269.5017 & 0.2158 & 0.2560 & 0.0022 & 33.1049 & 0.0651 \\\\\n",
      "False & finite-diff & 0.5000 & 0.0100 & mad & 43.3651 & 0.0709 & 302.0558 & 0.8187 & 88.0161 & 0.2878 & 440.7160 & 0.2773 & 443.9472 & 0.9556 & 318.5841 & 0.7542 & 0.0911 & 0.0016 & 26.8046 & 0.0101 \\\\\n",
      "False & finite-diff & 0.8000 & 0.0100 & mad & 28.6086 & 0.3258 & 331.3625 & 10.9008 & 46.3003 & 0.8459 & 494.7790 & 19.0883 & 485.7695 & 15.2927 & 350.8417 & 11.8768 & 0.0057 & 0.0007 & 47.3229 & 0.0514 \\\\\n",
      "False & finite-diff & 1.5000 & 0.0100 & mad & 21.3419 & 0.0237 & 297.3912 & 0.5549 & 30.0523 & 0.0871 & 431.3783 & 0.0453 & 436.7462 & 0.3379 & 313.3625 & 0.4834 & 0.0351 & 0.0001 & 47.1312 & 0.0732 \\\\\n",
      "False & finite-diff & 2.0000 & 0.0100 & mad & 19.3492 & 0.0161 & 296.4515 & 0.0690 & 25.8095 & 0.0781 & 428.2074 & 1.3035 & 434.8802 & 0.4146 & 312.1568 & 0.2162 & 0.2026 & 0.0021 & 33.0746 & 0.1717 \\\\\n",
      "False & finite-diff & 0.5000 & 1.0000 & atkinson & 43.1713 & 0.0888 & 302.6050 & 0.8333 & 87.7375 & 0.1166 & 441.4578 & 0.3602 & 0.6380 & 0.0005 & 319.1563 & 0.7769 & 0.0913 & 0.0016 & 26.8384 & 0.0610 \\\\\n",
      "False & finite-diff & 0.8000 & 1.0000 & atkinson & 28.5288 & 0.1585 & 334.4505 & 4.5687 & 46.2132 & 0.4855 & 498.0763 & 9.5459 & 0.6360 & 0.0004 & 353.9547 & 5.1620 & 0.0057 & 0.0003 & 47.2291 & 0.0445 \\\\\n",
      "False & finite-diff & 1.5000 & 1.0000 & atkinson & 21.3708 & 0.0404 & 299.8009 & 2.1475 & 30.0354 & 0.1516 & 434.7404 & 2.8292 & 0.6365 & 0.0010 & 315.8857 & 2.2288 & 0.0353 & 0.0004 & 47.3115 & 0.1785 \\\\\n",
      "False & finite-diff & 2.0000 & 1.0000 & atkinson & 19.3479 & 0.0109 & 296.9744 & 0.1574 & 25.8229 & 0.0923 & 429.4753 & 1.2050 & 0.6366 & 0.0003 & 312.7685 & 0.2823 & 0.2022 & 0.0015 & 33.1353 & 0.0836 \\\\\n",
      "False & finite-diff & 0.5000 & 10.0000 & atkinson & 43.2749 & 0.0571 & 302.0587 & 0.3887 & 87.7353 & 0.3105 & 440.8779 & 0.3866 & 0.6382 & 0.0003 & 318.6059 & 0.2963 & 0.0913 & 0.0014 & 26.7112 & 0.0819 \\\\\n",
      "False & finite-diff & 0.8000 & 10.0000 & atkinson & 28.5268 & 0.0726 & 335.0184 & 2.5690 & 46.4479 & 0.0962 & 497.9979 & 2.2731 & 0.6364 & 0.0003 & 354.4455 & 2.5337 & 0.0057 & 0.0002 & 47.4242 & 0.0879 \\\\\n",
      "False & finite-diff & 1.5000 & 10.0000 & atkinson & 21.3509 & 0.0031 & 298.3928 & 1.2775 & 30.0531 & 0.0553 & 432.9533 & 2.5101 & 0.6374 & 0.0003 & 314.4324 & 1.4244 & 0.0351 & 0.0001 & 47.2436 & 0.0526 \\\\\n",
      "False & finite-diff & 2.0000 & 10.0000 & atkinson & 19.3559 & 0.0212 & 297.3667 & 0.3604 & 25.8281 & 0.0974 & 429.8478 & 0.5149 & 0.6364 & 0.0006 & 313.1584 & 0.2561 & 0.2026 & 0.0021 & 33.1122 & 0.0026 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Hyperparameter Grid Definition ---\n",
    "alphas = [0.5, 0.8, 1.5, 2]\n",
    "group_settings = [True, False]\n",
    "grad_methods = ['closed-form', 'finite-diff']  # New parameter\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2.  GRID-SEARCH HARNESS  (only the inner loop changed)\n",
    "# ---------------------------------------------------------------------\n",
    "results_list = []\n",
    "final_model_cf = None\n",
    "final_model_fd = None\n",
    "\n",
    "for group in group_settings:\n",
    "    fairness_types = ['mad', 'atkinson']\n",
    "    for grad_method in grad_methods:\n",
    "        for fairness in fairness_types:\n",
    "            if fairness == 'mad':\n",
    "                fairness_lambdas = [0, 1, 0.01]\n",
    "            elif fairness == 'atkinson':\n",
    "                fairness_lambdas = [0, 1, 10]\n",
    "            else:\n",
    "                fairness_lambdas = [0]\n",
    "            for lam in fairness_lambdas:\n",
    "                if lam == 0 and fairness != fairness_types[0]:\n",
    "                    continue  # skip unattainable combos\n",
    "                for alpha in alphas:\n",
    "\n",
    "                    run_params = {\n",
    "                        'Group': group,\n",
    "                        'Grad Method': grad_method,\n",
    "                        'Alpha': alpha,\n",
    "                        'Lambda': lam,\n",
    "                        'Fairness': fairness\n",
    "                    }\n",
    "                    print(\"\\n\" + \"-\"*70)\n",
    "                    print(f\"RUNNING EXPERIMENT: {run_params}\")\n",
    "                    print(\"-\"*70)\n",
    "\n",
    "                    train_args = dict(\n",
    "                        X_train=feats_train, y_train=b_train, race_train=race_train,\n",
    "                        cost_train=cost_train, gainF_train=gainF_train,\n",
    "                        X_test=feats_test,  y_test=b_test,  race_test=race_test,\n",
    "                        cost_test=cost_test, gainF_test=gainF_test,\n",
    "                        model_class=FairRiskPredictor,\n",
    "                        input_dim=feats_train.shape[1],\n",
    "                        alpha=alpha, Q=Q,\n",
    "                        lambda_fair=lam, fairness_type=fairness,\n",
    "                        group=group, grad_method=grad_method,\n",
    "                        num_epochs=50, lr=0.001\n",
    "                    )\n",
    "\n",
    "                    avg_results, final_model = train_many_trials_regret(\n",
    "                        n_trials=2, **train_args) #type: ignore[call-arg]\n",
    "\n",
    "                    # ---------------- build DataFrame row ------------\n",
    "                    row = run_params.copy()\n",
    "                    row.update(avg_results)          # every metric goes in\n",
    "                    results_list.append(row)\n",
    "                    # ---------------- save the final model ------------\n",
    "                    model_name = f\"predmodel_{fairness}_{lam}_{grad_method}_{group}_{alpha}_NN.pth\"\n",
    "                    model_path = f\"E:/myREPO/Fairness-Decision-Focused-Loss/Organized-FDFL/src/models/FDFL/{model_name}\"\n",
    "                    torch.save(final_model.state_dict(), model_path) # type: ignore[arg-type]\n",
    "\n",
    "# ---------------- DataFrame & LaTeX dump -----------------------------\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Put the hyper-parameters first; everything else follows automatically\n",
    "hp_cols = ['Group', 'Grad Method', 'Alpha', 'Lambda', 'Fairness']\n",
    "other_cols = sorted([c for c in results_df.columns if c not in hp_cols])\n",
    "results_df = results_df[hp_cols + other_cols]\n",
    "\n",
    "latex_table = results_df.to_latex(\n",
    "    index=False,\n",
    "    caption=\"Averaged Experimental Results Across Different Parameters.\",\n",
    "    label=\"tab:avg_exp_results_expanded\",\n",
    "    float_format=\"%.4f\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"                           GRID SEARCH COMPLETE\")\n",
    "print(\"=\"*90)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None,\n",
    "                       'display.width', 1200):\n",
    "    print(results_df)\n",
    "\n",
    "print(\"\\n--- LaTeX Table Output ---\")\n",
    "print(latex_table)\n",
    "\n",
    "# Run NN first, lr = 1e-3\n",
    "results_df.to_csv(\"closed-form-res-NN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256b7a9c",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9440c88b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "fe3af208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Linear Reg with lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "fe681c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85beff10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 0.5, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 28.6403 | Test-MSE 360.5598 | Regret 0.0630 | Fair-Val 84.4475\n",
      "Epoch 010/50 | Train-Loss 27.7569 | Test-MSE 358.7179 | Regret 0.0617 | Fair-Val 83.2841\n",
      "Epoch 020/50 | Train-Loss 26.6246 | Test-MSE 356.1054 | Regret 0.0598 | Fair-Val 81.7882\n",
      "Epoch 030/50 | Train-Loss 25.6684 | Test-MSE 353.4138 | Regret 0.0582 | Fair-Val 80.3669\n",
      "Epoch 040/50 | Train-Loss 24.9282 | Test-MSE 350.8079 | Regret 0.0569 | Fair-Val 79.1400\n",
      "Epoch 050/50 | Train-Loss 24.3867 | Test-MSE 348.5539 | Regret 0.0559 | Fair-Val 78.0377\n",
      "Training finished in 258.01s.\n",
      "Epoch 001/50 | Train-Loss 28.8216 | Test-MSE 360.7564 | Regret 0.0629 | Fair-Val 85.1091\n",
      "Epoch 010/50 | Train-Loss 27.9582 | Test-MSE 359.0159 | Regret 0.0611 | Fair-Val 84.2789\n",
      "Epoch 020/50 | Train-Loss 26.9622 | Test-MSE 356.3358 | Regret 0.0588 | Fair-Val 82.8943\n",
      "Epoch 030/50 | Train-Loss 26.0709 | Test-MSE 353.2612 | Regret 0.0569 | Fair-Val 81.2709\n",
      "Epoch 040/50 | Train-Loss 25.3837 | Test-MSE 350.2787 | Regret 0.0557 | Fair-Val 79.7460\n",
      "Epoch 050/50 | Train-Loss 24.8997 | Test-MSE 347.6046 | Regret 0.0549 | Fair-Val 78.4153\n",
      "Training finished in 257.90s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0554 | σ = 0.0005\n",
      "[                 MSE]  μ = 348.0793 | σ = 0.4746\n",
      "[            FAIRNESS]  μ = 78.2265 | σ = 0.1888\n",
      "[       TRAINING_TIME]  μ = 257.9510 | σ = 0.0554\n",
      "[              G0_MSE]  μ = 329.4301 | σ = 0.5197\n",
      "[              G1_MSE]  μ = 485.8831 | σ = 0.1420\n",
      "[     G0_DECISION_OBJ]  μ = 28.0509 | σ = 0.2424\n",
      "[     G1_DECISION_OBJ]  μ = 186.4247 | σ = 3.1368\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 0.8, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 0.0770 | Test-MSE 360.5602 | Regret 0.0012 | Fair-Val 84.4572\n",
      "Epoch 010/50 | Train-Loss 0.0736 | Test-MSE 358.5839 | Regret 0.0012 | Fair-Val 83.3541\n",
      "Epoch 020/50 | Train-Loss 0.0700 | Test-MSE 355.6268 | Regret 0.0011 | Fair-Val 81.7590\n",
      "Epoch 030/50 | Train-Loss 0.0673 | Test-MSE 352.8184 | Regret 0.0011 | Fair-Val 80.3754\n",
      "Epoch 040/50 | Train-Loss 0.0649 | Test-MSE 350.1938 | Regret 0.0011 | Fair-Val 79.1611\n",
      "Epoch 050/50 | Train-Loss 0.0627 | Test-MSE 347.9506 | Regret 0.0011 | Fair-Val 78.0707\n",
      "Training finished in 258.43s.\n",
      "Epoch 001/50 | Train-Loss 0.0777 | Test-MSE 360.7430 | Regret 0.0012 | Fair-Val 85.0975\n",
      "Epoch 010/50 | Train-Loss 0.0748 | Test-MSE 358.9955 | Regret 0.0012 | Fair-Val 84.2432\n",
      "Epoch 020/50 | Train-Loss 0.0711 | Test-MSE 356.3569 | Regret 0.0011 | Fair-Val 82.7532\n",
      "Epoch 030/50 | Train-Loss 0.0683 | Test-MSE 353.7391 | Regret 0.0011 | Fair-Val 81.1107\n",
      "Epoch 040/50 | Train-Loss 0.0663 | Test-MSE 351.6870 | Regret 0.0011 | Fair-Val 79.7624\n",
      "Epoch 050/50 | Train-Loss 0.0648 | Test-MSE 350.1609 | Regret 0.0011 | Fair-Val 78.5384\n",
      "Training finished in 257.92s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0011 | σ = 0.0000\n",
      "[                 MSE]  μ = 349.0557 | σ = 1.1051\n",
      "[            FAIRNESS]  μ = 78.3046 | σ = 0.2338\n",
      "[       TRAINING_TIME]  μ = 258.1758 | σ = 0.2584\n",
      "[              G0_MSE]  μ = 330.3879 | σ = 1.0494\n",
      "[              G1_MSE]  μ = 486.9970 | σ = 1.5171\n",
      "[     G0_DECISION_OBJ]  μ = 19.0220 | σ = 0.0129\n",
      "[     G1_DECISION_OBJ]  μ = 157.4919 | σ = 0.3509\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 1.5, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 2.5373 | Test-MSE 360.5175 | Regret 0.0266 | Fair-Val 84.4485\n",
      "Epoch 010/50 | Train-Loss 2.4086 | Test-MSE 357.9746 | Regret 0.0255 | Fair-Val 83.3014\n",
      "Epoch 020/50 | Train-Loss 2.2650 | Test-MSE 354.0658 | Regret 0.0242 | Fair-Val 81.7520\n",
      "Epoch 030/50 | Train-Loss 2.1380 | Test-MSE 349.6664 | Regret 0.0231 | Fair-Val 80.1043\n",
      "Epoch 040/50 | Train-Loss 2.0466 | Test-MSE 345.6197 | Regret 0.0223 | Fair-Val 78.6267\n",
      "Epoch 050/50 | Train-Loss 1.9827 | Test-MSE 342.2632 | Regret 0.0217 | Fair-Val 77.3538\n",
      "Training finished in 258.46s.\n",
      "Epoch 001/50 | Train-Loss 2.5729 | Test-MSE 360.6705 | Regret 0.0267 | Fair-Val 85.0893\n",
      "Epoch 010/50 | Train-Loss 2.4394 | Test-MSE 357.9366 | Regret 0.0255 | Fair-Val 84.0753\n",
      "Epoch 020/50 | Train-Loss 2.2911 | Test-MSE 353.9335 | Regret 0.0243 | Fair-Val 82.4075\n",
      "Epoch 030/50 | Train-Loss 2.1729 | Test-MSE 349.8137 | Regret 0.0233 | Fair-Val 80.6339\n",
      "Epoch 040/50 | Train-Loss 2.0959 | Test-MSE 346.2624 | Regret 0.0227 | Fair-Val 79.1787\n",
      "Epoch 050/50 | Train-Loss 2.0362 | Test-MSE 343.3510 | Regret 0.0221 | Fair-Val 78.0074\n",
      "Training finished in 258.19s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0219 | σ = 0.0002\n",
      "[                 MSE]  μ = 342.8071 | σ = 0.5439\n",
      "[            FAIRNESS]  μ = 77.6806 | σ = 0.3268\n",
      "[       TRAINING_TIME]  μ = 258.3254 | σ = 0.1378\n",
      "[              G0_MSE]  μ = 324.2880 | σ = 0.4660\n",
      "[              G1_MSE]  μ = 479.6492 | σ = 1.1196\n",
      "[     G0_DECISION_OBJ]  μ = 18.8340 | σ = 0.0175\n",
      "[     G1_DECISION_OBJ]  μ = 61.5229 | σ = 0.0521\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 2, 'Lambda': 0, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 73.0982 | Test-MSE 360.5104 | Regret 0.3255 | Fair-Val 84.4483\n",
      "Epoch 010/50 | Train-Loss 69.2711 | Test-MSE 357.8800 | Regret 0.3102 | Fair-Val 83.3283\n",
      "Epoch 020/50 | Train-Loss 64.5104 | Test-MSE 353.7810 | Regret 0.2916 | Fair-Val 81.8271\n",
      "Epoch 030/50 | Train-Loss 60.5455 | Test-MSE 349.2481 | Regret 0.2756 | Fair-Val 80.1960\n",
      "Epoch 040/50 | Train-Loss 57.7151 | Test-MSE 345.2078 | Regret 0.2643 | Fair-Val 78.6245\n",
      "Epoch 050/50 | Train-Loss 55.7777 | Test-MSE 341.9214 | Regret 0.2564 | Fair-Val 77.3611\n",
      "Training finished in 258.23s.\n",
      "Epoch 001/50 | Train-Loss 73.9881 | Test-MSE 360.6762 | Regret 0.3265 | Fair-Val 85.0926\n",
      "Epoch 010/50 | Train-Loss 69.9767 | Test-MSE 357.9181 | Regret 0.3106 | Fair-Val 84.1087\n",
      "Epoch 020/50 | Train-Loss 65.4987 | Test-MSE 353.8767 | Regret 0.2930 | Fair-Val 82.4704\n",
      "Epoch 030/50 | Train-Loss 61.8926 | Test-MSE 349.6828 | Regret 0.2797 | Fair-Val 80.7300\n",
      "Epoch 040/50 | Train-Loss 59.3716 | Test-MSE 346.1065 | Regret 0.2704 | Fair-Val 79.2708\n",
      "Epoch 050/50 | Train-Loss 57.3973 | Test-MSE 343.1184 | Regret 0.2629 | Fair-Val 78.1358\n",
      "Training finished in 258.42s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.2596 | σ = 0.0032\n",
      "[                 MSE]  μ = 342.5199 | σ = 0.5985\n",
      "[            FAIRNESS]  μ = 77.7484 | σ = 0.3873\n",
      "[       TRAINING_TIME]  μ = 258.3236 | σ = 0.0924\n",
      "[              G0_MSE]  μ = 323.9847 | σ = 0.5061\n",
      "[              G1_MSE]  μ = 479.4815 | σ = 1.2808\n",
      "[     G0_DECISION_OBJ]  μ = 19.5293 | σ = 0.0385\n",
      "[     G1_DECISION_OBJ]  μ = 26.9073 | σ = 0.0839\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 0.5, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 127.8903 | Test-MSE 360.5876 | Regret 0.0630 | Fair-Val 84.4480\n",
      "Epoch 010/50 | Train-Loss 124.1546 | Test-MSE 358.8936 | Regret 0.0617 | Fair-Val 83.2395\n",
      "Epoch 020/50 | Train-Loss 119.3254 | Test-MSE 356.0041 | Regret 0.0598 | Fair-Val 81.4277\n",
      "Epoch 030/50 | Train-Loss 114.3192 | Test-MSE 352.5167 | Regret 0.0581 | Fair-Val 79.2927\n",
      "Epoch 040/50 | Train-Loss 109.5508 | Test-MSE 348.7690 | Regret 0.0570 | Fair-Val 77.1422\n",
      "Epoch 050/50 | Train-Loss 105.1355 | Test-MSE 344.9907 | Regret 0.0564 | Fair-Val 75.0148\n",
      "Training finished in 259.20s.\n",
      "Epoch 001/50 | Train-Loss 129.1419 | Test-MSE 360.7570 | Regret 0.0629 | Fair-Val 85.1016\n",
      "Epoch 010/50 | Train-Loss 126.1140 | Test-MSE 359.0021 | Regret 0.0612 | Fair-Val 84.1389\n",
      "Epoch 020/50 | Train-Loss 121.4747 | Test-MSE 355.9688 | Regret 0.0589 | Fair-Val 82.3916\n",
      "Epoch 030/50 | Train-Loss 116.1195 | Test-MSE 352.0660 | Regret 0.0570 | Fair-Val 80.1505\n",
      "Epoch 040/50 | Train-Loss 110.7796 | Test-MSE 347.7105 | Regret 0.0558 | Fair-Val 77.7855\n",
      "Epoch 050/50 | Train-Loss 105.7145 | Test-MSE 343.3787 | Regret 0.0552 | Fair-Val 75.3405\n",
      "Training finished in 258.31s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0558 | σ = 0.0006\n",
      "[                 MSE]  μ = 344.1847 | σ = 0.8060\n",
      "[            FAIRNESS]  μ = 75.1776 | σ = 0.1629\n",
      "[       TRAINING_TIME]  μ = 258.7509 | σ = 0.4455\n",
      "[              G0_MSE]  μ = 326.2623 | σ = 0.8448\n",
      "[              G1_MSE]  μ = 476.6176 | σ = 0.5191\n",
      "[     G0_DECISION_OBJ]  μ = 28.6459 | σ = 0.4249\n",
      "[     G1_DECISION_OBJ]  μ = 187.5461 | σ = 0.8749\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 0.8, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 99.3270 | Test-MSE 360.5876 | Regret 0.0012 | Fair-Val 84.4480\n",
      "Epoch 010/50 | Train-Loss 96.3726 | Test-MSE 358.8941 | Regret 0.0012 | Fair-Val 83.2397\n",
      "Epoch 020/50 | Train-Loss 92.5847 | Test-MSE 356.0059 | Regret 0.0011 | Fair-Val 81.4282\n",
      "Epoch 030/50 | Train-Loss 88.5447 | Test-MSE 352.5192 | Regret 0.0011 | Fair-Val 79.2931\n",
      "Epoch 040/50 | Train-Loss 84.4831 | Test-MSE 348.7723 | Regret 0.0011 | Fair-Val 77.1425\n",
      "Epoch 050/50 | Train-Loss 80.5095 | Test-MSE 344.9950 | Regret 0.0011 | Fair-Val 75.0148\n",
      "Training finished in 259.16s.\n",
      "Epoch 001/50 | Train-Loss 100.3981 | Test-MSE 360.7570 | Regret 0.0012 | Fair-Val 85.1016\n",
      "Epoch 010/50 | Train-Loss 98.1912 | Test-MSE 359.0041 | Regret 0.0012 | Fair-Val 84.1394\n",
      "Epoch 020/50 | Train-Loss 94.5304 | Test-MSE 355.9715 | Regret 0.0011 | Fair-Val 82.3922\n",
      "Epoch 030/50 | Train-Loss 90.0957 | Test-MSE 352.0685 | Regret 0.0011 | Fair-Val 80.1508\n",
      "Epoch 040/50 | Train-Loss 85.4361 | Test-MSE 347.7122 | Regret 0.0011 | Fair-Val 77.7853\n",
      "Epoch 050/50 | Train-Loss 80.7559 | Test-MSE 343.3792 | Regret 0.0010 | Fair-Val 75.3395\n",
      "Training finished in 259.37s.\n",
      "\n",
      "============================================================\n",
      "      AVERAGED RESULTS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[              REGRET]  μ = 0.0011 | σ = 0.0000\n",
      "[                 MSE]  μ = 344.1871 | σ = 0.8079\n",
      "[            FAIRNESS]  μ = 75.1772 | σ = 0.1623\n",
      "[       TRAINING_TIME]  μ = 259.2637 | σ = 0.1082\n",
      "[              G0_MSE]  μ = 326.2648 | σ = 0.8466\n",
      "[              G1_MSE]  μ = 476.6192 | σ = 0.5219\n",
      "[     G0_DECISION_OBJ]  μ = 19.0808 | σ = 0.0298\n",
      "[     G1_DECISION_OBJ]  μ = 159.2120 | σ = 0.3901\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': True, 'Grad Method': 'closed-form', 'Alpha': 1.5, 'Lambda': 1, 'Fairness': 'mad'}\n",
      "----------------------------------------------------------------------\n",
      "Epoch 001/50 | Train-Loss 101.7874 | Test-MSE 360.5798 | Regret 0.0266 | Fair-Val 84.4511\n",
      "Epoch 010/50 | Train-Loss 98.7260 | Test-MSE 358.8036 | Regret 0.0258 | Fair-Val 83.2433\n",
      "Epoch 020/50 | Train-Loss 94.8321 | Test-MSE 355.8036 | Regret 0.0246 | Fair-Val 81.4231\n",
      "Epoch 030/50 | Train-Loss 90.7196 | Test-MSE 352.2318 | Regret 0.0237 | Fair-Val 79.2981\n",
      "Epoch 040/50 | Train-Loss 86.6091 | Test-MSE 348.4288 | Regret 0.0230 | Fair-Val 77.1656\n"
     ]
    }
   ],
   "source": [
    "# --- Hyperparameter Grid Definition ---\n",
    "alphas = [0.5, 0.8, 1.5, 2]\n",
    "group_settings = [True, False]\n",
    "grad_methods = ['closed-form', 'finite-diff']  # New parameter\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2.  GRID-SEARCH HARNESS  (only the inner loop changed)\n",
    "# ---------------------------------------------------------------------\n",
    "results_list = []\n",
    "final_model_cf = None\n",
    "final_model_fd = None\n",
    "\n",
    "for group in group_settings:\n",
    "    fairness_types = ['mad', 'atkinson']\n",
    "    for grad_method in grad_methods:\n",
    "        for fairness in fairness_types:\n",
    "            if fairness == 'mad':\n",
    "                fairness_lambdas = [0, 1, 0.01]\n",
    "            elif fairness == 'atkinson':\n",
    "                fairness_lambdas = [0, 1, 10]\n",
    "            else:\n",
    "                fairness_lambdas = [0]\n",
    "            for lam in fairness_lambdas:\n",
    "                if lam == 0 and fairness != fairness_types[0]:\n",
    "                    continue  # skip unattainable combos\n",
    "                for alpha in alphas:\n",
    "\n",
    "                    run_params = {\n",
    "                        'Group': group,\n",
    "                        'Grad Method': grad_method,\n",
    "                        'Alpha': alpha,\n",
    "                        'Lambda': lam,\n",
    "                        'Fairness': fairness\n",
    "                    }\n",
    "                    print(\"\\n\" + \"-\"*70)\n",
    "                    print(f\"RUNNING EXPERIMENT: {run_params}\")\n",
    "                    print(\"-\"*70)\n",
    "\n",
    "                    train_args = dict(\n",
    "                        X_train=feats_train, y_train=b_train, race_train=race_train,\n",
    "                        cost_train=cost_train, gainF_train=gainF_train,\n",
    "                        X_test=feats_test,  y_test=b_test,  race_test=race_test,\n",
    "                        cost_test=cost_test, gainF_test=gainF_test,\n",
    "                        model_class=LinearRegressionModel,\n",
    "                        input_dim=feats_train.shape[1],\n",
    "                        alpha=alpha, Q=Q,\n",
    "                        lambda_fair=lam, fairness_type=fairness,\n",
    "                        group=group, grad_method=grad_method,\n",
    "                        num_epochs=50, lr=0.001\n",
    "                    )\n",
    "\n",
    "                    avg_results, final_model = train_many_trials_regret(\n",
    "                        n_trials=2, **train_args) # type: ignore[call-arg]\n",
    "                    \n",
    "\n",
    "                    # ---------------- build DataFrame row ------------\n",
    "                    row = run_params.copy()\n",
    "                    row.update(avg_results)          # every metric goes in\n",
    "                    results_list.append(row)\n",
    "                    # ---------------- save the final model ------------\n",
    "                    model_name = f\"predmodel_{fairness}_{lam}_{grad_method}_{group}_{alpha}_LR.pth\"\n",
    "                    model_path = f\"E:/myREPO/Fairness-Decision-Focused-Loss/Organized-FDFL/src/models/FDFL/{model_name}\"\n",
    "                    torch.save(final_model.state_dict(), model_path) # type: ignore[arg-type]\n",
    "\n",
    "# ---------------- DataFrame & LaTeX dump -----------------------------\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Put the hyper-parameters first; everything else follows automatically\n",
    "hp_cols = ['Group', 'Grad Method', 'Alpha', 'Lambda', 'Fairness']\n",
    "other_cols = sorted([c for c in results_df.columns if c not in hp_cols])\n",
    "results_df = results_df[hp_cols + other_cols]\n",
    "\n",
    "latex_table = results_df.to_latex(\n",
    "    index=False,\n",
    "    caption=\"Averaged Experimental Results Across Different Parameters.\",\n",
    "    label=\"tab:avg_exp_results_expanded\",\n",
    "    float_format=\"%.4f\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"                           GRID SEARCH COMPLETE\")\n",
    "print(\"=\"*90)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None,\n",
    "                       'display.width', 1200):\n",
    "    print(results_df)\n",
    "\n",
    "print(\"\\n--- LaTeX Table Output ---\")\n",
    "print(latex_table)\n",
    "results_df.to_csv(\"closed-form-res-LR.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b194e4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
