{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cvxpy as cp\n",
    "from collections import defaultdict\n",
    "\n",
    "# Add custom paths\n",
    "sys.path.insert(0, 'E:\\\\myREPO\\\\Fairness-Decision-Focused-Loss\\\\fold-opt-package\\\\fold_opt')\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from GMRES import *\n",
    "from fold_opt import *\n",
    "\n",
    "# Set device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "from src.utils.myOptimization import (\n",
    "    AlphaFairnesstorch,\n",
    "    solveIndProblem, solve_closed_form, solve_group, solve_group_grad,\n",
    "    compute_coupled_group_obj\n",
    ")\n",
    "from src.utils.myPrediction import generate_random_features, customPredictionModel\n",
    "from src.utils.plots import visLearningCurve\n",
    "from src.fairness.cal_fair_penalty import atkinson_loss, mean_abs_dev\n",
    "from src.utils.features import get_all_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coupled_group_obj_torch(d, b, group_idx, alpha, beta=None):\n",
    "    \"\"\"\n",
    "    Calculates the objective value for the new alpha=beta formulation using torch tensors.\n",
    "    \"\"\"\n",
    "    # Ensure all inputs are torch tensors\n",
    "    if not torch.is_tensor(d):\n",
    "        d = torch.tensor(d, dtype=torch.float32)\n",
    "    if not torch.is_tensor(b):\n",
    "        b = torch.tensor(b, dtype=torch.float32)\n",
    "    if not torch.is_tensor(group_idx):\n",
    "        group_idx = torch.tensor(group_idx, dtype=torch.float32)\n",
    "\n",
    "    d = d.reshape(-1)\n",
    "    b = b.reshape(-1)\n",
    "    group_idx = group_idx.reshape(-1)\n",
    "\n",
    "    epsilon = 1e-12\n",
    "    y = b * d + epsilon\n",
    "    unique_groups = torch.unique(group_idx)\n",
    "    g_k_values = torch.zeros(len(unique_groups), dtype=torch.float32, device=y.device)\n",
    "\n",
    "    for i, k in enumerate(unique_groups):\n",
    "        members_mask = (group_idx == k)\n",
    "        y_k = y[members_mask]\n",
    "        if 0 < alpha < 1:\n",
    "            g_k_values[i] = torch.sum(y_k ** (1 - alpha)) / (1 - alpha)\n",
    "        elif alpha > 1:\n",
    "            g_k_values[i] = (alpha - 1) / torch.sum(y_k ** (1 - alpha))\n",
    "        elif abs(alpha - 1.0) < epsilon:\n",
    "            g_k_values[i] = torch.sum(torch.log(y_k))\n",
    "        else:  # alpha <= 0\n",
    "            g_k_values[i] = torch.sum(y_k)\n",
    "\n",
    "    if alpha == float('inf') or str(alpha).lower() == 'inf':\n",
    "        objective_value = torch.min(g_k_values)\n",
    "    elif abs(alpha - 1.0) < epsilon:\n",
    "        objective_value = torch.sum(torch.log(g_k_values + epsilon))\n",
    "    else:\n",
    "        objective_value = torch.sum(g_k_values)\n",
    "\n",
    "    return objective_value\n",
    "\n",
    "def alpha_fair_individual(utilities, alpha):\n",
    "    \"\"\"\n",
    "    Calculate alpha-fair objective for individual optimization.\n",
    "    Works with both numpy arrays and torch tensors.\n",
    "    \"\"\"\n",
    "    if isinstance(utilities, torch.Tensor):\n",
    "        utilities = utilities.detach().cpu().numpy()\n",
    "    \n",
    "    utilities = np.maximum(utilities, 1e-8)  # Avoid log(0) or division by 0\n",
    "    \n",
    "    if alpha == 0.5:\n",
    "        return 2 * np.sqrt(np.sum(utilities))\n",
    "    elif alpha == 1.0:\n",
    "        return np.log(np.sum(utilities))\n",
    "    elif alpha == float('inf') or str(alpha).lower() == 'inf':\n",
    "        return np.min(utilities)\n",
    "    else:\n",
    "        return (np.sum(utilities) ** alpha) / alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Alpha & Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, Q = 1.5, 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy_1d(x):\n",
    "    \"\"\"Return a 1-D NumPy array; error if the length is not > 1.\"\"\"\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        x = x.detach().cpu().numpy()\n",
    "    x = np.asarray(x).reshape(-1)\n",
    "    assert x.ndim == 1, f\"expected 1-D, got shape {x.shape}\"\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/Users/dennis/Downloads/2024-fall/research/Fairness-Decision-Focused-Loss/Organized-FDFL/src/data/data.csv')\n",
    "\n",
    "df = pd.read_csv(r'E:\\myREPO\\Fairness-Decision-Focused-Loss\\Organized-FDFL\\src\\data\\data.csv')\n",
    "\n",
    "df = df.sample(n=5000, random_state=42)\n",
    "\n",
    "columns_to_keep = [\n",
    "    'risk_score_t', 'program_enrolled_t', 'cost_t', 'cost_avoidable_t', 'race', 'dem_female', 'gagne_sum_tm1', 'gagne_sum_t', \n",
    "    'risk_score_percentile', 'screening_eligible', 'avoidable_cost_mapped', 'propensity_score', 'g_binary', \n",
    "    'g_continuous', 'utility_binary', 'utility_continuous'\n",
    "]\n",
    "# for race 0 is white, 1 is black\n",
    "df_stat = df[columns_to_keep]\n",
    "df_feature = df[[col for col in df.columns if col not in columns_to_keep]]\n",
    "\n",
    "# ---------- basic 1-D helpers ----------\n",
    "def as_1d(a, dtype=np.float32):\n",
    "    a = np.asarray(a, dtype=dtype).reshape(-1)   # (N,)\n",
    "    if a.ndim != 1:\n",
    "        raise ValueError(f\"expect 1-D, got {a.shape}\")\n",
    "    return a\n",
    "\n",
    "# transform the features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# risk   = as_1d(df['risk_score_t']) * 100\n",
    "risk = np.array(df['benefit']) * 100.0  # scale to [0,100]\n",
    "risk = np.maximum(risk,1) + 1\n",
    "gainF  = np.ones_like(risk, dtype=np.float32)\n",
    "cost   = as_1d(df['cost_t_capped']) * 10.0\n",
    "cost   = np.maximum(cost, 1)              # keep strictly positive\n",
    "race   = as_1d(df['race'])  # keep as int\n",
    "\n",
    "feats  = scaler.fit_transform(df[get_all_features(df)]).astype(np.float32)   # (N,p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optDataset(Dataset):\n",
    "    def __init__(self, optmodel, feats, risk, gainF, cost, race, alpha=alpha, Q=Q):\n",
    "        # Store as numpy arrays for now\n",
    "        self.feats = feats\n",
    "        self.risk = risk\n",
    "        self.gainF = gainF\n",
    "        self.cost = cost\n",
    "        self.race = race\n",
    "        self.optmodel = optmodel\n",
    "\n",
    "        # Call optmodel (expects numpy arrays)\n",
    "        sol = self.optmodel(self.risk, self.cost, self.race, Q=Q, alpha=alpha)\n",
    "        obj = compute_coupled_group_obj_torch(sol, self.risk, self.race, alpha=alpha)\n",
    "\n",
    "        # Convert everything to torch tensors for storage\n",
    "        self.feats = torch.from_numpy(self.feats).float()\n",
    "        self.risk = torch.from_numpy(self.risk).float()\n",
    "        self.gainF = torch.from_numpy(self.gainF).float()\n",
    "        self.cost = torch.from_numpy(self.cost).float()\n",
    "        self.race = torch.from_numpy(self.race).float()\n",
    "        self.sol = torch.from_numpy(sol).float()\n",
    "        self.obj = torch.tensor(obj).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feats)\n",
    "\n",
    "    # def __getitem__(self, idx):\n",
    "    #     return self.feats, self.risk, self.gainF, self.cost, self.race, self.sol, self.obj\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return ( self.feats[idx],\n",
    "                self.risk[idx],\n",
    "                self.gainF[idx],\n",
    "                self.cost[idx],\n",
    "                self.race[idx],\n",
    "                self.sol[idx],    # or store per-item solutions; see note ▼\n",
    "                self.obj )  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairRiskPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    An improved predictor model featuring Batch Normalization for stability\n",
    "    and Kaiming (He) weight initialization for faster convergence.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, dropout_rate=0.2, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.model:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The squeeze operation is now done in the training loop for clarity\n",
    "        return self.model(x).squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2500\n",
      "Test size: 2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FairRiskPredictor(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=152, out_features=64, bias=True)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (5): Softplus(beta=1.0, threshold=20.0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup training parameters\n",
    "\n",
    "optmodel = solve_group\n",
    "\n",
    "feats_np  = np.asarray(feats)              # 2-D OK\n",
    "gainF_np  = to_numpy_1d(gainF)\n",
    "risk_np   = to_numpy_1d(risk)\n",
    "cost_np   = to_numpy_1d(cost)\n",
    "race_np   = to_numpy_1d(df['race'].values)\n",
    "\n",
    "\n",
    "# Perform train-test split\n",
    "feats_train, feats_test, gainF_train, gainF_test, risk_train, risk_test, cost_train, cost_test, race_train, race_test = train_test_split(\n",
    "    feats, gainF, risk, cost, df['race'].values, test_size=0.5, random_state=2\n",
    ")\n",
    "\n",
    "print(f\"Train size: {feats_train.shape[0]}\")\n",
    "print(f\"Test size: {feats_test.shape[0]}\")\n",
    "\n",
    "dataset_train = optDataset(optmodel, feats_train, risk_train, gainF_train, cost_train, race_train, alpha=alpha, Q=Q)\n",
    "dataset_test = optDataset(optmodel, feats_test, risk_test, gainF_test, cost_test, race_test, alpha=alpha, Q=Q)\n",
    "\n",
    "# Create dataloaders\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=len(dataset_train), shuffle=False)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=len(dataset_train), shuffle=False)\n",
    "\n",
    "predmodel = FairRiskPredictor(feats_train.shape[1])\n",
    "predmodel.to(DEVICE)\n",
    "# save the initial model\n",
    "# torch.save(predmodel.state_dict(), 'initial_model.pth')\n",
    "# load the initial model\n",
    "\n",
    "# self.sol is (N,) – __getitem__ returns a scalar component;\n",
    "# DataLoader stacks to (B,), which is exactly what the training loop expects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha Fair Obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def alpha_fair_individual(u, alpha, epsilon=1e-12):\n",
    "    \"\"\"\n",
    "    Calculates the alpha-fairness objective for individuals.\n",
    "    This function is type-aware and works with both PyTorch Tensors and NumPy arrays.\n",
    "    \"\"\"\n",
    "    # Check the input type to use the correct library\n",
    "    is_torch = isinstance(u, torch.Tensor)\n",
    "\n",
    "    # Add epsilon for numerical stability\n",
    "    u = u + epsilon\n",
    "\n",
    "    if abs(alpha - 1.0) < epsilon:\n",
    "        return torch.log(u).sum(-1) if is_torch else np.log(u).sum(-1)\n",
    "    \n",
    "    elif abs(alpha - 0.0) < epsilon:\n",
    "        return u.sum(-1)\n",
    "\n",
    "    elif alpha == float('inf'):\n",
    "        if is_torch:\n",
    "            return u.min(-1).values\n",
    "        else:\n",
    "            return u.min(-1)\n",
    "\n",
    "    # Use the appropriate power function based on the type\n",
    "    if is_torch:\n",
    "        return (torch.pow(u, 1 - alpha) / (1 - alpha)).sum(-1)\n",
    "    else:\n",
    "        return (np.power(u, 1 - alpha) / (1 - alpha)).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_optimization(gainF, risk, cost, alpha, Q):\n",
    "    gainF = gainF.detach().cpu().numpy() if isinstance(gainF, torch.Tensor) else gainF\n",
    "    risk = risk.detach().cpu().numpy() if isinstance(risk, torch.Tensor) else risk\n",
    "    cost = cost.detach().cpu().numpy() if isinstance(cost, torch.Tensor) else cost\n",
    "\n",
    "    risk = risk.clip(1)\n",
    "    gainF, risk, cost = gainF.flatten(), risk.flatten(), cost.flatten()\n",
    "    d = cp.Variable(risk.shape, nonneg=True)\n",
    "\n",
    "    if gainF.shape != risk.shape or risk.shape != cost.shape:\n",
    "        raise ValueError(\"Dimensions of gainF, risk, and cost do not match\")\n",
    "\n",
    "    utils = cp.multiply(cp.multiply(gainF, risk), d)\n",
    "    constraints = [d >= 0, cp.sum(cost * d) <= Q]\n",
    "\n",
    "    if alpha == 'inf':\n",
    "        t = cp.Variable()\n",
    "        objective = cp.Maximize(t)\n",
    "        constraints.append(utils >= t)\n",
    "    elif alpha == 1:\n",
    "        objective = cp.Maximize(cp.sum(cp.log(utils)))\n",
    "    elif alpha == 0:\n",
    "        objective = cp.Maximize(cp.sum(utils))\n",
    "    else:\n",
    "        objective = cp.Maximize(cp.sum(utils**(1-alpha)) / (1-alpha))\n",
    "\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve(solver=cp.MOSEK, verbose=False, warm_start=True, mosek_params={'MSK_IPAR_LOG': 1})\n",
    "\n",
    "    if problem.status != 'optimal':\n",
    "        print(f\"Warning: Problem status is {problem.status}\")\n",
    "\n",
    "    optimal_decision = d.value\n",
    "    optimal_value = alpha_fair_individual(optimal_decision * gainF * risk, alpha)\n",
    "\n",
    "    return optimal_decision, optimal_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_budget(x, cost, Q, max_iter=100):\n",
    "    \"\"\"\n",
    "    x : (B,n)   or (n,)   –– internally promoted to (B,n)\n",
    "    cost : (n,) positive\n",
    "    Q : scalar or length‑B tensor\n",
    "    \"\"\"\n",
    "    batched = x.dim() == 2\n",
    "    if not batched:                       # (n,)  →  (1,n)\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "    B, n = x.shape\n",
    "    cost = cost.to(x)\n",
    "    Q    = torch.as_tensor(Q, dtype=x.dtype, device=x.device).reshape(-1, 1)  # (B,1)\n",
    "\n",
    "    d    = x.clamp(min=0.)                # enforce non‑neg\n",
    "    viol = (d @ cost) > Q.squeeze(1)      # which rows violate the budget?\n",
    "\n",
    "    if viol.any():\n",
    "        dv, Qv = d[viol], Q[viol]\n",
    "        lam_lo = torch.zeros_like(Qv.squeeze(1))\n",
    "        lam_hi = (dv / cost).max(1).values   # upper bound for λ⋆\n",
    "\n",
    "        for _ in range(max_iter):\n",
    "            lam_mid = 0.5 * (lam_lo + lam_hi)\n",
    "            trial   = (dv - lam_mid[:, None] * cost).clamp(min=0.)\n",
    "            too_big = (trial @ cost) > Qv.squeeze(1)\n",
    "            lam_lo[too_big] = lam_mid[too_big]\n",
    "            lam_hi[~too_big]= lam_mid[~too_big]\n",
    "\n",
    "        d[viol] = (dv - lam_hi[:, None] * cost).clamp(min=0.)\n",
    "\n",
    "    return d if batched else d.squeeze(0)   # restore original rank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cvxpylayer Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxpylayers.torch.cvxpylayer import CvxpyLayer\n",
    "# --- 1. Define the Differentiable Projection Layer ---\n",
    "def get_differentiable_projection(n, cost_np, Q_val):\n",
    "    \"\"\"\n",
    "    Creates a differentiable projection layer using CvxpyLayer.\n",
    "    This layer solves the projection problem:\n",
    "        minimize   ||d - z||_2^2\n",
    "        subject to cost^T * d <= Q\n",
    "                   d >= 0\n",
    "    \"\"\"\n",
    "    # Define CVXPY variables and parameters\n",
    "    d_var = cp.Variable(n)\n",
    "    z_param = cp.Parameter(n)\n",
    "    objective = cp.Minimize(cp.sum_squares(d_var - z_param))\n",
    "    constraints = [cost_np @ d_var <= Q_val, d_var >= 0]\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    return CvxpyLayer(problem, parameters=[z_param], variables=[d_var])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fold-Opt Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_step_cvxpylayer(r, d, g, race, cost, Q, alpha, lr, projection_layer, group=False):\n",
    "    \"\"\"\n",
    "    Performs one PGD step using the CvxpyLayer for projection.\n",
    "    \"\"\"\n",
    "    # Temporarily enable gradients for the internal gradient calculation\n",
    "    with torch.enable_grad():\n",
    "        # The input 'd' comes from the solver and has no grad history.\n",
    "        # We clone it and require gradients to trace the PGD update.\n",
    "        d_clone = d.clone().requires_grad_(True)\n",
    "    \n",
    "        if not group:\n",
    "            obj = alpha_fair_individual(g* d_clone * r, alpha=alpha)\n",
    "        else:\n",
    "            obj = compute_coupled_group_obj_torch(d_clone, r, race, alpha=alpha)\n",
    "        \n",
    "        # Compute gradient of the objective w.r.t. the decision `d_clone`\n",
    "        # This now happens within the `enable_grad` context.\n",
    "        grad_d, = torch.autograd.grad(obj, d_clone, create_graph=True)\n",
    "\n",
    "    # Perform the gradient ascent step\n",
    "    unprojected_d = d + lr * grad_d\n",
    "    \n",
    "    # Project back to the feasible set using the differentiable layer\n",
    "    projected_d, = projection_layer(unprojected_d)\n",
    "    \n",
    "    return projected_d\n",
    "\n",
    "def make_foldopt_layer_cvxpylayer(g, cost, race, alpha, Q, group, lr=5e-3, n_fixedpt=50, backprop_rule='FPI'):\n",
    "    \"\"\"\n",
    "    Factory function to create a FoldOptLayer with a differentiable PGD update.\n",
    "    \"\"\"\n",
    "    # Detach tensors that are not parameters of the prediction model but are used in the optimization.\n",
    "    # This prevents trying to compute gradients with respect to them.\n",
    "    g_detached = g.detach()\n",
    "    cost_detached = cost.detach()\n",
    "    race_detached = race.detach()\n",
    "\n",
    "    # --- Create the differentiable projection layer once ---\n",
    "    n_vars = cost.shape[0]\n",
    "    cost_np = cost_detached.cpu().numpy()\n",
    "    Q_val = Q.item() if isinstance(Q, torch.Tensor) else Q\n",
    "    projection_layer = get_differentiable_projection(n_vars, cost_np, Q_val)\n",
    "\n",
    "    # --- Solver function (no gradients needed) ---\n",
    "    def solver_fn(r_b): # r_b is batched, expected shape (B, n)\n",
    "        # Assuming the solver can only handle one instance at a time.\n",
    "        # If your solver is batched, you can simplify this.\n",
    "        d_list = []\n",
    "        for r_single in r_b:\n",
    "            r_np = r_single.detach().cpu().numpy()\n",
    "            cost_np_local = cost_detached.cpu().numpy()\n",
    "            race_np_local = race_detached.cpu().numpy()\n",
    "            \n",
    "            if group:\n",
    "                d_np = solve_group(r_np, cost_np_local, race_np_local, Q=Q_val, alpha=alpha)\n",
    "            else:\n",
    "                # FIXED: Correct parameter order for solve_closed_form\n",
    "                # Function signature: solve_closed_form(g, r, c, alpha, Q)\n",
    "                d_np,_ = solve_closed_form(g_detached.cpu().numpy(), r_np, cost_np_local, alpha, Q_val)\n",
    "                # d_np, _ = solve_optimization(g_detached.cpu().numpy(), r_np, cost_np, alpha, Q)\n",
    "\n",
    "            \n",
    "            d_list.append(torch.from_numpy(d_np).to(r_b.device, r_b.dtype))\n",
    "        return torch.stack(d_list)\n",
    "\n",
    "\n",
    "    # --- Differentiable update function (closure) ---\n",
    "    def update_fn(r, d_star):\n",
    "        # r and d_star are batched\n",
    "        g_b = g_detached.expand_as(r)\n",
    "        \n",
    "        # Call the PGD step with the captured projection_layer and group flag\n",
    "        return pgd_step_cvxpylayer(r, d_star, g_b, race_detached, cost_detached, Q, alpha, lr, projection_layer, group)\n",
    "\n",
    "    return FoldOptLayer(solver_fn, update_fn, n_iter=n_fixedpt, backprop_rule=backprop_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_differentiable_dfl(\n",
    "    predmodel,\n",
    "    feats_train, risk_train, gainF_train, cost_train, race_train,\n",
    "    alpha, Q,\n",
    "    group=True,\n",
    "    num_epochs=50,\n",
    "    lr_pred=1e-3,\n",
    "    pgd_lr=5e-3,\n",
    "    n_fixedpt=50,\n",
    "    lambda_fairness=0.0,\n",
    "    fairness_type='atkinson'\n",
    "):\n",
    "    device = next(predmodel.parameters()).device\n",
    "    optimizer = torch.optim.Adam(predmodel.parameters(), lr=lr_pred)\n",
    "    \n",
    "    feats = torch.from_numpy(feats_train).to(device)\n",
    "    risk = torch.from_numpy(risk_train).to(device)\n",
    "    gainF = torch.from_numpy(gainF_train).to(device)\n",
    "    cost = torch.from_numpy(cost_train).to(device)\n",
    "    race = torch.from_numpy(race_train).to(device)\n",
    "\n",
    "    # --- Pre-calculate optimal solution (ground truth) ---\n",
    "    if group:\n",
    "        opt_d_np = solve_group(risk.cpu().numpy(), cost.cpu().numpy(), race.cpu().numpy(), Q=Q, alpha=alpha)\n",
    "    else:\n",
    "        opt_d_np, _ = solve_closed_form(gainF.cpu().numpy(), risk.cpu().numpy(), cost.cpu().numpy(), alpha=alpha, Q=Q)\n",
    "        # NOTE: solve_closed_form sometimes returns incorrect objective values\n",
    "        # We'll recalculate the objective manually for safety\n",
    "    opt_d = torch.from_numpy(opt_d_np).to(device)\n",
    "    \n",
    "    # --- CORRECTED: Calculate optimal objective ---\n",
    "    # ALWAYS recalculate objective manually to avoid numerical errors from solvers\n",
    "    if group:\n",
    "        opt_obj = compute_coupled_group_obj_torch(opt_d, risk, race, alpha)\n",
    "    else:\n",
    "        # For individual optimization, manually calculate objective using our consistent function\n",
    "        opt_obj = alpha_fair_individual(opt_d * risk * gainF, alpha)\n",
    "\n",
    "\n",
    "    # --- Build the FoldOpt layer with the 'group' flag ---\n",
    "    differentiable_opt_layer = make_foldopt_layer_cvxpylayer(\n",
    "        gainF, cost, race, alpha, Q, group, lr=pgd_lr, n_fixedpt=n_fixedpt\n",
    "    )\n",
    "\n",
    "    logs = {\"loss\": [], \"regret\": [], \"fairness\": []}\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        predmodel.train()\n",
    "        \n",
    "        pred_risk = predmodel(feats).clamp(min=1)\n",
    "        d_pred = differentiable_opt_layer(pred_risk.unsqueeze(0)).squeeze(0)\n",
    "        \n",
    "        # --- Loss Calculation ---\n",
    "        if group:\n",
    "            # Use d_pred here to keep the computation graph intact\n",
    "            pred_obj = compute_coupled_group_obj_torch(d_pred, risk, race, alpha)\n",
    "        else:\n",
    "            # For individual optimization, ensure consistent calculation\n",
    "            # IMPORTANT: Use TRUE risk values for objective evaluation, not predicted risk\n",
    "            pred_obj = alpha_fair_individual(d_pred * risk * gainF, alpha)\n",
    "\n",
    "        # Calculate normalized regret for logging\n",
    "        normalized_regret = (opt_obj - pred_obj) / (torch.abs(opt_obj) + 1e-8)\n",
    "        \n",
    "        # Use raw regret (not normalized) for loss calculation\n",
    "        raw_regret = opt_obj - pred_obj\n",
    "        \n",
    "        # --- Fairness Penalty ---\n",
    "        fairness_penalty = torch.tensor(0.0, device=device)\n",
    "        if lambda_fairness > 0:\n",
    "            mode = 'between' if group else 'individual'\n",
    "            if fairness_type == 'atkinson':\n",
    "                fairness_penalty = atkinson_loss(pred_risk, risk, race, beta=0.5, mode=mode)\n",
    "            elif fairness_type == 'mad':\n",
    "                fairness_penalty = mean_abs_dev(pred_risk, risk, race, mode=mode)\n",
    "\n",
    "        # Use raw regret for loss, but log normalized regret\n",
    "        loss = raw_regret + lambda_fairness * fairness_penalty\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        logs[\"loss\"].append(loss.item())\n",
    "        logs[\"regret\"].append(normalized_regret.item())  # Log normalized regret\n",
    "        logs[\"fairness\"].append(fairness_penalty.item())\n",
    "            \n",
    "    # --- Final Evaluation for Detailed Logging ---\n",
    "    predmodel.eval()\n",
    "    with torch.no_grad():\n",
    "        final_pred_risk = predmodel(feats).clamp(min=1)\n",
    "        final_d_pred = differentiable_opt_layer(final_pred_risk.unsqueeze(0)).squeeze(0)\n",
    "        \n",
    "        eval_logs = {}\n",
    "        unique_groups = torch.unique(race).cpu().numpy()\n",
    "        for g in unique_groups:\n",
    "            mask = (race == g)\n",
    "            if mask.sum() == 0: continue\n",
    "            eval_logs[f'G{int(g)}_mse'] = (final_pred_risk[mask] - risk[mask]).pow(2).mean().item()\n",
    "            group_utility = (final_d_pred[mask] * risk[mask] * gainF[mask])\n",
    "            eval_logs[f'G{int(g)}_decision_obj'] = alpha_fair_individual(group_utility, alpha).item()\n",
    "            eval_logs[f'G{int(g)}_true_benefit'] = risk[mask].mean().item()\n",
    "\n",
    "    return predmodel, logs, eval_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_many_trials_foldopt(n_trials: int, base_seed: int, **train_args):\n",
    "    \"\"\"\n",
    "    Runs `train_model_differentiable_dfl` for `n_trials` and aggregates the results.\n",
    "    \"\"\"\n",
    "    per_trial_metrics = defaultdict(list)\n",
    "    final_model = None\n",
    "    \n",
    "    # Extract data for splitting - these are passed in train_args\n",
    "    feats = train_args.pop('feats')\n",
    "    risk = train_args.pop('risk')\n",
    "    gainF = train_args.pop('gainF')\n",
    "    cost = train_args.pop('cost')\n",
    "    race = train_args.pop('race')\n",
    "\n",
    "    for t in range(n_trials):\n",
    "        seed = base_seed + t\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        print(f\"--- Running Trial {t+1}/{n_trials} (Seed: {seed}) ---\")\n",
    "\n",
    "        # Create a new train/test split for each trial\n",
    "        (feats_tr, _, risk_tr, _, gainF_tr, _, cost_tr, _, race_tr, _) = train_test_split(\n",
    "            feats, risk, gainF, cost, race, test_size=0.5, random_state=seed\n",
    "        )\n",
    "        \n",
    "        # Instantiate a new model for each trial to ensure fresh weights\n",
    "        input_dim = feats_tr.shape[1]\n",
    "        predictor = FairRiskPredictor(input_dim=input_dim).to(DEVICE)\n",
    "        \n",
    "        # Run the training\n",
    "        _, logs, eval_logs = train_model_differentiable_dfl(\n",
    "            predmodel=predictor,\n",
    "            feats_train=feats_tr, risk_train=risk_tr, gainF_train=gainF_tr, \n",
    "            cost_train=cost_tr, race_train=race_tr,\n",
    "            **train_args\n",
    "        )\n",
    "\n",
    "        # Log metrics from the final state of the trial\n",
    "        if logs and 'regret' in logs:\n",
    "            per_trial_metrics['regret'].append(logs['regret'][-1])\n",
    "            per_trial_metrics['loss'].append(logs['loss'][-1])\n",
    "            per_trial_metrics['fairness_penalty'].append(logs['fairness'][-1])\n",
    "        \n",
    "        if eval_logs:\n",
    "            for key, value in eval_logs.items():\n",
    "                per_trial_metrics[key].append(value)\n",
    "        else:\n",
    "            print(f\"Warning: Trial {t+1} did not produce evaluation logs.\")\n",
    "\n",
    "    # Aggregate results across all trials\n",
    "    avg_results = {}\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"        AVERAGED METRICS ACROSS ALL TRIALS\")\n",
    "    print(\"=\"*60)\n",
    "    for key, values in per_trial_metrics.items():\n",
    "        if values:\n",
    "            mu, sigma = np.mean(values), np.std(values)\n",
    "            avg_results[key] = mu\n",
    "            avg_results[f'{key}_std'] = sigma\n",
    "            print(f\"[{key.upper():>25s}]   μ = {mu:.4f} | σ = {sigma:.4f}\")\n",
    "        else:\n",
    "            avg_results[key] = np.nan\n",
    "            avg_results[f'{key}_std'] = np.nan\n",
    "            \n",
    "    return avg_results, final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                    RUNNING NEURAL NETWORK EXPERIMENTS\n",
      "================================================================================\n",
      "Started at: 2025-07-21 06:03:52.215576\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Alpha': 0.5, 'Lambda': 0, 'FairnessType': 'atkinson'}\n",
      "--------------------------------------------------------------------------------\n",
      "--- Running Trial 1/5 (Seed: 2025) ---\n",
      "--- Running Trial 2/5 (Seed: 2026) ---\n",
      "--- Running Trial 3/5 (Seed: 2027) ---\n",
      "--- Running Trial 4/5 (Seed: 2028) ---\n",
      "--- Running Trial 5/5 (Seed: 2029) ---\n",
      "\n",
      "============================================================\n",
      "        AVERAGED METRICS ACROSS ALL TRIALS\n",
      "============================================================\n",
      "[                   REGRET]   μ = 0.1244 | σ = 0.0040\n",
      "[                     LOSS]   μ = 1885.0956 | σ = 75.3782\n",
      "[         FAIRNESS_PENALTY]   μ = 0.0000 | σ = 0.0000\n",
      "[                   G0_MSE]   μ = 322.4952 | σ = 13.6493\n",
      "[          G0_DECISION_OBJ]   μ = 11340.3900 | σ = 92.9200\n",
      "[          G0_TRUE_BENEFIT]   μ = 12.2387 | σ = 0.2786\n",
      "[                   G1_MSE]   μ = 477.3596 | σ = 21.5101\n",
      "[          G1_DECISION_OBJ]   μ = 1950.5934 | σ = 129.3913\n",
      "[          G1_TRUE_BENEFIT]   μ = 16.3643 | σ = 0.5954\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RUNNING EXPERIMENT: {'Group': False, 'Alpha': 0.5, 'Lambda': 1, 'FairnessType': 'atkinson'}\n",
      "--------------------------------------------------------------------------------\n",
      "--- Running Trial 1/5 (Seed: 2025) ---\n",
      "--- Running Trial 2/5 (Seed: 2026) ---\n",
      "--- Running Trial 3/5 (Seed: 2027) ---\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfigFoldOpt:\n",
    "    \"\"\"A dataclass to hold all experiment settings for Fold-Opt.\"\"\"\n",
    "    # Parameters to iterate over\n",
    "    alphas = [0.5, 2.0]\n",
    "    group_settings = [False, True]\n",
    "    fairness_types = ['atkinson', 'mad']\n",
    "\n",
    "    # Static problem parameters\n",
    "    Q = 2500\n",
    "    num_epochs = 50\n",
    "    n_trials = 2\n",
    "    base_seed = 2025\n",
    "\n",
    "    # Fold-Opt specific hyperparameters\n",
    "    foldopt_hparams = {\n",
    "        'pgd_lr': 5e-3,\n",
    "        'n_fixedpt': 50,\n",
    "        'lr_pred': 1e-3,\n",
    "    }\n",
    "\n",
    "    def get_fairness_lambdas(self, fairness_type):\n",
    "        \"\"\"Returns the lambdas for a given fairness type.\"\"\"\n",
    "        if fairness_type == 'atkinson':\n",
    "            return [0, 1, 5]\n",
    "        if fairness_type == 'mad':\n",
    "            return [0, 0.05, 0.5]\n",
    "        return [0]\n",
    "\n",
    "# ===================================================================\n",
    "# 3. RESULTS PROCESSING: Renames and displays the final DataFrame\n",
    "# ===================================================================\n",
    "\n",
    "def process_and_display_results(results_df: pd.DataFrame):\n",
    "    \"\"\"Renames, reorders, and prints the final results DataFrame.\"\"\"\n",
    "    if results_df.empty:\n",
    "        print(\"No results to display.\")\n",
    "        return\n",
    "        \n",
    "    rename_map = {\n",
    "        'regret': 'Decision Regret',\n",
    "        'fairness_penalty': 'Fairness Penalty',\n",
    "        'G0_mse': 'G0 MSE', 'G1_mse': 'G1 MSE',\n",
    "        'G0_decision_obj': 'G0 Decision Obj', 'G1_decision_obj': 'G1 Decision Obj',\n",
    "        'G0_true_benefit': 'G0 True Benefit', 'G1_true_benefit': 'G1 True Benefit'\n",
    "    }\n",
    "    # Create mean and std versions of renames\n",
    "    full_rename_map = {}\n",
    "    for key, val in rename_map.items():\n",
    "        full_rename_map[key] = f'{val} mean'\n",
    "        full_rename_map[f'{key}_std'] = f'{val} std'\n",
    "    \n",
    "    results_df.rename(columns=full_rename_map, inplace=True)\n",
    "\n",
    "    primary_cols = [\n",
    "        'Group', 'Alpha', 'Lambda', 'FairnessType',\n",
    "        'Decision Regret mean', 'G0 MSE mean', 'G1 MSE mean'\n",
    "    ]\n",
    "    existing_primary_cols = [col for col in primary_cols if col in results_df.columns]\n",
    "    other_cols = sorted([c for c in results_df.columns if c not in existing_primary_cols])\n",
    "    \n",
    "    results_df = results_df[existing_primary_cols + other_cols]\n",
    "\n",
    "    print(\"\\n\" + \"=\"*120)\n",
    "    print(\" \" * 50 + \"EXPERIMENTS COMPLETE\")\n",
    "    print(\"=\"*120)\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', 1200):\n",
    "        print(results_df)\n",
    "\n",
    "# ===================================================================\n",
    "# 4. MAIN EXECUTION HARNESS: Manages the experiment lifecycle\n",
    "# ===================================================================\n",
    "\n",
    "def run_experiments_foldopt(config: ExperimentConfigFoldOpt):\n",
    "    \"\"\"Executes the main experiment loop based on the provided configuration.\"\"\"\n",
    "    results_list = []\n",
    "\n",
    "    experiment_params = list(itertools.product(\n",
    "        config.group_settings, config.fairness_types, config.alphas\n",
    "    ))\n",
    "\n",
    "    for group, fairness, alpha in experiment_params:\n",
    "        fairness_lambdas = config.get_fairness_lambdas(fairness)\n",
    "        for lam in fairness_lambdas:\n",
    "            # Skip redundant runs where lambda is 0\n",
    "                \n",
    "            run_params = {\n",
    "                'Group': group, 'Alpha': alpha, 'Lambda': lam, 'FairnessType': fairness\n",
    "            }\n",
    "            print(\"\\n\" + \"-\"*80)\n",
    "            print(f\"RUNNING EXPERIMENT: {run_params}\")\n",
    "            print(\"-\"*80)\n",
    "\n",
    "            # Assemble all arguments for the training function\n",
    "            train_args = dict(\n",
    "                # Data (will be split inside the trial runner)\n",
    "                feats=feats_np, risk=risk_np, gainF=gainF_np, cost=cost_np, race=race_np,\n",
    "                # Problem parameters\n",
    "                alpha=alpha, Q=config.Q, group=group,\n",
    "                # DFL/Fairness params\n",
    "                lambda_fairness=lam, fairness_type=fairness,\n",
    "                # Training loop params\n",
    "                num_epochs=config.num_epochs,\n",
    "                # Fold-Opt specific hparams\n",
    "                **config.foldopt_hparams\n",
    "            )\n",
    "            \n",
    "            # Run multiple trials and get aggregated results\n",
    "            avg_results, _ = train_many_trials_foldopt(\n",
    "                n_trials=config.n_trials, \n",
    "                base_seed=config.base_seed, \n",
    "                **train_args\n",
    "            )\n",
    "            \n",
    "            row = {**run_params, **avg_results}\n",
    "            results_list.append(row)\n",
    "\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    process_and_display_results(results_df)\n",
    "    return results_df\n",
    "\n",
    "# ===================================================================\n",
    "# 5. NEURAL NETWORK EXPERIMENTS\n",
    "# ===================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" \" * 20 + \"RUNNING NEURAL NETWORK EXPERIMENTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create a configuration object\n",
    "exp_config = ExperimentConfigFoldOpt()\n",
    "\n",
    "# Set trials to reasonable number for full experiments\n",
    "exp_config.n_trials = 5\n",
    "\n",
    "# Track start time\n",
    "start_time = datetime.datetime.now()\n",
    "print(f\"Started at: {start_time}\")\n",
    "\n",
    "# Run the Neural Network experiments\n",
    "nn_results = run_experiments_foldopt(exp_config)\n",
    "\n",
    "# Save Neural Network results\n",
    "nn_results.to_csv('res-foldopt-nn.csv', index=False)\n",
    "print(f\"\\n✅ Neural Network results saved to 'res-foldopt-nn.csv'\")\n",
    "print(f\"NN Experiments completed at: {datetime.datetime.now()}\")\n",
    "print(f\"NN Duration: {datetime.datetime.now() - start_time}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NEURAL NETWORK EXPERIMENTS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise SystemExit(\"Exiting after Neural Network experiments. Remove this line to continue with other experiments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m final_results_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlpha\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGroup\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLambda\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFairnessType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_regret_mean\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_results_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. SCRIPT ENTRY POINT & DATA LOADING\n",
    "# ===================================================================\n",
    "\n",
    "# --- Run Experiments ---\n",
    "\n",
    "# 1. Create a configuration object\n",
    "exp_config = ExperimentConfigFoldOpt()\n",
    "\n",
    "# 2. You can easily modify the config for a specific run, for example:\n",
    "# To run only the group-based model with a single alpha\n",
    "# exp_config.group_settings = [True]\n",
    "# exp_config.alphas = [1.5]\n",
    "exp_config.n_trials = 5 # For a quick test run\n",
    "\n",
    "# 3. Run the experiments\n",
    "final_results = run_experiments_foldopt(exp_config)\n",
    "\n",
    "final_results.head()\n",
    "\n",
    "final_results_df[['Alpha', 'Group', 'Lambda', 'FairnessType', 'final_regret_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final results to a CSV file\n",
    "final_results.to_csv('foldopt-NN-0719.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
