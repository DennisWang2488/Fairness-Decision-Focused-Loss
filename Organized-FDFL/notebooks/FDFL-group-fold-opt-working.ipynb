{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Function\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cvxpy as cp\n",
    "\n",
    "# Add custom paths\n",
    "sys.path.insert(0, 'E:\\\\User\\\\Stevens\\\\MyRepo\\\\FDFL\\\\helper')\n",
    "sys.path.insert(0, 'E:\\\\User\\\\Stevens\\\\MyRepo\\\\fold-opt-package\\\\fold_opt')\n",
    "\n",
    "from myutil import *\n",
    "from features import get_all_features\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from GMRES import *\n",
    "from fold_opt import *\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "from src.utils.myOptimization import (\n",
    "    solveGroupProblem, closed_form_group_alpha, AlphaFairnesstorch,\n",
    "    solveIndProblem, solve_closed_form, solve_coupled_group_alpha, solve_coupled_group_grad,\n",
    "    compute_coupled_group_obj\n",
    ")\n",
    "from src.utils.myPrediction import generate_random_features, customPredictionModel\n",
    "from src.utils.plots import visLearningCurve\n",
    "from src.fairness.cal_fair_penalty import atkinson_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Alpha & Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, Q = 0.5, 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('E:\\\\User\\\\Stevens\\\\MyRepo\\\\Organized-FDFL\\\\src\\\\data\\\\data.csv')\n",
    "\n",
    "df = df.sample(n=500, random_state=42)\n",
    "\n",
    "columns_to_keep = [\n",
    "    'risk_score_t', 'program_enrolled_t', 'cost_t', 'cost_avoidable_t', 'race', 'dem_female', 'gagne_sum_tm1', 'gagne_sum_t', \n",
    "    'risk_score_percentile', 'screening_eligible', 'avoidable_cost_mapped', 'propensity_score', 'g_binary', \n",
    "    'g_continuous', 'utility_binary', 'utility_continuous'\n",
    "]\n",
    "# for race 0 is white, 1 is black\n",
    "df_stat = df[columns_to_keep]\n",
    "df_feature = df[[col for col in df.columns if col not in columns_to_keep]]\n",
    "\n",
    "\n",
    "risk = np.array(df['benefit'].values) * 100 \n",
    "risk = np.maximum(risk, 0.1) \n",
    "\n",
    "\n",
    "feats = df[get_all_features(df)].values\n",
    "gainF = np.ones_like(risk)\n",
    "decision = df['propensity_score'].values\n",
    "cost = np.array(df['cost_t_capped'].values) * 10\n",
    "cost = np.maximum(cost, 0.1)\n",
    "race = np.array(df['race'].values)\n",
    "\n",
    "# transform the features\n",
    "scaler = StandardScaler()\n",
    "feats = scaler.fit_transform(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optDataset(Dataset):\n",
    "    def __init__(self, optmodel, feats, risk, gainF, cost, race, alpha=alpha, Q=Q):\n",
    "        # Store as numpy arrays for now\n",
    "        self.feats = feats\n",
    "        self.risk = risk\n",
    "        self.gainF = gainF\n",
    "        self.cost = cost\n",
    "        self.race = race\n",
    "        self.optmodel = optmodel\n",
    "\n",
    "        # Call optmodel (expects numpy arrays)\n",
    "        sol = self.optmodel(self.risk, self.cost, self.race, Q=Q, alpha=alpha, beta=alpha)\n",
    "        obj = compute_coupled_group_obj(sol, self.risk, self.race, alpha=alpha, beta=alpha)\n",
    "\n",
    "        # Convert everything to torch tensors for storage\n",
    "        self.feats = torch.from_numpy(self.feats).float()\n",
    "        self.risk = torch.from_numpy(self.risk).float()\n",
    "        self.gainF = torch.from_numpy(self.gainF).float()\n",
    "        self.cost = torch.from_numpy(self.cost).float()\n",
    "        self.race = torch.from_numpy(self.race).float()\n",
    "        self.sol = torch.from_numpy(sol).float()\n",
    "        self.obj = torch.tensor(obj).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feats)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.feats, self.risk, self.gainF, self.cost, self.race, self.sol, self.obj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairRiskPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # First layer with batch normalization\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            # Output layer\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Setup training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 250\n",
      "Test size: 250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FairRiskPredictor(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=152, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (4): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup training parameters\n",
    "\n",
    "optmodel = solve_coupled_group_alpha\n",
    "\n",
    "# Perform train-test split\n",
    "feats_train, feats_test, gainF_train, gainF_test, risk_train, risk_test, cost_train, cost_test, race_train, race_test = train_test_split(\n",
    "    feats, gainF, risk, cost, df['race'].values, test_size=0.5, random_state=2\n",
    ")\n",
    "\n",
    "print(f\"Train size: {feats_train.shape[0]}\")\n",
    "print(f\"Test size: {feats_test.shape[0]}\")\n",
    "\n",
    "dataset_train = optDataset(optmodel, feats_train, risk_train, gainF_train, cost_train, race_train, alpha=alpha, Q=Q)\n",
    "dataset_test = optDataset(optmodel, feats_test, risk_test, gainF_test, cost_test, race_test, alpha=alpha, Q=Q)\n",
    "\n",
    "# Create dataloaders\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=1, shuffle=False)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=1, shuffle=False)\n",
    "\n",
    "predmodel = FairRiskPredictor(feats_train.shape[1])\n",
    "predmodel.to(device)\n",
    "# save the initial model\n",
    "# torch.save(predmodel.state_dict(), 'initial_model.pth')\n",
    "# load the initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.32756579, -0.19324699, -0.38313051, ..., -0.0776931 ,\n",
       "        -0.07543471, -0.07474351],\n",
       "       [ 0.75325833, -0.19324699, -0.38313051, ..., -0.0776931 ,\n",
       "        -0.07543471, -0.07474351],\n",
       "       [ 0.75325833,  5.1747249 , -0.38313051, ..., -0.0776931 ,\n",
       "        -0.07543471, -0.07474351],\n",
       "       ...,\n",
       "       [-1.32756579, -0.19324699, -0.38313051, ..., -0.0776931 ,\n",
       "        -0.07543471, -0.07474351],\n",
       "       [ 0.75325833, -0.19324699, -0.38313051, ..., -0.0776931 ,\n",
       "        -0.07543471, -0.07474351],\n",
       "       [ 0.75325833, -0.19324699, -0.38313051, ..., -0.0776931 ,\n",
       "        -0.07543471, -0.07474351]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
