{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.autograd import Function\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cvxpy as cp\n",
    "#from pyepo.model.opt import optModel\n",
    "\n",
    "\n",
    "sys.path.insert(0, 'E:\\\\User\\\\Stevens\\\\Code\\\\The Paper\\\\algorithm')\n",
    "from myutil import *\n",
    "from features import get_all_features\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "alpha, Q = 2, 20\n",
    "df = pd.read_csv('data/data.csv')\n",
    "# fix random seed for reproducibility\n",
    "\n",
    "# report statistics on this dataset\n",
    "df = df.sample(n=200, random_state=1)\n",
    "\n",
    "columns_to_keep = [\n",
    "    'risk_score_t', 'program_enrolled_t', 'cost_t', 'cost_avoidable_t', 'race', 'dem_female', 'gagne_sum_tm1', 'gagne_sum_t', \n",
    "    'risk_score_percentile', 'screening_eligible', 'avoidable_cost_mapped', 'propensity_score', 'g_binary', \n",
    "    'g_continuous', 'utility_binary', 'utility_continuous'\n",
    "]\n",
    "# for race 0 is white, 1 is black\n",
    "df_stat = df[columns_to_keep]\n",
    "df_feature = df[[col for col in df.columns if col not in columns_to_keep]]\n",
    "\n",
    "# Replace all values less than 0.1 with 0.1\n",
    "#df['risk_score_t'] = df['risk_score_t'].apply(lambda x: 0.1 if x < 0.1 else x)\n",
    "df['g_continuous'] = df['g_continuous'].apply(lambda x: 0.1 if x < 0.1 else x)\n",
    "\n",
    "\n",
    "risk = df['risk_score_t'].values\n",
    "risk = risk + 0.001 if 0 in risk else risk\n",
    "\n",
    "\n",
    "feats = df[get_all_features(df)].values\n",
    "gainF = df['g_continuous'].values\n",
    "decision = df['propensity_score'].values\n",
    "cost = np.random.normal(1, 0.5, len(risk)).clip(0.1, 2)\n",
    "race = df['race'].values\n",
    "\n",
    "# transform the features\n",
    "scaler = StandardScaler()\n",
    "feats = scaler.fit_transform(feats)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "def AlphaFairness(util, alpha):\n",
    "    if alpha == 1:\n",
    "        return np.sum(np.log(util))\n",
    "    elif alpha == 0:\n",
    "        return np.sum(util)\n",
    "    elif alpha == 'inf':\n",
    "        return np.min(util)\n",
    "    else:\n",
    "        return np.sum(util**(1-alpha) / (1-alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_closed_form(g, r, c, alpha=alpha, Q=Q):\n",
    "\n",
    "    g = g.detach().cpu().numpy() if isinstance(g, torch.Tensor) else g\n",
    "    r = r.detach().cpu().numpy() if isinstance(r, torch.Tensor) else r\n",
    "    c = c.detach().cpu().numpy() if isinstance(c, torch.Tensor) else c\n",
    "    if c.shape != r.shape or c.shape != g.shape:\n",
    "        raise ValueError(\"c, r, and g must have the same shape.\")\n",
    "    if np.any(c <= 0):\n",
    "        raise ValueError(\"All cost values must be positive.\")\n",
    "    if np.any(r <= 0):\n",
    "        raise ValueError(\"All risk values must be positive.\")\n",
    "    if np.any(g <= 0):\n",
    "        raise ValueError(\"All gain factors must be positive.\")\n",
    "    \n",
    "    n = len(c)\n",
    "    utility = r * g\n",
    "    \n",
    "    if alpha == 0:\n",
    "        ratios = utility / c\n",
    "        sorted_indices = np.argsort(-ratios)  # Descending order\n",
    "        d_star_closed = np.zeros(n)\n",
    "        d_star_closed[sorted_indices[0]] = Q / c[sorted_indices[0]]\n",
    "        \n",
    "    elif alpha == 1:\n",
    "        d_star_closed = Q / (n * c)\n",
    "    \n",
    "    elif alpha == 'inf':\n",
    "        d_star_closed = (Q * c) / (utility * np.sum(c * c / utility))\n",
    "        \n",
    "    else:\n",
    "        if alpha <= 0:\n",
    "            raise ValueError(\"Alpha must be positive for general case.\")\n",
    "\n",
    "      #  numerator = np.power(c, -1/alpha) * np.power(utility, 1/alpha - 1)\n",
    "      #  denominator = np.sum(numerator)\n",
    "        \n",
    "        numerator = np.power(c, -1/alpha) * np.power(utility, 1/alpha - 1)\n",
    "        denominator = np.sum(np.power(c, 1-1/alpha) * np.power(utility, 1/alpha - 1))\n",
    "        \n",
    "        if denominator == 0:\n",
    "            raise ValueError(\"Denominator is zero in closed-form solution.\")\n",
    "            \n",
    "        d_star_closed = (numerator / denominator) * Q\n",
    "    obj = AlphaFairness(d_star_closed * utility, alpha)\n",
    "    return d_star_closed, obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "import numpy as np\n",
    "\n",
    "class RiskPredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc_out = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softplus(self.fc_out(x)) + 0.001  # Ensure risk values remain positive\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem parameters\n",
    "n = len(gainF)\n",
    "x = cp.Variable(n)\n",
    "p = cp.Parameter(n, nonneg=True)  # Fixed shape issue\n",
    "Q = 100 # Budget constraint\n",
    "\n",
    "# Define the CVXPY optimization problem\n",
    "obj = cp.Maximize((1 / (1 - alpha)) * cp.sum(cp.power(cp.multiply(p, x), 1 - alpha)))\n",
    "constr = [cp.sum(cp.multiply(cost, x)) <= Q, x >= 0]\n",
    "problem = cp.Problem(obj, constr)\n",
    "\n",
    "# Create CVXPY layer\n",
    "cvxpylayer = CvxpyLayer(problem, parameters=[p], variables=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_risk = risk  # Your provided true risk from data\n",
    "opt_sol, _ = solve_closed_form(gainF, risk, cost, alpha=alpha, Q=Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features and solutions into PyTorch tensors\n",
    "tensor_feats = torch.tensor(feats, dtype=torch.float32)\n",
    "tensor_true_sol = torch.tensor(opt_sol, dtype=torch.float32)\n",
    "tensor_risk = torch.tensor(risk, dtype=torch.float32)  # True risk for regret calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regret(pred_model, opt_model, feats, true_risk, gainF, cost, alpha=alpha, Q=Q):\n",
    "    pred_model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_risk = pred_model(feats).squeeze().cpu().numpy()\n",
    "\n",
    "    pred_risk = np.clip(pred_risk, 0.001, None)  # Ensure positivity\n",
    "    gainF_np = gainF.flatten()\n",
    "    cost_np = cost.flatten()\n",
    "    true_risk_np = true_risk.cpu().numpy()\n",
    "\n",
    "    # Compute optimal and predicted solutions\n",
    "    opt_sol, opt_val = opt_model(gainF_np, true_risk_np, cost_np, alpha, Q)\n",
    "    pred_sol, _ = opt_model(gainF_np, pred_risk, cost_np, alpha, Q)\n",
    "    \n",
    "    pred_obj = AlphaFairness(gainF_np * true_risk_np * pred_sol, alpha)\n",
    "\n",
    "    # Compute regret\n",
    "    normalized_regret = (opt_val - pred_obj) / (abs(opt_val) + 1e-7)\n",
    "\n",
    "    pred_model.train()\n",
    "    \n",
    "    print (\"In regret calculation: \", opt_val, pred_obj)\n",
    "    return normalized_regret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_fairness = 0\n",
    "\n",
    "\n",
    "def AlphaFairnessTorch(util, alpha):\n",
    "    # convert to torch tensor if not already\n",
    "    if not isinstance(util, torch.Tensor):\n",
    "        util = torch.tensor(util, dtype=torch.float32)\n",
    "    if alpha == 1:\n",
    "        return torch.sum(torch.log(util))\n",
    "    elif alpha == 0:\n",
    "        return torch.sum(util)\n",
    "    elif alpha == 'inf':\n",
    "        return torch.min(util)\n",
    "    else:\n",
    "        return torch.sum(util**(1-alpha) / (1-alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In regret calculation:  -246.87805537674768 -4187.582068880728\n",
      "Initial Regret: 15.9621\n",
      "From loss calculation:  tensor(-246.8781, dtype=torch.float64) tensor(-3742.1571, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Epoch 10/50, Loss: 14.1579\n",
      "In regret calculation:  -246.87805537674768 -3713.5770027433814\n",
      "Regret: 14.0422\n",
      "From loss calculation:  tensor(-246.8781, dtype=torch.float64) tensor(-3468.8391, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Epoch 20/50, Loss: 13.0508\n",
      "In regret calculation:  -246.87805537674768 -3450.570752511814\n",
      "Regret: 12.9768\n",
      "From loss calculation:  tensor(-246.8781, dtype=torch.float64) tensor(-3306.9461, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Epoch 30/50, Loss: 12.3951\n",
      "In regret calculation:  -246.87805537674768 -3292.159351899061\n",
      "Regret: 12.3352\n",
      "From loss calculation:  tensor(-246.8781, dtype=torch.float64) tensor(-3179.6928, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Epoch 40/50, Loss: 11.8796\n",
      "In regret calculation:  -246.87805537674768 -3168.4252763860727\n",
      "Regret: 11.8340\n",
      "From loss calculation:  tensor(-246.8781, dtype=torch.float64) tensor(-3069.3865, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Epoch 50/50, Loss: 11.4328\n",
      "In regret calculation:  -246.87805537674768 -3057.950031428101\n",
      "Regret: 11.3865\n",
      "In regret calculation:  -246.87805537674768 -3057.950031428101\n",
      "Final Regret: 11.3865\n"
     ]
    }
   ],
   "source": [
    "gainT = torch.from_numpy(gainF)\n",
    "# Fairness regularization parameter\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = RiskPredictor(input_dim=feats.shape[1])\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 50\n",
    "\n",
    "true_util = gainT * tensor_risk * tensor_true_sol\n",
    "opt_val = 1/(1-alpha) * (torch.sum(true_util ** (1-alpha)))\n",
    "\n",
    "# Compute initial regret before training\n",
    "initial_regret = regret(model, solve_closed_form, tensor_feats, tensor_risk, gainF, cost, alpha, Q)\n",
    "print(f\"Initial Regret: {initial_regret:.4f}\")\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Predict risk using the neural network\n",
    "    pred_risk = model(tensor_feats).squeeze()  # Ensure correct shape\n",
    "    pred_risk = torch.clamp(pred_risk, min=0.001)  # Ensure risk is positive\n",
    "\n",
    "    # Solve CVXPY optimization problem\n",
    "    pred_sol, = cvxpylayer((gainT * pred_risk).unsqueeze(0))  # Add batch dimension fix\n",
    "    \n",
    "    # Compute MSE loss between predicted and true solutions\n",
    "  #  loss = F.mse_loss(pred_sol, tensor_true_sol)\n",
    "    \n",
    "    # Compute normalized regret loss\n",
    "    pred_util = gainT * true_risk * pred_sol\n",
    "    pred_val = 1/(1-alpha) * (torch.sum(pred_util ** (1-alpha)))                       \n",
    "    loss = (opt_val - pred_val) / (abs(opt_val) + 1e-7) \n",
    "\n",
    "    group0_mask = (race == 0)\n",
    "    group1_mask = (race == 1)\n",
    "    mse0 = torch.mean((pred_risk[group0_mask] - tensor_risk[group0_mask]) ** 2)\n",
    "    mse1 = torch.mean((pred_risk[group1_mask] - tensor_risk[group1_mask]) ** 2)\n",
    "    fairness_reg = torch.abs(mse0 - mse1)\n",
    "    loss += lambda_fairness * fairness_reg\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        # Verified that loss and regret are consistent with small numerical differences\n",
    "        print (\"From loss calculation: \", opt_val, pred_val)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        regret_val = regret(model, solve_closed_form, tensor_feats, tensor_risk, gainF, cost, alpha, Q)\n",
    "        print(f\"Regret: {regret_val:.4f}\")\n",
    "\n",
    "\n",
    "# Compute final regret after training\n",
    "final_regret = regret(model, solve_closed_form, tensor_feats, tensor_risk, gainF, cost, alpha, Q)\n",
    "print(f\"Final Regret: {final_regret:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
