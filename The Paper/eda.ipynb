{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step\n",
    "\n",
    "\n",
    "Discuss general algorithm: need to approximate gradient for back propagation. Then present gradient approximation methods.\n",
    "- Closed-Form Decisions\n",
    "- Linear Decision Objective\n",
    "- Quadratic Decision Objective\n",
    "- Generic Decision Objective\n",
    "\n",
    "Gradient Free Methods\n",
    "\n",
    "Experiments\n",
    "\n",
    "Methods to compare:\n",
    "- Two-stage: prediction then decision, prediction then fair decision, fair prediction then decision, fair prediction then fair decision\n",
    "- DFL: DFL version of each of the above two-stage settings\n",
    "\n",
    "\n",
    "Performance measures to report:\n",
    "- Prediction accuracy: mean square errors of $r$ and $\\hat{r}$\n",
    "- Decision accuracy: mean square errors of $d(r)$ and $d(\\hat{r})$\n",
    "- Prediction fairness: prediction fairness measure of $\\hat{r}$\n",
    "- Decision fairness: decision fairness measure of $d(\\hat(r))$\n",
    "- Runtime of algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import warnings\n",
    "import sys\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, 'E:\\\\User\\\\Stevens\\\\Code\\\\The Paper\\\\algorithm')\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from myutil import *\n",
    "from features import get_all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Prediction Model\n",
    "class RiskDataset(Dataset):\n",
    "    def __init__(self, features, risks):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.risks = torch.FloatTensor(risks).reshape(-1, 1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.risks[idx]\n",
    "    \n",
    "class RiskPredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Training function\n",
    "def train_model(features, risks, epochs=10, batch_size=32):\n",
    "    dataset = RiskDataset(features, risks)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = RiskPredictor(features.shape[1])\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch_features, batch_risks in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(batch_features)\n",
    "            loss = criterion(predictions, batch_risks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48784, 168)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/data.csv')\n",
    "\n",
    "columns_to_keep = [\n",
    "    'risk_score_t', 'program_enrolled_t', 'cost_t', 'cost_avoidable_t', 'race', 'dem_female', 'gagne_sum_tm1', 'gagne_sum_t', \n",
    "    'risk_score_percentile', 'screening_eligible', 'avoidable_cost_mapped', 'propensity_score', 'g_binary', \n",
    "    'g_continuous', 'utility_binary', 'utility_continuous'\n",
    "]\n",
    "# for race 0 is white, 1 is black\n",
    "df_stat = df[columns_to_keep]\n",
    "df_feature = df[[col for col in df.columns if col not in columns_to_keep]]\n",
    "\n",
    "# Replace all values less than 0.1 with 0.1\n",
    "#df['risk_score_t'] = df['risk_score_t'].apply(lambda x: 0.1 if x < 0.1 else x)\n",
    "df['g_continuous'] = df['g_continuous'].apply(lambda x: 0.1 if x < 0.1 else x)\n",
    "\n",
    "# subset a sample of 5000 rows of df\n",
    "# df = df.sample(n=10000, random_state=1)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input variables for DFL\n",
    "feats = df[get_all_features(df)].values\n",
    "risk = df['risk_score_t'].values\n",
    "gainF = df['g_continuous'].values\n",
    "decision = df['propensity_score'].values\n",
    "cost = np.ones(risk.shape)\n",
    "race = df['race'].values\n",
    "alpha = 0.5\n",
    "Q = 1000\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Perform train-test split\n",
    "feats_train, feats_test, gainF_train, gainF_test, risk_train, risk_test, cost_train, cost_test, race_train, race_test = train_test_split(\n",
    "    feats, gainF, risk, cost, df['race'].values, test_size=0.4, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.7172887, 4.393691680358348)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "feats = scaler.fit_transform(feats)\n",
    "\n",
    "# model = train_model(feats, risk)\n",
    "# torch.save(model.state_dict(), 'risk_predictor_model.pth')\n",
    "\n",
    "# Load the model from local\n",
    "model = RiskPredictor(feats.shape[1])\n",
    "model.load_state_dict(torch.load('risk_predictor_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "pred_risk = model(torch.FloatTensor(feats)).detach().numpy().flatten()\n",
    "\n",
    "pred_risk.mean(), risk.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count      mean       std  min       25%       50%       75%  \\\n",
      "race                                                                   \n",
      "0     43202.0  4.266933  5.102404  0.0  1.426873  2.870732  5.282827   \n",
      "1      5582.0  5.374740  7.980310  0.0  1.494819  3.023611  6.030236   \n",
      "\n",
      "             max  \n",
      "race              \n",
      "0     100.000000  \n",
      "1      96.381858  \n",
      "        count      mean       std  min       25%       50%       75%  \\\n",
      "race                                                                   \n",
      "0     43202.0  2.554104  4.139664  0.0  0.053036  0.775554  3.488975   \n",
      "1      5582.0  3.980262  6.118409  0.0  0.111057  1.603591  5.302370   \n",
      "\n",
      "            max  \n",
      "race             \n",
      "0     51.777321  \n",
      "1     60.639240  \n"
     ]
    }
   ],
   "source": [
    "# True Risk Distribution\n",
    "distribution_stats = df_stat.groupby('race')['risk_score_t'].describe()\n",
    "print(distribution_stats)\n",
    "\n",
    "# Predicted Risk Distribution\n",
    "pred_risk_distribution = pd.DataFrame({'race': df['race'], 'pred_risk': pred_risk})\n",
    "distribution_stats_pred_risk = pred_risk_distribution.groupby('race')['pred_risk'].describe()\n",
    "print(distribution_stats_pred_risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Fair Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifically, we'll minimize the difference in mean predictions between the two racial groups (statistical parity). The total loss will be a combination of the Mean Squared Error and the fairness regularizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'race' to the dataset\n",
    "class FairRiskDataset(Dataset):\n",
    "    def __init__(self, features, races, risks):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.races = torch.LongTensor(races)\n",
    "        self.risks = torch.FloatTensor(risks).reshape(-1, 1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.races[idx], self.risks[idx]\n",
    "\n",
    "class FairRiskPredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fair_model(features, races, risks, epochs=10, batch_size=32, lambda_fairness=1.0):\n",
    "    \"\"\"\n",
    "    Train a fair regression model with a fairness regularizer.\n",
    "    \n",
    "    Args:\n",
    "        features (np.ndarray): Feature array.\n",
    "        races (np.ndarray): Array indicating race (0: white, 1: black).\n",
    "        risks (np.ndarray): True risk values.\n",
    "        epochs (int): Number of training epochs.\n",
    "        batch_size (int): Batch size for training.\n",
    "        lambda_fairness (float): Weight for the fairness regularizer.\n",
    "        \n",
    "    Returns:\n",
    "        nn.Module: Trained fair regression model.\n",
    "    \"\"\"\n",
    "    dataset = FairRiskDataset(features, races, risks)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = FairRiskPredictor(features.shape[1])\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch_features, batch_races, batch_risks in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(batch_features)\n",
    "            mse_loss = criterion(predictions, batch_risks)\n",
    "            \n",
    "            # Compute fairness loss\n",
    "            group0 = predictions[batch_races == 0]\n",
    "            group1 = predictions[batch_races == 1]\n",
    "            if len(group0) > 0 and len(group1) > 0:\n",
    "                fairness_loss = torch.abs(group0.mean() - group1.mean())\n",
    "            else:\n",
    "                fairness_loss = torch.tensor(0.0)\n",
    "            \n",
    "            # Total loss\n",
    "            total_loss = mse_loss + lambda_fairness * fairness_loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += total_loss.item()\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            avg_loss = epoch_loss / len(dataloader)\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 37.5431\n",
      "Epoch [5/20], Loss: 23.7993\n",
      "Epoch [10/20], Loss: 20.6913\n",
      "Epoch [15/20], Loss: 19.1335\n",
      "Epoch [20/20], Loss: 17.7668\n"
     ]
    }
   ],
   "source": [
    "# Extract necessary columns\n",
    "features = df[get_all_features(df)].values\n",
    "races = df_stat['race'].values  # 0: white, 1: black\n",
    "risks = df_stat['risk_score_t'].values\n",
    "\n",
    "# Drop rows with any NaNs or Infs\n",
    "mask = ~np.isnan(features).any(axis=1) & ~np.isinf(features).any(axis=1) & \\\n",
    "       ~np.isnan(races) & ~np.isinf(races) & \\\n",
    "       ~np.isnan(risks) & ~np.isinf(risks)\n",
    "\n",
    "features = features[mask]\n",
    "races = races[mask]\n",
    "risks = risks[mask]\n",
    "\n",
    "\n",
    "# Scale features\n",
    "scaler_fair = StandardScaler()\n",
    "features_scaled = scaler_fair.fit_transform(features)\n",
    "\n",
    "# Train the fair regression model\n",
    "lambda_fairness = 0.5  # Adjust this value as needed\n",
    "# fair_model = train_fair_model(features_scaled, races, risks, epochs=20, batch_size=64, lambda_fairness=lambda_fairness)\n",
    "\n",
    "# # Save the fair model\n",
    "# torch.save(fair_model.state_dict(), 'fair_risk_predictor_model.pth')\n",
    "\n",
    "# load the model\n",
    "fair_model = FairRiskPredictor(features_scaled.shape[1])\n",
    "fair_model.load_state_dict(torch.load('fair_risk_predictor_model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FairRiskPredictor(\n",
       "   (model): Sequential(\n",
       "     (0): Linear(in_features=149, out_features=1, bias=True)\n",
       "     (1): Softplus(beta=1, threshold=20)\n",
       "   )\n",
       " ),\n",
       " RiskPredictor(\n",
       "   (model): Sequential(\n",
       "     (0): Linear(in_features=149, out_features=1, bias=True)\n",
       "     (1): Softplus(beta=1, threshold=20)\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_model, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve Optimization Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AlphaFairness(util,alpha):\n",
    "    if alpha == 1:\n",
    "        return np.sum(np.log(util))\n",
    "    elif alpha == 0:\n",
    "        return np.sum(util)\n",
    "    elif alpha == 'inf':\n",
    "        return np.min(util)\n",
    "    else:\n",
    "        return np.sum(util**(1-alpha)/(1-alpha))\n",
    "    \n",
    "def solve_optimization(gainF, risk, cost, alpha, Q):\n",
    "    # Flatten input arrays\n",
    "    gainF, risk, cost = gainF.flatten(), risk.flatten() + 0.001, cost.flatten()\n",
    "    d = cp.Variable(risk.shape, nonneg=True)\n",
    "    \n",
    "    utils = cp.multiply(cp.multiply(gainF, risk), d)\n",
    "    \n",
    "    if alpha == 'inf':\n",
    "        # Maximin formulation\n",
    "        t = cp.Variable()  # auxiliary variable for minimum utility\n",
    "        objective = cp.Maximize(t)\n",
    "        constraints = [\n",
    "            d >= 0,\n",
    "            # d <= 1,\n",
    "            cp.sum(cost * d) <= Q,\n",
    "            utils >= t  # t is the minimum utility\n",
    "        ]\n",
    "    elif alpha == 1:\n",
    "        # Nash welfare (alpha = 1)\n",
    "        objective = cp.Maximize(cp.sum(cp.log(utils)))\n",
    "        constraints = [\n",
    "            d >= 0,\n",
    "            # d <= 1,\n",
    "            cp.sum(cost * d) <= Q\n",
    "        ]\n",
    "    elif alpha == 0:\n",
    "        # Utilitarian welfare (alpha = 0)\n",
    "        objective = cp.Maximize(cp.sum(utils))\n",
    "        constraints = [\n",
    "            d >= 0,\n",
    "            # d <= 1,\n",
    "            cp.sum(cost * d) <= Q\n",
    "        ]\n",
    "    else:\n",
    "        # General alpha-fairness\n",
    "        objective = cp.Maximize(cp.sum(utils**(1-alpha))/(1-alpha) if alpha != 0 \n",
    "                              else cp.sum(utils))\n",
    "        constraints = [\n",
    "            d >= 0,\n",
    "            # d <= 1,\n",
    "            cp.sum(cost * d) <= Q\n",
    "        ]\n",
    "    \n",
    "    # Solve the problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve(solver=cp.MOSEK, verbose=False, warm_start=True, mosek_params={'MSK_IPAR_LOG': 1})\n",
    "    \n",
    "    if problem.status != 'optimal':\n",
    "        print(f\"Warning: Problem status is {problem.status}\")\n",
    "    \n",
    "    optimal_decision = d.value\n",
    "    optimal_value = AlphaFairness(optimal_decision * gainF * risk, alpha)\n",
    "    \n",
    "    return optimal_decision, optimal_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_sol,_ = solve_optimization(gainF, predicted_risk, cost, alpha='inf', Q=Q)\n",
    "# pred_obj = np.sum((risk * gainF * pred_sol)**(1-alpha)/(1-alpha))\n",
    "# true_obj = np.sum((optimal_decision * gainF * risk)**(1-alpha)/(1-alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoStagePTO(model, feats, gainF, risk, cost, Q, alphas=[0.5]):\n",
    "    \"\"\"\n",
    "    Perform a two-stage optimization analysis with predictions and calculate normalized regrets.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): A regression neural network for risk prediction.\n",
    "        feats (np.ndarray): Feature array for predictions.\n",
    "        gainF (np.ndarray): Gain factors.\n",
    "        risk (np.ndarray): True risk values.\n",
    "        cost (np.ndarray): Cost constraints.\n",
    "        Q (float): Budget constraint.\n",
    "        alphas (list): List of alpha values for fairness.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A table of prediction risk means, true risk mean, objectives, and normalized regrets.\n",
    "    \"\"\"\n",
    "\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    feats_scaled = scaler.fit_transform(feats)\n",
    "\n",
    "    # Predict risks\n",
    "    model.eval()\n",
    "    pred_risk = model(torch.FloatTensor(feats_scaled)).detach().numpy().flatten()\n",
    "\n",
    "    # Initialize result storage\n",
    "    results = []\n",
    "\n",
    "    # Iterate over alphas\n",
    "    for alpha in alphas:\n",
    "        # Solve optimization problems\n",
    "        true_sol, _ = solve_optimization(gainF, risk, cost, alpha, Q)\n",
    "        pred_sol, _ = solve_optimization(gainF, pred_risk, cost, alpha, Q)\n",
    "\n",
    "        # Calculate true and predicted utilities\n",
    "        true_utility = (risk + 0.001) * gainF * true_sol\n",
    "        pred_utility = (pred_risk + 0.001) * gainF * pred_sol\n",
    "        pred_utility_truerisk = (risk + 0.001) * gainF * pred_sol\n",
    "\n",
    "        # Calculate objectives\n",
    "        true_obj = AlphaFairness(true_utility, alpha)\n",
    "        pred_obj = AlphaFairness(pred_utility, alpha)\n",
    "        pred_obj_truerisk = AlphaFairness(pred_utility_truerisk, alpha)\n",
    "\n",
    "        # Calculate regret and normalized regret\n",
    "        # regret = true_obj - pred_obj\n",
    "        regret = true_obj - pred_obj_truerisk\n",
    "        normalized_regret = regret / (abs(true_obj) + 1e-7)        \n",
    "\n",
    "        # Collect results for this alpha\n",
    "        results.append({\n",
    "            'Alpha': alpha,\n",
    "            'Predicted Risk Mean': pred_risk.mean(),\n",
    "            'True Risk Mean': risk.mean(),\n",
    "            'True Objective': true_obj,\n",
    "            'Predicted Objective': pred_obj,\n",
    "            'Regret': f\"{regret:.2f}\",\n",
    "            'Normalized Regret': f\"{normalized_regret:.2f}\"\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame for results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(results_df)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = df.sample(n=40000, random_state=42)\n",
    "feats_sample = data_sample[get_all_features(data_sample)].values\n",
    "risk_sample = data_sample['risk_score_t'].values\n",
    "gainF_sample = data_sample['g_continuous'].values\n",
    "decision_sample = data_sample['propensity_score'].values\n",
    "cost_sample = np.ones(risk_sample.shape)\n",
    "race_sample = data_sample['race'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Predicted Risk Mean</th>\n",
       "      <th>True Risk Mean</th>\n",
       "      <th>True Objective</th>\n",
       "      <th>Predicted Objective</th>\n",
       "      <th>Regret</th>\n",
       "      <th>Normalized Regret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>284164.896752</td>\n",
       "      <td>7.960235e+06</td>\n",
       "      <td>104721.50</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>73629.284021</td>\n",
       "      <td>3.811415e+04</td>\n",
       "      <td>23887.93</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>361873.257701</td>\n",
       "      <td>3.060051e+05</td>\n",
       "      <td>658.10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>-44900.932086</td>\n",
       "      <td>-1.127005e+05</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>-834952.038551</td>\n",
       "      <td>-1.546416e+06</td>\n",
       "      <td>2847299.59</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>inf</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>3.833028e-03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alpha  Predicted Risk Mean  True Risk Mean  True Objective  \\\n",
       "0    0.0             2.703654        4.387568   284164.896752   \n",
       "1    0.5             2.703654        4.387568    73629.284021   \n",
       "2    0.9             2.703654        4.387568   361873.257701   \n",
       "3    1.0             2.703654        4.387568   -44900.932086   \n",
       "4    2.0             2.703654        4.387568  -834952.038551   \n",
       "5    inf             2.703654        4.387568        0.000627   \n",
       "\n",
       "   Predicted Objective      Regret  Normalized Regret  \n",
       "0         7.960235e+06   104721.50               0.37  \n",
       "1         3.811415e+04    23887.93               0.32  \n",
       "2         3.060051e+05      658.10               0.00  \n",
       "3        -1.127005e+05       -0.00              -0.00  \n",
       "4        -1.546416e+06  2847299.59               3.41  \n",
       "5         3.833028e-03        0.00               1.00  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results.to_csv('data/results.csv', index=False)\n",
    "# results = twoStagePTO(model, feats_sample, gainF_sample, risk_sample, cost_sample, Q, alphas=[0,.5,.9,1,2,'inf'])\n",
    "results = pd.read_csv('data/results.csv')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoStagePTO_with_bias_analysis(model, fair_model, feats, gainF, risk, cost, race, Q=1000, alphas=[0.5],):\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    feats_scaled = scaler.fit_transform(feats)\n",
    "\n",
    "    # Predict risks\n",
    "    model.eval()\n",
    "    pred_risk = model(torch.FloatTensor(feats_scaled)).detach().numpy().flatten()\n",
    "    fair_pred_risk = fair_model(torch.FloatTensor(feats_scaled)).detach().numpy().flatten()\n",
    "\n",
    "    # Initialize result storage\n",
    "    results = []\n",
    "    bias_analysis = []\n",
    "    fair_pto_results = []\n",
    "    fair_pto_analysis = []\n",
    "\n",
    "    # Iterate over alphas\n",
    "    for alpha in alphas:\n",
    "        # Solve optimization problems\n",
    "        true_sol, _ = solve_optimization(gainF, risk, cost, alpha, Q)\n",
    "        pred_sol, _ = solve_optimization(gainF, pred_risk, cost, alpha, Q)\n",
    "        fair_pred_sol, _ = solve_optimization(gainF, fair_pred_risk, cost, alpha, Q)\n",
    "\n",
    "        # Calculate true and predicted utilities\n",
    "        true_utility = (risk + 0.001) * gainF * true_sol\n",
    "        pred_utility = (pred_risk + 0.001) * gainF * pred_sol\n",
    "        pred_utility_truerisk = (risk + 0.001) * gainF * pred_sol\n",
    "        fair_pred_utility_truerisk = (risk + 0.001) * gainF * fair_pred_sol\n",
    "\n",
    "        # Calculate objectives\n",
    "        true_obj = AlphaFairness(true_utility, alpha)\n",
    "        pred_obj = AlphaFairness(pred_utility, alpha)\n",
    "        pred_obj_truerisk = AlphaFairness(pred_utility_truerisk, alpha)\n",
    "        fair_pred_obj_truerisk = AlphaFairness(fair_pred_utility_truerisk, alpha)\n",
    "\n",
    "        # Calculate regret and normalized regret\n",
    "        # regret = true_obj - pred_obj\n",
    "        regret = true_obj - pred_obj_truerisk\n",
    "        normalized_regret = regret / (abs(true_obj) + 1e-7)\n",
    "\n",
    "        fair_regret = true_obj - fair_pred_obj_truerisk\n",
    "        fair_normalized_regret = fair_regret / (abs(true_obj) + 1e-7)\n",
    "\n",
    "        # Collect results for this alpha\n",
    "        results.append({\n",
    "            'Alpha': alpha,\n",
    "            'Predicted Risk Mean': pred_risk.mean(),\n",
    "            'True Risk Mean': risk.mean(),\n",
    "            'True Objective': true_obj,\n",
    "            'Predicted Objective': pred_obj,\n",
    "            'Regret': f\"{regret:.2f}\",\n",
    "            'Normalized Regret': f\"{normalized_regret:.2f}\"\n",
    "        })\n",
    "\n",
    "        fair_pto_results.append({\n",
    "            'Alpha': alpha,\n",
    "            'Predicted Risk Mean': fair_pred_risk.mean(),\n",
    "            'True Risk Mean': risk.mean(),\n",
    "            'True Objective': true_obj,\n",
    "            'Predicted Objective': fair_pred_obj_truerisk,\n",
    "            'Regret': f\"{fair_regret:.2f}\",\n",
    "            'Normalized Regret': f\"{fair_normalized_regret:.2f}\"\n",
    "        })\n",
    "\n",
    "        # Analyze bias in the optimal solution and utilities by race\n",
    "        for r in [0, 1]:  # 0 = white, 1 = black\n",
    "            mask = race == r\n",
    "            race_stats = {\n",
    "                'Alpha': alpha,\n",
    "                'Race': r,\n",
    "                'True Solution Mean': true_sol[mask].mean(),\n",
    "                'True Solution Std': true_sol[mask].std(),\n",
    "                'Predicted Solution Mean': pred_sol[mask].mean(),\n",
    "                'Predicted Solution Std': pred_sol[mask].std(),\n",
    "                'True Utility Mean': true_utility[mask].mean(),\n",
    "                'True Utility Std': true_utility[mask].std(),\n",
    "                'Predicted Utility Mean': pred_utility[mask].mean(),\n",
    "                'Predicted Utility Std': pred_utility[mask].std()\n",
    "            }\n",
    "            bias_analysis.append(race_stats)\n",
    "        \n",
    "        # Analyze bias in the optimal solution and utilities by race in for fair model\n",
    "        for r in [0, 1]:\n",
    "            mask = race == r\n",
    "            fair_stats = {\n",
    "                'Alpha': alpha,\n",
    "                'Race': r,\n",
    "                'True Solution Mean': true_sol[mask].mean(),\n",
    "                'True Solution Std': true_sol[mask].std(),\n",
    "                'Predicted Solution Mean': fair_pred_sol[mask].mean(),\n",
    "                'Predicted Solution Std': fair_pred_sol[mask].std(),\n",
    "                'True Utility Mean': true_utility[mask].mean(),\n",
    "                'True Utility Std': true_utility[mask].std(),\n",
    "                'Predicted Utility Mean': fair_pred_utility_truerisk[mask].mean(),\n",
    "                'Predicted Utility Std': fair_pred_utility_truerisk[mask].std()\n",
    "            }\n",
    "            fair_pto_analysis.append(fair_stats)\n",
    "\n",
    "\n",
    "    # Create DataFrames for results and bias analysis\n",
    "    results_df = pd.DataFrame(results)\n",
    "    bias_analysis_df = pd.DataFrame(bias_analysis)\n",
    "    bias_analysis_df['Race'] = bias_analysis_df['Race'].replace({0: 'White', 1: 'Black'})\n",
    "\n",
    "    fair_pto_results_df = pd.DataFrame(fair_pto_results)\n",
    "    fair_pto_analysis_df = pd.DataFrame(fair_pto_analysis)\n",
    "    fair_pto_analysis_df['Race'] = fair_pto_analysis_df['Race'].replace({0: 'White', 1: 'Black'})\n",
    "\n",
    "    return results_df, bias_analysis_df, fair_pto_results_df, fair_pto_analysis_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# racial_results, racial_bias_analysis, fair_pto_results, fair_pto_analysis = twoStagePTO_with_bias_analysis(model, fair_model, feats_sample, gainF_sample, risk_sample, cost_sample, race_sample, alphas=[0,.5,.9,1,2,'inf'])\n",
    "\n",
    "# racial_bias_analysis = racial_bias_analysis.round(8)\n",
    "# fair_pto_analysis = fair_pto_analysis.round(8)\n",
    "\n",
    "# racial_bias_analysis.to_csv('data/racial_bias_analysis.csv', index=False)\n",
    "# fair_pto_analysis.to_csv('data/fair_pto_analysis.csv', index=False)\n",
    "# fair_pto_results.to_csv('data/fair_pto_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Predicted Risk Mean</th>\n",
       "      <th>True Risk Mean</th>\n",
       "      <th>True Objective</th>\n",
       "      <th>Predicted Objective</th>\n",
       "      <th>Regret</th>\n",
       "      <th>Normalized Regret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>284164.896752</td>\n",
       "      <td>7.960235e+06</td>\n",
       "      <td>104721.50</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>73629.284021</td>\n",
       "      <td>3.811415e+04</td>\n",
       "      <td>23887.93</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>361873.257701</td>\n",
       "      <td>3.060051e+05</td>\n",
       "      <td>658.10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>-44900.932086</td>\n",
       "      <td>-1.127005e+05</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>-834952.038551</td>\n",
       "      <td>-1.546416e+06</td>\n",
       "      <td>2847299.59</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>inf</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>3.833028e-03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alpha  Predicted Risk Mean  True Risk Mean  True Objective  \\\n",
       "0    0.0             2.703654        4.387568   284164.896752   \n",
       "1    0.5             2.703654        4.387568    73629.284021   \n",
       "2    0.9             2.703654        4.387568   361873.257701   \n",
       "3    1.0             2.703654        4.387568   -44900.932086   \n",
       "4    2.0             2.703654        4.387568  -834952.038551   \n",
       "5    inf             2.703654        4.387568        0.000627   \n",
       "\n",
       "   Predicted Objective      Regret  Normalized Regret  \n",
       "0         7.960235e+06   104721.50               0.37  \n",
       "1         3.811415e+04    23887.93               0.32  \n",
       "2         3.060051e+05      658.10               0.00  \n",
       "3        -1.127005e+05       -0.00              -0.00  \n",
       "4        -1.546416e+06  2847299.59               3.41  \n",
       "5         3.833028e-03        0.00               1.00  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Predicted Risk Mean</th>\n",
       "      <th>True Risk Mean</th>\n",
       "      <th>True Objective</th>\n",
       "      <th>Predicted Objective</th>\n",
       "      <th>Regret</th>\n",
       "      <th>Normalized Regret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>284164.896752</td>\n",
       "      <td>7.960235e+06</td>\n",
       "      <td>104721.50</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>73629.284021</td>\n",
       "      <td>3.811415e+04</td>\n",
       "      <td>23887.93</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>361873.257701</td>\n",
       "      <td>3.060051e+05</td>\n",
       "      <td>658.10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>-44900.932086</td>\n",
       "      <td>-1.127005e+05</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>-834952.038551</td>\n",
       "      <td>-1.546416e+06</td>\n",
       "      <td>2847299.59</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>inf</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>3.833028e-03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Alpha  Predicted Risk Mean  True Risk Mean  True Objective  \\\n",
       "0     0             2.703654        4.387568   284164.896752   \n",
       "1   0.5             2.703654        4.387568    73629.284021   \n",
       "2   0.9             2.703654        4.387568   361873.257701   \n",
       "3     1             2.703654        4.387568   -44900.932086   \n",
       "4     2             2.703654        4.387568  -834952.038551   \n",
       "5   inf             2.703654        4.387568        0.000627   \n",
       "\n",
       "   Predicted Objective      Regret Normalized Regret  \n",
       "0         7.960235e+06   104721.50              0.37  \n",
       "1         3.811415e+04    23887.93              0.32  \n",
       "2         3.060051e+05      658.10              0.00  \n",
       "3        -1.127005e+05       -0.00             -0.00  \n",
       "4        -1.546416e+06  2847299.59              3.41  \n",
       "5         3.833028e-03        0.00              1.00  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "racial_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Risk Mean</th>\n",
       "      <th>True Risk Mean</th>\n",
       "      <th>True Objective</th>\n",
       "      <th>Predicted Objective</th>\n",
       "      <th>Regret</th>\n",
       "      <th>Normalized Regret</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>2.733022</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>284164.896752</td>\n",
       "      <td>1.766419e+05</td>\n",
       "      <td>107522.97</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>2.733022</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>73629.284021</td>\n",
       "      <td>5.448407e+04</td>\n",
       "      <td>19145.22</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>2.733022</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>361873.257701</td>\n",
       "      <td>3.613766e+05</td>\n",
       "      <td>496.65</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2.733022</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>-44900.932086</td>\n",
       "      <td>-4.490093e+04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>2.733022</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>-834952.038551</td>\n",
       "      <td>-3.321640e+06</td>\n",
       "      <td>2486687.55</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inf</th>\n",
       "      <td>2.733022</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>2.412388e-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predicted Risk Mean  True Risk Mean  True Objective  \\\n",
       "Alpha                                                        \n",
       "0.0               2.733022        4.387568   284164.896752   \n",
       "0.5               2.733022        4.387568    73629.284021   \n",
       "0.9               2.733022        4.387568   361873.257701   \n",
       "1.0               2.733022        4.387568   -44900.932086   \n",
       "2.0               2.733022        4.387568  -834952.038551   \n",
       "inf               2.733022        4.387568        0.000627   \n",
       "\n",
       "       Predicted Objective      Regret  Normalized Regret  \n",
       "Alpha                                                      \n",
       "0.0           1.766419e+05   107522.97               0.38  \n",
       "0.5           5.448407e+04    19145.22               0.26  \n",
       "0.9           3.613766e+05      496.65               0.00  \n",
       "1.0          -4.490093e+04        0.00               0.00  \n",
       "2.0          -3.321640e+06  2486687.55               2.98  \n",
       "inf           2.412388e-06        0.00               1.00  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_pto_results = pd.read_csv('data/fair_pto_results.csv')\n",
    "fair_pto_results.groupby('Alpha').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>True Solution Mean</th>\n",
       "      <th>True Solution Std</th>\n",
       "      <th>Predicted Solution Mean</th>\n",
       "      <th>Predicted Solution Std</th>\n",
       "      <th>True Utility Mean</th>\n",
       "      <th>True Utility Std</th>\n",
       "      <th>Predicted Utility Mean</th>\n",
       "      <th>Predicted Utility Std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <th>Race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.028225</td>\n",
       "      <td>5.312689</td>\n",
       "      <td>0.028225</td>\n",
       "      <td>5.312689</td>\n",
       "      <td>8.020686</td>\n",
       "      <td>1509.679826</td>\n",
       "      <td>4.985801</td>\n",
       "      <td>938.443701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.5</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.023181</td>\n",
       "      <td>0.035950</td>\n",
       "      <td>0.027342</td>\n",
       "      <td>0.097788</td>\n",
       "      <td>2.479947</td>\n",
       "      <td>6.371667</td>\n",
       "      <td>1.665787</td>\n",
       "      <td>10.759633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.025235</td>\n",
       "      <td>0.036278</td>\n",
       "      <td>0.024698</td>\n",
       "      <td>0.144549</td>\n",
       "      <td>2.646779</td>\n",
       "      <td>6.408446</td>\n",
       "      <td>1.825810</td>\n",
       "      <td>25.133334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.9</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.024675</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.025380</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>0.945569</td>\n",
       "      <td>1.602100</td>\n",
       "      <td>0.846239</td>\n",
       "      <td>1.367325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.025042</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.024951</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>1.029735</td>\n",
       "      <td>1.615768</td>\n",
       "      <td>0.912369</td>\n",
       "      <td>1.382302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.785466</td>\n",
       "      <td>1.218131</td>\n",
       "      <td>0.785441</td>\n",
       "      <td>1.218093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.855046</td>\n",
       "      <td>1.229236</td>\n",
       "      <td>0.855019</td>\n",
       "      <td>1.229198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.026925</td>\n",
       "      <td>0.227790</td>\n",
       "      <td>0.023978</td>\n",
       "      <td>0.079558</td>\n",
       "      <td>0.152662</td>\n",
       "      <td>0.119106</td>\n",
       "      <td>0.483615</td>\n",
       "      <td>0.801976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.215799</td>\n",
       "      <td>0.025132</td>\n",
       "      <td>0.070277</td>\n",
       "      <td>0.162163</td>\n",
       "      <td>0.120497</td>\n",
       "      <td>0.555863</td>\n",
       "      <td>0.853823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">inf</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.027516</td>\n",
       "      <td>0.413693</td>\n",
       "      <td>0.030162</td>\n",
       "      <td>0.494613</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089678</td>\n",
       "      <td>1.160345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.024675</td>\n",
       "      <td>0.391829</td>\n",
       "      <td>0.024334</td>\n",
       "      <td>0.376532</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084970</td>\n",
       "      <td>0.850023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             True Solution Mean  True Solution Std  Predicted Solution Mean  \\\n",
       "Alpha Race                                                                    \n",
       "0.0   Black            0.000000           0.000000                 0.000000   \n",
       "      White            0.028225           5.312689                 0.028225   \n",
       "0.5   Black            0.023181           0.035950                 0.027342   \n",
       "      White            0.025235           0.036278                 0.024698   \n",
       "0.9   Black            0.024675           0.003974                 0.025380   \n",
       "      White            0.025042           0.004007                 0.024951   \n",
       "1.0   Black            0.025000           0.000010                 0.025000   \n",
       "      White            0.025000           0.000010                 0.025000   \n",
       "2.0   Black            0.026925           0.227790                 0.023978   \n",
       "      White            0.024752           0.215799                 0.025132   \n",
       "inf   Black            0.027516           0.413693                 0.030162   \n",
       "      White            0.024675           0.391829                 0.024334   \n",
       "\n",
       "             Predicted Solution Std  True Utility Mean  True Utility Std  \\\n",
       "Alpha Race                                                                 \n",
       "0.0   Black                0.000000           0.000000          0.000000   \n",
       "      White                5.312689           8.020686       1509.679826   \n",
       "0.5   Black                0.097788           2.479947          6.371667   \n",
       "      White                0.144549           2.646779          6.408446   \n",
       "0.9   Black                0.003714           0.945569          1.602100   \n",
       "      White                0.003765           1.029735          1.615768   \n",
       "1.0   Black                0.000003           0.785466          1.218131   \n",
       "      White                0.000003           0.855046          1.229236   \n",
       "2.0   Black                0.079558           0.152662          0.119106   \n",
       "      White                0.070277           0.162163          0.120497   \n",
       "inf   Black                0.494613           0.000627          0.000000   \n",
       "      White                0.376532           0.000627          0.000000   \n",
       "\n",
       "             Predicted Utility Mean  Predicted Utility Std  \n",
       "Alpha Race                                                  \n",
       "0.0   Black                0.000000               0.000000  \n",
       "      White                4.985801             938.443701  \n",
       "0.5   Black                1.665787              10.759633  \n",
       "      White                1.825810              25.133334  \n",
       "0.9   Black                0.846239               1.367325  \n",
       "      White                0.912369               1.382302  \n",
       "1.0   Black                0.785441               1.218093  \n",
       "      White                0.855019               1.229198  \n",
       "2.0   Black                0.483615               0.801976  \n",
       "      White                0.555863               0.853823  \n",
       "inf   Black                0.089678               1.160345  \n",
       "      White                0.084970               0.850023  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_pto_analysis = pd.read_csv('data/fair_pto_analysis.csv')\n",
    "fair_pto_analysis.groupby(['Alpha', 'Race']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>True Solution Mean</th>\n",
       "      <th>True Solution Std</th>\n",
       "      <th>Predicted Solution Mean</th>\n",
       "      <th>Predicted Solution Std</th>\n",
       "      <th>True Utility Mean</th>\n",
       "      <th>True Utility Std</th>\n",
       "      <th>Predicted Utility Mean</th>\n",
       "      <th>Predicted Utility Std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <th>Race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.028225</td>\n",
       "      <td>5.312689</td>\n",
       "      <td>0.028225</td>\n",
       "      <td>5.312689e+00</td>\n",
       "      <td>8.020686</td>\n",
       "      <td>1509.679826</td>\n",
       "      <td>224.681324</td>\n",
       "      <td>42290.253843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.5</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.023181</td>\n",
       "      <td>0.035950</td>\n",
       "      <td>0.028787</td>\n",
       "      <td>1.233266e-01</td>\n",
       "      <td>2.479947</td>\n",
       "      <td>6.371667</td>\n",
       "      <td>5.824611</td>\n",
       "      <td>126.158507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.025235</td>\n",
       "      <td>0.036278</td>\n",
       "      <td>0.024511</td>\n",
       "      <td>1.855345e-01</td>\n",
       "      <td>2.646779</td>\n",
       "      <td>6.408446</td>\n",
       "      <td>12.720251</td>\n",
       "      <td>1152.159325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.9</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.024675</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.025626</td>\n",
       "      <td>4.277230e-03</td>\n",
       "      <td>0.945569</td>\n",
       "      <td>1.602100</td>\n",
       "      <td>0.365721</td>\n",
       "      <td>2.078181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.025042</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.024919</td>\n",
       "      <td>4.393810e-03</td>\n",
       "      <td>1.029735</td>\n",
       "      <td>1.615768</td>\n",
       "      <td>0.312457</td>\n",
       "      <td>3.827480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>2.340000e-06</td>\n",
       "      <td>0.785466</td>\n",
       "      <td>1.218131</td>\n",
       "      <td>0.261360</td>\n",
       "      <td>1.119721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>9.700000e-07</td>\n",
       "      <td>0.855046</td>\n",
       "      <td>1.229236</td>\n",
       "      <td>0.222547</td>\n",
       "      <td>1.684594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.026925</td>\n",
       "      <td>0.227790</td>\n",
       "      <td>0.022331</td>\n",
       "      <td>6.234881e-02</td>\n",
       "      <td>0.152662</td>\n",
       "      <td>0.119106</td>\n",
       "      <td>0.058741</td>\n",
       "      <td>0.057505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.215799</td>\n",
       "      <td>0.025344</td>\n",
       "      <td>5.960121e-02</td>\n",
       "      <td>0.162163</td>\n",
       "      <td>0.120497</td>\n",
       "      <td>0.052995</td>\n",
       "      <td>0.054254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">inf</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.027516</td>\n",
       "      <td>0.413693</td>\n",
       "      <td>0.026002</td>\n",
       "      <td>4.189160e-01</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.024675</td>\n",
       "      <td>0.391829</td>\n",
       "      <td>0.024871</td>\n",
       "      <td>3.555798e-01</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             True Solution Mean  True Solution Std  Predicted Solution Mean  \\\n",
       "Alpha Race                                                                    \n",
       "0.0   Black            0.000000           0.000000                 0.000000   \n",
       "      White            0.028225           5.312689                 0.028225   \n",
       "0.5   Black            0.023181           0.035950                 0.028787   \n",
       "      White            0.025235           0.036278                 0.024511   \n",
       "0.9   Black            0.024675           0.003974                 0.025626   \n",
       "      White            0.025042           0.004007                 0.024919   \n",
       "1.0   Black            0.025000           0.000010                 0.025000   \n",
       "      White            0.025000           0.000010                 0.025000   \n",
       "2.0   Black            0.026925           0.227790                 0.022331   \n",
       "      White            0.024752           0.215799                 0.025344   \n",
       "inf   Black            0.027516           0.413693                 0.026002   \n",
       "      White            0.024675           0.391829                 0.024871   \n",
       "\n",
       "             Predicted Solution Std  True Utility Mean  True Utility Std  \\\n",
       "Alpha Race                                                                 \n",
       "0.0   Black            0.000000e+00           0.000000          0.000000   \n",
       "      White            5.312689e+00           8.020686       1509.679826   \n",
       "0.5   Black            1.233266e-01           2.479947          6.371667   \n",
       "      White            1.855345e-01           2.646779          6.408446   \n",
       "0.9   Black            4.277230e-03           0.945569          1.602100   \n",
       "      White            4.393810e-03           1.029735          1.615768   \n",
       "1.0   Black            2.340000e-06           0.785466          1.218131   \n",
       "      White            9.700000e-07           0.855046          1.229236   \n",
       "2.0   Black            6.234881e-02           0.152662          0.119106   \n",
       "      White            5.960121e-02           0.162163          0.120497   \n",
       "inf   Black            4.189160e-01           0.000627          0.000000   \n",
       "      White            3.555798e-01           0.000627          0.000000   \n",
       "\n",
       "             Predicted Utility Mean  Predicted Utility Std  \n",
       "Alpha Race                                                  \n",
       "0.0   Black                0.000000               0.000000  \n",
       "      White              224.681324           42290.253843  \n",
       "0.5   Black                5.824611             126.158507  \n",
       "      White               12.720251            1152.159325  \n",
       "0.9   Black                0.365721               2.078181  \n",
       "      White                0.312457               3.827480  \n",
       "1.0   Black                0.261360               1.119721  \n",
       "      White                0.222547               1.684594  \n",
       "2.0   Black                0.058741               0.057505  \n",
       "      White                0.052995               0.054254  \n",
       "inf   Black                0.003833               0.000000  \n",
       "      White                0.003833               0.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "racial_bias_analysis = pd.read_csv('data/racial_bias_analysis.csv')\n",
    "racial_bias_analysis.groupby(['Alpha', 'Race']).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
