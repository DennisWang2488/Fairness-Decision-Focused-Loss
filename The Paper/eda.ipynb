{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step\n",
    "\n",
    "\n",
    "Discuss general algorithm: need to approximate gradient for back propagation. Then present gradient approximation methods.\n",
    "- Closed-Form Decisions\n",
    "- Linear Decision Objective\n",
    "- Quadratic Decision Objective\n",
    "- Generic Decision Objective\n",
    "\n",
    "Gradient Free Methods\n",
    "\n",
    "Experiments\n",
    "\n",
    "Methods to compare:\n",
    "- Two-stage: prediction then decision, prediction then fair decision, fair prediction then decision, fair prediction then fair decision\n",
    "- DFL: DFL version of each of the above two-stage settings\n",
    "\n",
    "\n",
    "Performance measures to report:\n",
    "- Prediction accuracy: mean square errors of $r$ and $\\hat{r}$\n",
    "- Decision accuracy: mean square errors of $d(r)$ and $d(\\hat{r})$\n",
    "- Prediction fairness: prediction fairness measure of $\\hat{r}$\n",
    "- Decision fairness: decision fairness measure of $d(\\hat(r))$\n",
    "- Runtime of algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import warnings\n",
    "import sys\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, 'E:\\\\User\\\\Stevens\\\\Code\\\\The Paper\\\\algorithm')\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from myutil import *\n",
    "from features import get_all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Prediction Model\n",
    "class RiskDataset(Dataset):\n",
    "    def __init__(self, features, risks):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.risks = torch.FloatTensor(risks).reshape(-1, 1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.risks[idx]\n",
    "    \n",
    "class RiskPredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Training function\n",
    "def train_model(features, risks, epochs=10, batch_size=32):\n",
    "    dataset = RiskDataset(features, risks)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = RiskPredictor(features.shape[1])\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch_features, batch_risks in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(batch_features)\n",
    "            loss = criterion(predictions, batch_risks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48784, 168)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/data.csv')\n",
    "\n",
    "columns_to_keep = [\n",
    "    'risk_score_t', 'program_enrolled_t', 'cost_t', 'cost_avoidable_t', 'race', 'dem_female', 'gagne_sum_tm1', 'gagne_sum_t', \n",
    "    'risk_score_percentile', 'screening_eligible', 'avoidable_cost_mapped', 'propensity_score', 'g_binary', \n",
    "    'g_continuous', 'utility_binary', 'utility_continuous'\n",
    "]\n",
    "# for race 0 is white, 1 is black\n",
    "df_stat = df[columns_to_keep]\n",
    "df_feature = df[[col for col in df.columns if col not in columns_to_keep]]\n",
    "\n",
    "# Replace all values less than 0.1 with 0.1\n",
    "#df['risk_score_t'] = df['risk_score_t'].apply(lambda x: 0.1 if x < 0.1 else x)\n",
    "df['g_continuous'] = df['g_continuous'].apply(lambda x: 0.1 if x < 0.1 else x)\n",
    "\n",
    "# subset a sample of 5000 rows of df\n",
    "# df = df.sample(n=10000, random_state=1)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input variables for DFL\n",
    "feats = df[get_all_features(df)].values\n",
    "risk = df['risk_score_t'].values\n",
    "gainF = df['g_continuous'].values\n",
    "decision = df['propensity_score'].values\n",
    "cost = np.ones(risk.shape)\n",
    "race = df['race'].values\n",
    "alpha = 0.5\n",
    "Q = 1000\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Perform train-test split\n",
    "feats_train, feats_test, gainF_train, gainF_test, risk_train, risk_test, cost_train, cost_test, race_train, race_test = train_test_split(\n",
    "    feats, gainF, risk, cost, df['race'].values, test_size=0.4, random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.7172887, 4.393691680358348)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "feats = scaler.fit_transform(feats)\n",
    "\n",
    "# model = train_model(feats, risk)\n",
    "# torch.save(model.state_dict(), 'risk_predictor_model.pth')\n",
    "\n",
    "# Load the model from local\n",
    "model = RiskPredictor(feats.shape[1])\n",
    "model.load_state_dict(torch.load('risk_predictor_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "pred_risk = model(torch.FloatTensor(feats)).detach().numpy().flatten()\n",
    "\n",
    "pred_risk.mean(), risk.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count      mean       std  min       25%       50%       75%  \\\n",
      "race                                                                   \n",
      "0     43202.0  4.266933  5.102404  0.0  1.426873  2.870732  5.282827   \n",
      "1      5582.0  5.374740  7.980310  0.0  1.494819  3.023611  6.030236   \n",
      "\n",
      "             max  \n",
      "race              \n",
      "0     100.000000  \n",
      "1      96.381858  \n",
      "        count      mean       std  min       25%       50%       75%  \\\n",
      "race                                                                   \n",
      "0     43202.0  2.554104  4.139664  0.0  0.053036  0.775554  3.488975   \n",
      "1      5582.0  3.980262  6.118409  0.0  0.111057  1.603591  5.302370   \n",
      "\n",
      "            max  \n",
      "race             \n",
      "0     51.777321  \n",
      "1     60.639240  \n"
     ]
    }
   ],
   "source": [
    "# True Risk Distribution\n",
    "distribution_stats = df_stat.groupby('race')['risk_score_t'].describe()\n",
    "print(distribution_stats)\n",
    "\n",
    "# Predicted Risk Distribution\n",
    "pred_risk_distribution = pd.DataFrame({'race': df['race'], 'pred_risk': pred_risk})\n",
    "distribution_stats_pred_risk = pred_risk_distribution.groupby('race')['pred_risk'].describe()\n",
    "print(distribution_stats_pred_risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Fair Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifically, we'll minimize the difference in mean predictions between the two racial groups (statistical parity). The total loss will be a combination of the Mean Squared Error and the fairness regularizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'race' to the dataset\n",
    "class FairRiskDataset(Dataset):\n",
    "    def __init__(self, features, races, risks):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.races = torch.LongTensor(races)\n",
    "        self.risks = torch.FloatTensor(risks).reshape(-1, 1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.races[idx], self.risks[idx]\n",
    "\n",
    "class FairRiskPredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fair_model(features, races, risks, epochs=10, batch_size=32, lambda_fairness=0.8):\n",
    "    \"\"\"\n",
    "    Train a fair regression model with a fairness regularizer.\n",
    "    \n",
    "    Args:\n",
    "        features (np.ndarray): Feature array.\n",
    "        races (np.ndarray): Array indicating race (0: white, 1: black).\n",
    "        risks (np.ndarray): True risk values.\n",
    "        epochs (int): Number of training epochs.\n",
    "        batch_size (int): Batch size for training.\n",
    "        lambda_fairness (float): Weight for the fairness regularizer.\n",
    "        \n",
    "    Returns:\n",
    "        nn.Module: Trained fair regression model.\n",
    "    \"\"\"\n",
    "    dataset = FairRiskDataset(features, races, risks)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = FairRiskPredictor(features.shape[1])\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch_features, batch_races, batch_risks in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(batch_features)\n",
    "            mse_loss = criterion(predictions, batch_risks)\n",
    "            \n",
    "            # Compute fairness loss\n",
    "            group0 = predictions[batch_races == 0]\n",
    "            group1 = predictions[batch_races == 1]\n",
    "            if len(group0) > 0 and len(group1) > 0:\n",
    "                fairness_loss = torch.abs(group0.mean() - group1.mean())\n",
    "            else:\n",
    "                fairness_loss = torch.tensor(0.0)\n",
    "            \n",
    "            # Total loss\n",
    "            total_loss = mse_loss + lambda_fairness * fairness_loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += total_loss.item()\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            avg_loss = epoch_loss / len(dataloader)\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract necessary columns\n",
    "features = df[get_all_features(df)].values\n",
    "races = df_stat['race'].values  # 0: white, 1: black\n",
    "risks = df_stat['risk_score_t'].values\n",
    "\n",
    "# Drop rows with any NaNs or Infs\n",
    "mask = ~np.isnan(features).any(axis=1) & ~np.isinf(features).any(axis=1) & \\\n",
    "       ~np.isnan(races) & ~np.isinf(races) & \\\n",
    "       ~np.isnan(risks) & ~np.isinf(risks)\n",
    "\n",
    "features = features[mask]\n",
    "races = races[mask]\n",
    "risks = risks[mask]\n",
    "\n",
    "\n",
    "# Scale features\n",
    "scaler_fair = StandardScaler()\n",
    "features_scaled = scaler_fair.fit_transform(features)\n",
    "\n",
    "# Train the fair regression model\n",
    "lambda_fairness = 1  # Adjust this value as needed\n",
    "# fair_model = train_fair_model(features_scaled, races, risks, epochs=20, batch_size=64, lambda_fairness=lambda_fairness)\n",
    "\n",
    "# # Save the fair model\n",
    "# torch.save(fair_model.state_dict(), 'fair_risk_predictor_model.pth')\n",
    "\n",
    "# load the model\n",
    "fair_model = FairRiskPredictor(features_scaled.shape[1])\n",
    "fair_model.load_state_dict(torch.load('fair_risk_predictor_model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FairRiskPredictor(\n",
       "   (model): Sequential(\n",
       "     (0): Linear(in_features=149, out_features=1, bias=True)\n",
       "     (1): Softplus(beta=1, threshold=20)\n",
       "   )\n",
       " ),\n",
       " RiskPredictor(\n",
       "   (model): Sequential(\n",
       "     (0): Linear(in_features=149, out_features=1, bias=True)\n",
       "     (1): Softplus(beta=1, threshold=20)\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_model, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve Optimization Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AlphaFairness(util,alpha):\n",
    "    if alpha == 1:\n",
    "        return np.sum(np.log(util))\n",
    "    elif alpha == 0:\n",
    "        return np.sum(util)\n",
    "    elif alpha == 'inf':\n",
    "        return np.min(util)\n",
    "    else:\n",
    "        return np.sum(util**(1-alpha)/(1-alpha))\n",
    "    \n",
    "def solve_optimization(gainF, risk, cost, alpha, Q):\n",
    "    # Flatten input arrays\n",
    "    gainF, risk, cost = gainF.flatten(), risk.flatten() + 0.001, cost.flatten()\n",
    "    d = cp.Variable(risk.shape, nonneg=True)\n",
    "    \n",
    "    utils = cp.multiply(cp.multiply(gainF, risk), d)\n",
    "    \n",
    "    if alpha == 'inf':\n",
    "        # Maximin formulation\n",
    "        t = cp.Variable()  # auxiliary variable for minimum utility\n",
    "        objective = cp.Maximize(t)\n",
    "        constraints = [\n",
    "            d >= 0,\n",
    "            # d <= 1,\n",
    "            cp.sum(cost * d) <= Q,\n",
    "            utils >= t  # t is the minimum utility\n",
    "        ]\n",
    "    elif alpha == 1:\n",
    "        # Nash welfare (alpha = 1)\n",
    "        objective = cp.Maximize(cp.sum(cp.log(utils)))\n",
    "        constraints = [\n",
    "            d >= 0,\n",
    "            # d <= 1,\n",
    "            cp.sum(cost * d) <= Q\n",
    "        ]\n",
    "    elif alpha == 0:\n",
    "        # Utilitarian welfare (alpha = 0)\n",
    "        objective = cp.Maximize(cp.sum(utils))\n",
    "        constraints = [\n",
    "            d >= 0,\n",
    "            # d <= 1,\n",
    "            cp.sum(cost * d) <= Q\n",
    "        ]\n",
    "    else:\n",
    "        # General alpha-fairness\n",
    "        objective = cp.Maximize(cp.sum(utils**(1-alpha))/(1-alpha) if alpha != 0 \n",
    "                              else cp.sum(utils))\n",
    "        constraints = [\n",
    "            d >= 0,\n",
    "            # d <= 1,\n",
    "            cp.sum(cost * d) <= Q\n",
    "        ]\n",
    "    \n",
    "    # Solve the problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve(solver=cp.MOSEK, verbose=False, warm_start=True, mosek_params={'MSK_IPAR_LOG': 1})\n",
    "    \n",
    "    if problem.status != 'optimal':\n",
    "        print(f\"Warning: Problem status is {problem.status}\")\n",
    "    \n",
    "    optimal_decision = d.value\n",
    "    optimal_value = AlphaFairness(optimal_decision * gainF * risk, alpha)\n",
    "    \n",
    "    return optimal_decision, optimal_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_sol,_ = solve_optimization(gainF, predicted_risk, cost, alpha='inf', Q=Q)\n",
    "# pred_obj = np.sum((risk * gainF * pred_sol)**(1-alpha)/(1-alpha))\n",
    "# true_obj = np.sum((optimal_decision * gainF * risk)**(1-alpha)/(1-alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoStagePTO(model, feats, gainF, risk, cost, Q, alphas=[0.5]):\n",
    "    \"\"\"\n",
    "    Perform a two-stage optimization analysis with predictions and calculate normalized regrets.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): A regression neural network for risk prediction.\n",
    "        feats (np.ndarray): Feature array for predictions.\n",
    "        gainF (np.ndarray): Gain factors.\n",
    "        risk (np.ndarray): True risk values.\n",
    "        cost (np.ndarray): Cost constraints.\n",
    "        Q (float): Budget constraint.\n",
    "        alphas (list): List of alpha values for fairness.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A table of prediction risk means, true risk mean, objectives, and normalized regrets.\n",
    "    \"\"\"\n",
    "\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    feats_scaled = scaler.fit_transform(feats)\n",
    "\n",
    "    # Predict risks\n",
    "    model.eval()\n",
    "    pred_risk = model(torch.FloatTensor(feats_scaled)).detach().numpy().flatten()\n",
    "\n",
    "    # Initialize result storage\n",
    "    results = []\n",
    "\n",
    "    # Iterate over alphas\n",
    "    for alpha in alphas:\n",
    "        # Solve optimization problems\n",
    "        true_sol, _ = solve_optimization(gainF, risk, cost, alpha, Q)\n",
    "        pred_sol, _ = solve_optimization(gainF, pred_risk, cost, alpha, Q)\n",
    "\n",
    "        # Calculate true and predicted utilities\n",
    "        true_utility = (risk + 0.001) * gainF * true_sol\n",
    "        pred_utility = (pred_risk + 0.001) * gainF * pred_sol\n",
    "        pred_utility_truerisk = (risk + 0.001) * gainF * pred_sol\n",
    "\n",
    "        # Calculate objectives\n",
    "        true_obj = AlphaFairness(true_utility, alpha)\n",
    "        pred_obj = AlphaFairness(pred_utility, alpha)\n",
    "        pred_obj_truerisk = AlphaFairness(pred_utility_truerisk, alpha)\n",
    "\n",
    "        # Calculate regret and normalized regret\n",
    "        # regret = true_obj - pred_obj\n",
    "        regret = true_obj - pred_obj_truerisk\n",
    "        normalized_regret = regret / (abs(true_obj) + 1e-7)        \n",
    "\n",
    "        # Collect results for this alpha\n",
    "        results.append({\n",
    "            'Alpha': alpha,\n",
    "            'Predicted Risk Mean': pred_risk.mean(),\n",
    "            'True Risk Mean': risk.mean(),\n",
    "            'True Objective': true_obj,\n",
    "            'Predicted Objective': pred_obj,\n",
    "            'Regret': f\"{regret:.2f}\",\n",
    "            'Normalized Regret': f\"{normalized_regret:.2f}\"\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame for results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(results_df)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = df.sample(n=40000, random_state=42)\n",
    "feats_sample = data_sample[get_all_features(data_sample)].values\n",
    "risk_sample = data_sample['risk_score_t'].values\n",
    "gainF_sample = data_sample['g_continuous'].values\n",
    "decision_sample = data_sample['propensity_score'].values\n",
    "cost_sample = np.ones(risk_sample.shape)\n",
    "race_sample = data_sample['race'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Predicted Risk Mean</th>\n",
       "      <th>True Risk Mean</th>\n",
       "      <th>True Objective</th>\n",
       "      <th>Predicted Objective</th>\n",
       "      <th>Regret</th>\n",
       "      <th>Normalized Regret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>284164.896752</td>\n",
       "      <td>7.960235e+06</td>\n",
       "      <td>104721.50</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>73629.284021</td>\n",
       "      <td>3.811415e+04</td>\n",
       "      <td>23887.93</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>361873.257701</td>\n",
       "      <td>3.060051e+05</td>\n",
       "      <td>658.10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>-44900.932086</td>\n",
       "      <td>-1.127005e+05</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>-834952.038551</td>\n",
       "      <td>-1.546416e+06</td>\n",
       "      <td>2847299.59</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>inf</td>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>3.833028e-03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alpha  Predicted Risk Mean  True Risk Mean  True Objective  \\\n",
       "0    0.0             2.703654        4.387568   284164.896752   \n",
       "1    0.5             2.703654        4.387568    73629.284021   \n",
       "2    0.9             2.703654        4.387568   361873.257701   \n",
       "3    1.0             2.703654        4.387568   -44900.932086   \n",
       "4    2.0             2.703654        4.387568  -834952.038551   \n",
       "5    inf             2.703654        4.387568        0.000627   \n",
       "\n",
       "   Predicted Objective      Regret  Normalized Regret  \n",
       "0         7.960235e+06   104721.50               0.37  \n",
       "1         3.811415e+04    23887.93               0.32  \n",
       "2         3.060051e+05      658.10               0.00  \n",
       "3        -1.127005e+05       -0.00              -0.00  \n",
       "4        -1.546416e+06  2847299.59               3.41  \n",
       "5         3.833028e-03        0.00               1.00  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results.to_csv('data/results.csv', index=False)\n",
    "# results = twoStagePTO(model, feats_sample, gainF_sample, risk_sample, cost_sample, Q, alphas=[0,.5,.9,1,2,'inf'])\n",
    "results = pd.read_csv('data/results.csv')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoStagePTO_with_bias_analysis(model, fair_model, feats, gainF, risk, cost, race, Q=1000, alphas=[0.5],):\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    feats_scaled = scaler.fit_transform(feats)\n",
    "\n",
    "    # Predict risks\n",
    "    model.eval()\n",
    "    pred_risk = model(torch.FloatTensor(feats_scaled)).detach().numpy().flatten()\n",
    "    fair_pred_risk = fair_model(torch.FloatTensor(feats_scaled)).detach().numpy().flatten()\n",
    "\n",
    "    # Initialize result storage\n",
    "    results = []\n",
    "    bias_analysis = []\n",
    "    fair_pto_results = []\n",
    "    fair_pto_analysis = []\n",
    "\n",
    "    # Iterate over alphas\n",
    "    for alpha in alphas:\n",
    "        # Solve optimization problems\n",
    "        true_sol, _ = solve_optimization(gainF, risk, cost, alpha, Q)\n",
    "        pred_sol, _ = solve_optimization(gainF, pred_risk, cost, alpha, Q)\n",
    "        fair_pred_sol, _ = solve_optimization(gainF, fair_pred_risk, cost, alpha, Q)\n",
    "\n",
    "        # Calculate true and predicted utilities\n",
    "        true_utility = (risk + 0.001) * gainF * true_sol\n",
    "        pred_utility = (pred_risk + 0.001) * gainF * pred_sol\n",
    "        pred_utility_truerisk = (risk + 0.001) * gainF * pred_sol\n",
    "        fair_pred_utility_truerisk = (risk + 0.001) * gainF * fair_pred_sol\n",
    "\n",
    "        # Calculate objectives\n",
    "        true_obj = AlphaFairness(true_utility, alpha)\n",
    "        pred_obj = AlphaFairness(pred_utility, alpha)\n",
    "        pred_obj_truerisk = AlphaFairness(pred_utility_truerisk, alpha)\n",
    "        fair_pred_obj_truerisk = AlphaFairness(fair_pred_utility_truerisk, alpha)\n",
    "\n",
    "        # Calculate regret and normalized regret\n",
    "        # regret = true_obj - pred_obj\n",
    "        regret = true_obj - pred_obj_truerisk\n",
    "        normalized_regret = regret / (abs(true_obj) + 1e-7)\n",
    "\n",
    "        fair_regret = true_obj - fair_pred_obj_truerisk\n",
    "        fair_normalized_regret = fair_regret / (abs(true_obj) + 1e-7)\n",
    "\n",
    "        # Collect results for this alpha\n",
    "        results.append({\n",
    "            'Alpha': alpha,\n",
    "            'Predicted Risk Mean': pred_risk.mean(),\n",
    "            'True Risk Mean': risk.mean(),\n",
    "            'True Objective': true_obj,\n",
    "            'Predicted Objective': pred_obj,\n",
    "            'Regret': f\"{regret:.2f}\",\n",
    "            'Normalized Regret': f\"{normalized_regret:.2f}\"\n",
    "        })\n",
    "\n",
    "        # Add racial results\n",
    "        fair_pto_results.append({\n",
    "            'Alpha': alpha,\n",
    "            'Predicted Risk Mean': fair_pred_risk.mean(),\n",
    "            'True Risk Mean': risk.mean(),\n",
    "            'True Objective': true_obj,\n",
    "            'Predicted Objective': fair_pred_obj_truerisk,\n",
    "            'Regret': f\"{fair_regret:.2f}\",\n",
    "            'Normalized Regret': f\"{fair_normalized_regret:.2f}\"\n",
    "        })\n",
    "\n",
    "        # Analyze bias in the optimal solution and utilities by race\n",
    "        for r in [0, 1]:  # 0 = white, 1 = black\n",
    "            mask = race == r\n",
    "            race_stats = {\n",
    "                'Alpha': alpha,\n",
    "                'Race': r,\n",
    "                'True Solution Mean': true_sol[mask].mean(),\n",
    "                'True Solution Std': true_sol[mask].std(),\n",
    "                'Predicted Solution Mean': pred_sol[mask].mean(),\n",
    "                'Predicted Solution Std': pred_sol[mask].std(),\n",
    "                'True Utility Mean': true_utility[mask].mean(),\n",
    "                'True Utility Std': true_utility[mask].std(),\n",
    "                'Predicted Utility Mean': pred_utility_truerisk[mask].mean(),\n",
    "                'Predicted Utility Std': pred_utility_truerisk[mask].std()\n",
    "            }\n",
    "            bias_analysis.append(race_stats)\n",
    "        \n",
    "        # Analyze bias in the optimal solution and utilities by race in for fair model\n",
    "        for r in [0, 1]:\n",
    "            mask = race == r\n",
    "            fair_stats = {\n",
    "                'Alpha': alpha,\n",
    "                'Race': r,\n",
    "                'True Solution Mean': true_sol[mask].mean(),\n",
    "                'True Solution Std': true_sol[mask].std(),\n",
    "                'Predicted Solution Mean': fair_pred_sol[mask].mean(),\n",
    "                'Predicted Solution Std': fair_pred_sol[mask].std(),\n",
    "                'True Utility Mean': true_utility[mask].mean(),\n",
    "                'True Utility Std': true_utility[mask].std(),\n",
    "                'Predicted Utility Mean': fair_pred_utility_truerisk[mask].mean(),\n",
    "                'Predicted Utility Std': fair_pred_utility_truerisk[mask].std()\n",
    "            }\n",
    "            fair_pto_analysis.append(fair_stats)\n",
    "\n",
    "\n",
    "    # Create DataFrames for results and bias analysis\n",
    "    results_df = pd.DataFrame(results)\n",
    "    bias_analysis_df = pd.DataFrame(bias_analysis)\n",
    "    bias_analysis_df['Race'] = bias_analysis_df['Race'].replace({0: 'White', 1: 'Black'})\n",
    "\n",
    "    fair_pto_results_df = pd.DataFrame(fair_pto_results)\n",
    "    fair_pto_analysis_df = pd.DataFrame(fair_pto_analysis)\n",
    "    fair_pto_analysis_df['Race'] = fair_pto_analysis_df['Race'].replace({0: 'White', 1: 'Black'})\n",
    "\n",
    "    return results_df, bias_analysis_df, fair_pto_results_df, fair_pto_analysis_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# racial_results, racial_bias_analysis, fair_pto_results, fair_pto_analysis = twoStagePTO_with_bias_analysis(model, fair_model, feats_sample, gainF_sample, risk_sample, cost_sample, race_sample, alphas=[0,.5,.9,1,2,'inf'])\n",
    "\n",
    "# racial_bias_analysis = racial_bias_analysis.round(8)\n",
    "# fair_pto_analysis = fair_pto_analysis.round(8)\n",
    "\n",
    "# racial_bias_analysis.to_csv('data/racial_bias_analysis.csv', index=False)\n",
    "# fair_pto_analysis.to_csv('data/fair_pto_analysis.csv', index=False)\n",
    "# fair_pto_results.to_csv('data/fair_pto_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Risk Mean</th>\n",
       "      <th>True Risk Mean</th>\n",
       "      <th>True Objective</th>\n",
       "      <th>Predicted Objective</th>\n",
       "      <th>Regret</th>\n",
       "      <th>Normalized Regret</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>2.733022</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>284164.896752</td>\n",
       "      <td>1.766419e+05</td>\n",
       "      <td>107522.97</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>2.733022</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>73629.284021</td>\n",
       "      <td>5.448407e+04</td>\n",
       "      <td>19145.22</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>2.733022</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>361873.257701</td>\n",
       "      <td>3.613766e+05</td>\n",
       "      <td>496.65</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2.733022</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>-44900.932086</td>\n",
       "      <td>-4.490093e+04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>2.733022</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>-834952.038551</td>\n",
       "      <td>-3.321640e+06</td>\n",
       "      <td>2486687.55</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inf</th>\n",
       "      <td>2.733022</td>\n",
       "      <td>4.387568</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>2.412388e-06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predicted Risk Mean  True Risk Mean  True Objective  \\\n",
       "Alpha                                                        \n",
       "0.0               2.733022        4.387568   284164.896752   \n",
       "0.5               2.733022        4.387568    73629.284021   \n",
       "0.9               2.733022        4.387568   361873.257701   \n",
       "1.0               2.733022        4.387568   -44900.932086   \n",
       "2.0               2.733022        4.387568  -834952.038551   \n",
       "inf               2.733022        4.387568        0.000627   \n",
       "\n",
       "       Predicted Objective      Regret  Normalized Regret  \n",
       "Alpha                                                      \n",
       "0.0           1.766419e+05   107522.97               0.38  \n",
       "0.5           5.448407e+04    19145.22               0.26  \n",
       "0.9           3.613766e+05      496.65               0.00  \n",
       "1.0          -4.490093e+04        0.00               0.00  \n",
       "2.0          -3.321640e+06  2486687.55               2.98  \n",
       "inf           2.412388e-06        0.00               1.00  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_pto_results = pd.read_csv('data/fair_pto_results.csv')\n",
    "racial_bias_analysis = pd.read_csv('data/racial_bias_analysis.csv')\n",
    "fair_pto_analysis = pd.read_csv('data/fair_pto_analysis.csv')\n",
    "\n",
    "fair_pto_results.groupby('Alpha').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>True Solution Mean</th>\n",
       "      <th>True Solution Std</th>\n",
       "      <th>Predicted Solution Mean</th>\n",
       "      <th>Predicted Solution Std</th>\n",
       "      <th>True Utility Mean</th>\n",
       "      <th>True Utility Std</th>\n",
       "      <th>Predicted Utility Mean</th>\n",
       "      <th>Predicted Utility Std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <th>Race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.028225</td>\n",
       "      <td>5.312689</td>\n",
       "      <td>0.028225</td>\n",
       "      <td>5.312689e+00</td>\n",
       "      <td>8.020686</td>\n",
       "      <td>1509.679826</td>\n",
       "      <td>5.064873</td>\n",
       "      <td>953.327050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.5</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.023181</td>\n",
       "      <td>0.035950</td>\n",
       "      <td>0.028787</td>\n",
       "      <td>1.233266e-01</td>\n",
       "      <td>2.479947</td>\n",
       "      <td>6.371667</td>\n",
       "      <td>1.866960</td>\n",
       "      <td>15.644671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.025235</td>\n",
       "      <td>0.036278</td>\n",
       "      <td>0.024511</td>\n",
       "      <td>1.855345e-01</td>\n",
       "      <td>2.646779</td>\n",
       "      <td>6.408446</td>\n",
       "      <td>1.867408</td>\n",
       "      <td>32.928870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.9</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.024675</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.025626</td>\n",
       "      <td>4.277230e-03</td>\n",
       "      <td>0.945569</td>\n",
       "      <td>1.602100</td>\n",
       "      <td>0.843973</td>\n",
       "      <td>1.361967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.025042</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.024919</td>\n",
       "      <td>4.393810e-03</td>\n",
       "      <td>1.029735</td>\n",
       "      <td>1.615768</td>\n",
       "      <td>0.904438</td>\n",
       "      <td>1.371417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>2.340000e-06</td>\n",
       "      <td>0.785466</td>\n",
       "      <td>1.218131</td>\n",
       "      <td>0.785445</td>\n",
       "      <td>1.218099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>9.700000e-07</td>\n",
       "      <td>0.855046</td>\n",
       "      <td>1.229236</td>\n",
       "      <td>0.855023</td>\n",
       "      <td>1.229204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.026925</td>\n",
       "      <td>0.227790</td>\n",
       "      <td>0.022331</td>\n",
       "      <td>6.234881e-02</td>\n",
       "      <td>0.152662</td>\n",
       "      <td>0.119106</td>\n",
       "      <td>0.492565</td>\n",
       "      <td>0.810503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.215799</td>\n",
       "      <td>0.025344</td>\n",
       "      <td>5.960121e-02</td>\n",
       "      <td>0.162163</td>\n",
       "      <td>0.120497</td>\n",
       "      <td>0.584593</td>\n",
       "      <td>0.858324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">inf</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.027516</td>\n",
       "      <td>0.413693</td>\n",
       "      <td>0.026002</td>\n",
       "      <td>4.189160e-01</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089402</td>\n",
       "      <td>0.791130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.024675</td>\n",
       "      <td>0.391829</td>\n",
       "      <td>0.024871</td>\n",
       "      <td>3.555798e-01</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104034</td>\n",
       "      <td>0.545042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             True Solution Mean  True Solution Std  Predicted Solution Mean  \\\n",
       "Alpha Race                                                                    \n",
       "0.0   Black            0.000000           0.000000                 0.000000   \n",
       "      White            0.028225           5.312689                 0.028225   \n",
       "0.5   Black            0.023181           0.035950                 0.028787   \n",
       "      White            0.025235           0.036278                 0.024511   \n",
       "0.9   Black            0.024675           0.003974                 0.025626   \n",
       "      White            0.025042           0.004007                 0.024919   \n",
       "1.0   Black            0.025000           0.000010                 0.025000   \n",
       "      White            0.025000           0.000010                 0.025000   \n",
       "2.0   Black            0.026925           0.227790                 0.022331   \n",
       "      White            0.024752           0.215799                 0.025344   \n",
       "inf   Black            0.027516           0.413693                 0.026002   \n",
       "      White            0.024675           0.391829                 0.024871   \n",
       "\n",
       "             Predicted Solution Std  True Utility Mean  True Utility Std  \\\n",
       "Alpha Race                                                                 \n",
       "0.0   Black            0.000000e+00           0.000000          0.000000   \n",
       "      White            5.312689e+00           8.020686       1509.679826   \n",
       "0.5   Black            1.233266e-01           2.479947          6.371667   \n",
       "      White            1.855345e-01           2.646779          6.408446   \n",
       "0.9   Black            4.277230e-03           0.945569          1.602100   \n",
       "      White            4.393810e-03           1.029735          1.615768   \n",
       "1.0   Black            2.340000e-06           0.785466          1.218131   \n",
       "      White            9.700000e-07           0.855046          1.229236   \n",
       "2.0   Black            6.234881e-02           0.152662          0.119106   \n",
       "      White            5.960121e-02           0.162163          0.120497   \n",
       "inf   Black            4.189160e-01           0.000627          0.000000   \n",
       "      White            3.555798e-01           0.000627          0.000000   \n",
       "\n",
       "             Predicted Utility Mean  Predicted Utility Std  \n",
       "Alpha Race                                                  \n",
       "0.0   Black                0.000000               0.000000  \n",
       "      White                5.064873             953.327050  \n",
       "0.5   Black                1.866960              15.644671  \n",
       "      White                1.867408              32.928870  \n",
       "0.9   Black                0.843973               1.361967  \n",
       "      White                0.904438               1.371417  \n",
       "1.0   Black                0.785445               1.218099  \n",
       "      White                0.855023               1.229204  \n",
       "2.0   Black                0.492565               0.810503  \n",
       "      White                0.584593               0.858324  \n",
       "inf   Black                0.089402               0.791130  \n",
       "      White                0.104034               0.545042  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['risk_score_t'].groupby(df['race']).mean()\n",
    "df['g_continuous'].groupby(df['race']).mean()\n",
    "df.race.value_counts()\n",
    "df['risk_score_t'].groupby(df['race']).mean() * df['g_continuous'].groupby(df['race']).mean()\n",
    "fair_pto_analysis.groupby(['Alpha', 'Race']).mean()\n",
    "racial_bias_analysis.groupby(['Alpha', 'Race']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve in Closed Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_d_star_closed_form(c, r, g, Q, alpha):\n",
    "    \"\"\"\n",
    "    Compute the optimal decision variables d* using the closed-form solution,\n",
    "    handling special cases for alpha = 0, 1, and 'inf'.\n",
    "    \n",
    "    Parameters:\n",
    "    - c (np.ndarray): Array of costs (c_i), shape (n,)\n",
    "    - r (np.ndarray): Array of risks (r_i), shape (n,)\n",
    "    - g (np.ndarray): Array of gain factors (g_i), shape (n,)\n",
    "    - Q (float): Total budget constraint\n",
    "    - alpha (float or str): Fairness parameter. Use 'inf' for alpha = infinity.\n",
    "    \n",
    "    Returns:\n",
    "    - d_star_closed (np.ndarray): Optimal decision variables (d_i*), shape (n,)\n",
    "    \n",
    "    Raises:\n",
    "    - ValueError: If any of the inputs are invalid (e.g., non-positive costs, risks, gains, or budget).\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if not isinstance(c, np.ndarray) or not isinstance(r, np.ndarray) or not isinstance(g, np.ndarray):\n",
    "        raise TypeError(\"c, r, and g must be numpy arrays.\")\n",
    "    if c.shape != r.shape or c.shape != g.shape:\n",
    "        raise ValueError(\"c, r, and g must have the same shape.\")\n",
    "    if np.any(c < 0):\n",
    "        raise ValueError(\"All cost values must be positive.\")\n",
    "    if np.any(r < 0):\n",
    "        raise ValueError(\"All risk values must be positive.\")\n",
    "    if np.any(g < 0):\n",
    "        raise ValueError(\"All gain factors must be positive.\")\n",
    "    if Q <= 0:\n",
    "        raise ValueError(\"Total budget Q must be positive.\")\n",
    "    \n",
    "    n = len(c)\n",
    "    \n",
    "    # Handle special cases based on alpha\n",
    "    if alpha == 0:\n",
    "        # Utilitarian maximization: maximize sum(r_i * g_i * d_i)\n",
    "        # Optimal solution: Allocate all budget to the decision variable with the highest (r_i * g_i / c_i)\n",
    "        ratios = (r * g) / c\n",
    "        sorted_indices = np.argsort(-ratios)  # Descending order\n",
    "        d_star_closed = np.zeros(n)\n",
    "        remaining_Q = Q\n",
    "        \n",
    "        for idx in sorted_indices:\n",
    "            if remaining_Q <= 0:\n",
    "                break\n",
    "            # Since there are no upper bounds on d_i, allocate as much as possible\n",
    "            # Here, assuming no upper limit, allocate all remaining budget\n",
    "            d_star_closed[idx] = remaining_Q / c[idx]\n",
    "            remaining_Q = 0  # Budget exhausted\n",
    "        \n",
    "        # If any residual budget remains due to numerical issues, distribute proportionally\n",
    "        if remaining_Q > 1e-6:\n",
    "            allocation_ratio = (r * g) / c\n",
    "            sum_ratio = np.sum(allocation_ratio)\n",
    "            if sum_ratio > 0:\n",
    "                d_star_closed += (allocation_ratio / sum_ratio) * remaining_Q\n",
    "        \n",
    "    elif alpha == 1:\n",
    "        # Nash Welfare: maximize sum(log(r_i * g_i * d_i))\n",
    "        # Solution: d_i* = Q / (n * c_i)\n",
    "        if n == 0:\n",
    "            raise ValueError(\"No decision variables to allocate.\")\n",
    "        d_star_closed = Q / (n * c)\n",
    "    \n",
    "    elif alpha == 'inf':\n",
    "        # Maximin Fairness: maximize min(r_i * g_i * d_i)\n",
    "        # Solution: Allocate d_i* proportional to 1 / (r_i * g_i)\n",
    "        allocation_ratio = 1 / (r * g)\n",
    "        sum_ratio = np.sum(allocation_ratio)\n",
    "        if sum_ratio == 0:\n",
    "            raise ValueError(\"Sum of 1 / (r * g) is zero, cannot allocate budget.\")\n",
    "        d_star_closed = (allocation_ratio / sum_ratio) * Q\n",
    "    \n",
    "    else:\n",
    "        # General alpha-fairness for alpha > 1\n",
    "        if alpha < 0:\n",
    "            raise ValueError(\"Alpha must be non-negative.\")\n",
    "        \n",
    "        # Compute log(numerator) to prevent numerical underflow/overflow\n",
    "        log_numerator = (-1 / alpha) * np.log(c) + (-1 + 1 / alpha) * np.log(r * g)\n",
    "        \n",
    "        # Shift log_numerator for numerical stability\n",
    "        max_log = np.max(log_numerator)\n",
    "        log_numerator_shifted = log_numerator - max_log\n",
    "        \n",
    "        # Compute numerator in log-space\n",
    "        numerator = np.exp(log_numerator_shifted)\n",
    "        \n",
    "        # Compute denominator using log-sum-exp for numerical stability\n",
    "        sum_numerator = np.sum(numerator)\n",
    "        if sum_numerator == 0:\n",
    "            raise ValueError(\"Sum of numerators is zero, cannot allocate budget.\")\n",
    "        \n",
    "        # Normalize to get allocation ratios and scale by Q\n",
    "        d_star_closed = (numerator / sum_numerator) * Q\n",
    "    \n",
    "    return d_star_closed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def analyze_race_stats(alpha, race, true_sol, pred_sol, true_utility, pred_utility, race_labels={0: 'White', 1: 'Black'}):\n",
    "    \"\"\"\n",
    "    Analyze and compute statistics based on race.\n",
    "\n",
    "    Parameters:\n",
    "    - alpha (float): Fairness parameter\n",
    "    - race (np.ndarray): Array indicating race (e.g., 0 for White, 1 for Black)\n",
    "    - true_sol (np.ndarray): True optimal solutions\n",
    "    - pred_sol (np.ndarray): Predicted optimal solutions\n",
    "    - true_utility (np.ndarray): True utilities\n",
    "    - pred_utility (np.ndarray): Predicted utilities\n",
    "    - race_labels (dict): Mapping from race codes to labels\n",
    "\n",
    "    Returns:\n",
    "    - stats (list of dict): List containing statistics per race\n",
    "    \"\"\"\n",
    "    stats = []\n",
    "    for r_code, r_label in race_labels.items():\n",
    "        mask = race == r_code\n",
    "        if np.sum(mask) == 0:\n",
    "            continue  # Skip if no instances of this race\n",
    "        race_stats = {\n",
    "            'Alpha': alpha,\n",
    "            'Race': r_label,\n",
    "            'True Solution Mean': np.mean(true_sol[mask]),\n",
    "            'True Solution Std': np.std(true_sol[mask]),\n",
    "            'Predicted Solution Mean': np.mean(pred_sol[mask]),\n",
    "            'Predicted Solution Std': np.std(pred_sol[mask]),\n",
    "            'True Utility Mean': np.mean(true_utility[mask]),\n",
    "            'True Utility Std': np.std(true_utility[mask]),\n",
    "            'Predicted Utility Mean': np.mean(pred_utility[mask]),\n",
    "            'Predicted Utility Std': np.std(pred_utility[mask])\n",
    "        }\n",
    "        stats.append(race_stats)\n",
    "    return stats\n",
    "\n",
    "def twoStagePTO_with_bias_analysis(\n",
    "    model, fair_model, feats, gainF, risk, cost, race, \n",
    "    Q=1000, alphas=[0.5]\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform two-stage PTO with bias analysis by computing both solver-based and closed-form solutions.\n",
    "\n",
    "    Parameters:\n",
    "    - model: PyTorch model for risk prediction\n",
    "    - fair_model: PyTorch model for fair risk prediction\n",
    "    - feats (np.ndarray): Feature matrix, shape (n_samples, n_features)\n",
    "    - gainF (np.ndarray): Gain factors, shape (n_samples,)\n",
    "    - risk (np.ndarray): True risks, shape (n_samples,)\n",
    "    - cost (np.ndarray): Costs, shape (n_samples,)\n",
    "    - race (np.ndarray): Race indicators (e.g., 0 for White, 1 for Black), shape (n_samples,)\n",
    "    - Q (float): Total budget constraint\n",
    "    - alphas (list of float or str): List of alpha fairness parameters\n",
    "\n",
    "    Returns:\n",
    "    - results_df (pd.DataFrame): Aggregated results comparing solver and closed-form\n",
    "    - bias_analysis_df (pd.DataFrame): Bias analysis per race for both methods\n",
    "    - solutions (dict): Contains optimal solutions from solver and closed-form\n",
    "    \"\"\"\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    feats_scaled = scaler.fit_transform(feats)\n",
    "\n",
    "    # Predict risks using the trained models\n",
    "    model.eval()\n",
    "    fair_model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_risk = model(torch.FloatTensor(feats_scaled)).numpy().flatten()\n",
    "        fair_pred_risk = fair_model(torch.FloatTensor(feats_scaled)).numpy().flatten()\n",
    "\n",
    "        pred_risk = pred_risk.clip(min=0.001)  # Ensure no zero values\n",
    "        fair_pred_risk = fair_pred_risk.clip(min=0.001)  # Ensure no zero values\n",
    "\n",
    "    risk = risk.clip(min=0.001)  # Ensure no zero values\n",
    "\n",
    "    # Initialize result storage\n",
    "    results = []\n",
    "    bias_analysis = []\n",
    "    solutions = {\n",
    "        'solver': {},\n",
    "        'closed_form': {}\n",
    "    }\n",
    "\n",
    "    # Iterate over alphas\n",
    "    for alpha in alphas:\n",
    "        # Solver-based solutions\n",
    "        true_sol_solver, true_obj_solver = solve_optimization(gainF, risk, cost, alpha, Q)\n",
    "        pred_sol_solver, pred_obj_solver = solve_optimization(gainF, pred_risk, cost, alpha, Q)\n",
    "        fair_pred_sol_solver, fair_pred_obj_solver = solve_optimization(gainF, fair_pred_risk, cost, alpha, Q)\n",
    "\n",
    "        # Closed-form solutions\n",
    "        try:\n",
    "            true_sol_cf = compute_d_star_closed_form(cost, risk, gainF, Q, alpha)\n",
    "            pred_sol_cf = compute_d_star_closed_form(cost, pred_risk, gainF, Q, alpha)\n",
    "            fair_pred_sol_cf = compute_d_star_closed_form(cost, fair_pred_risk, gainF, Q, alpha)\n",
    "        except ValueError as e:\n",
    "            print(f\"Closed-form computation skipped for alpha={alpha}: {e}\")\n",
    "            true_sol_cf = pred_sol_cf = fair_pred_sol_cf = np.zeros_like(risk)\n",
    "\n",
    "        # Store solutions\n",
    "        solutions['solver'][alpha] = {\n",
    "            'true_sol': true_sol_solver,\n",
    "            'pred_sol': pred_sol_solver,\n",
    "            'fair_pred_sol': fair_pred_sol_solver\n",
    "        }\n",
    "        solutions['closed_form'][alpha] = {\n",
    "            'true_sol': true_sol_cf,\n",
    "            'pred_sol': pred_sol_cf,\n",
    "            'fair_pred_sol': fair_pred_sol_cf\n",
    "        }\n",
    "\n",
    "        # Compute utilities\n",
    "        utilities_solver = gainF * risk * true_sol_solver\n",
    "        pred_util_solver = gainF * risk * pred_sol_solver\n",
    "        fair_pred_util_solver = gainF * risk * fair_pred_sol_solver\n",
    "\n",
    "        utilities_cf = gainF * risk * true_sol_cf\n",
    "        pred_util_cf = gainF * risk * pred_sol_cf\n",
    "        fair_pred_util_cf = gainF * risk * fair_pred_sol_cf\n",
    "\n",
    "        # Compute objectives using helper function\n",
    "        true_obj_cf = AlphaFairness(utilities_cf, alpha)\n",
    "        pred_obj_cf = AlphaFairness(pred_util_cf, alpha)\n",
    "        fair_pred_obj_cf = AlphaFairness(fair_pred_util_cf, alpha)\n",
    "\n",
    "        # Compute regrets and normalized regrets\n",
    "        # Solver-based\n",
    "        regret_solver = true_obj_solver - AlphaFairness(gainF * risk * pred_sol_solver, alpha)\n",
    "        normalized_regret_solver = regret_solver / (abs(true_obj_solver) + 1e-7)\n",
    "\n",
    "        fair_regret_solver = true_obj_solver - AlphaFairness(gainF * risk * fair_pred_sol_solver, alpha)\n",
    "        fair_normalized_regret_solver = fair_regret_solver / (abs(true_obj_solver) + 1e-7)\n",
    "\n",
    "        # Closed-form\n",
    "        regret_cf = true_obj_cf - pred_obj_cf\n",
    "        normalized_regret_cf = regret_cf / (abs(true_obj_cf) + 1e-7)\n",
    "\n",
    "        fair_regret_cf = true_obj_cf - fair_pred_obj_cf\n",
    "        fair_normalized_regret_cf = fair_regret_cf / (abs(true_obj_cf) + 1e-7)\n",
    "\n",
    "        # Append solver results\n",
    "        results.append({\n",
    "            'Alpha': alpha,\n",
    "            'Method': 'Solver',\n",
    "            'Predicted Risk Mean': pred_risk.mean(),\n",
    "            'True Risk Mean': risk.mean(),\n",
    "            'True Objective': true_obj_solver,\n",
    "            'Predicted Objective': AlphaFairness(gainF * risk * pred_sol_solver, alpha),\n",
    "            'Regret': regret_solver,\n",
    "            'Normalized Regret': normalized_regret_solver\n",
    "        })\n",
    "\n",
    "        # Append closed-form results\n",
    "        results.append({\n",
    "            'Alpha': alpha,\n",
    "            'Method': 'Closed-Form',\n",
    "            'Predicted Risk Mean': pred_risk.mean(),\n",
    "            'True Risk Mean': risk.mean(),\n",
    "            'True Objective': true_obj_cf,\n",
    "            'Predicted Objective': pred_obj_cf,\n",
    "            'Regret': regret_cf,\n",
    "            'Normalized Regret': normalized_regret_cf\n",
    "        })\n",
    "\n",
    "        # Append fair solver results\n",
    "        results.append({\n",
    "            'Alpha': alpha,\n",
    "            'Method': 'Solver (Fair)',\n",
    "            'Predicted Risk Mean': fair_pred_risk.mean(),\n",
    "            'True Risk Mean': risk.mean(),\n",
    "            'True Objective': true_obj_solver,\n",
    "            'Predicted Objective': AlphaFairness(gainF * risk * fair_pred_sol_solver, alpha),\n",
    "            'Regret': fair_regret_solver,\n",
    "            'Normalized Regret': fair_normalized_regret_solver\n",
    "        })\n",
    "\n",
    "        # Append fair closed-form results\n",
    "        results.append({\n",
    "            'Alpha': alpha,\n",
    "            'Method': 'Closed-Form (Fair)',\n",
    "            'Predicted Risk Mean': fair_pred_risk.mean(),\n",
    "            'True Risk Mean': risk.mean(),\n",
    "            'True Objective': true_obj_cf,\n",
    "            'Predicted Objective': fair_pred_obj_cf,\n",
    "            'Regret': fair_regret_cf,\n",
    "            'Normalized Regret': fair_normalized_regret_cf\n",
    "        })\n",
    "\n",
    "        # Bias analysis for solver\n",
    "        bias_solver = analyze_race_stats(\n",
    "            alpha, race, true_sol_solver, pred_sol_solver, \n",
    "            utilities_solver, pred_util_solver\n",
    "        )\n",
    "        bias_analysis.extend([{'Method': 'Solver'} | stat for stat in bias_solver])\n",
    "\n",
    "        # Bias analysis for closed-form\n",
    "        bias_cf = analyze_race_stats(\n",
    "            alpha, race, true_sol_cf, pred_sol_cf, \n",
    "            utilities_cf, pred_util_cf\n",
    "        )\n",
    "        bias_analysis.extend([{'Method': 'Closed-Form'} | stat for stat in bias_cf])\n",
    "\n",
    "        # Bias analysis for fair solver\n",
    "        bias_fair_solver = analyze_race_stats(\n",
    "            alpha, race, true_sol_solver, fair_pred_sol_solver, \n",
    "            utilities_solver, fair_pred_util_solver\n",
    "        )\n",
    "        bias_analysis.extend([{'Method': 'Solver (Fair)'} | stat for stat in bias_fair_solver])\n",
    "\n",
    "        # Bias analysis for fair closed-form\n",
    "        bias_fair_cf = analyze_race_stats(\n",
    "            alpha, race, true_sol_cf, fair_pred_sol_cf, \n",
    "            utilities_cf, fair_pred_util_cf\n",
    "        )\n",
    "        bias_analysis.extend([{'Method': 'Closed-Form (Fair)'} | stat for stat in bias_fair_cf])\n",
    "\n",
    "    # Create DataFrames for results and bias analysis\n",
    "    results_df = pd.DataFrame(results)\n",
    "    bias_analysis_df = pd.DataFrame(bias_analysis)\n",
    "    bias_analysis_df['Race'] = bias_analysis_df['Race'].astype(str)\n",
    "\n",
    "    return results_df, bias_analysis_df, solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Results:\n",
      "   Alpha              Method  Predicted Risk Mean  True Risk Mean  \\\n",
      "0    0.0              Solver             2.703654        4.387572   \n",
      "1    0.0         Closed-Form             2.703654        4.387572   \n",
      "2    0.0       Solver (Fair)             2.149763        4.387572   \n",
      "3    0.0  Closed-Form (Fair)             2.149763        4.387572   \n",
      "4    0.5              Solver             2.703654        4.387572   \n",
      "5    0.5         Closed-Form             2.703654        4.387572   \n",
      "6    0.5       Solver (Fair)             2.149763        4.387572   \n",
      "7    0.5  Closed-Form (Fair)             2.149763        4.387572   \n",
      "8    1.0              Solver             2.703654        4.387572   \n",
      "9    1.0         Closed-Form             2.703654        4.387572   \n",
      "10   1.0       Solver (Fair)             2.149763        4.387572   \n",
      "11   1.0  Closed-Form (Fair)             2.149763        4.387572   \n",
      "12   2.0              Solver             2.703654        4.387572   \n",
      "13   2.0         Closed-Form             2.703654        4.387572   \n",
      "14   2.0       Solver (Fair)             2.149763        4.387572   \n",
      "15   2.0  Closed-Form (Fair)             2.149763        4.387572   \n",
      "16   inf              Solver             2.703654        4.387572   \n",
      "17   inf         Closed-Form             2.703654        4.387572   \n",
      "18   inf       Solver (Fair)             2.149763        4.387572   \n",
      "19   inf  Closed-Form (Fair)             2.149763        4.387572   \n",
      "\n",
      "    True Objective  Predicted Objective        Regret  Normalized Regret  \n",
      "0    284164.896752         1.694669e+05  1.146980e+05           0.403632  \n",
      "1    283123.180400         1.694669e+05  1.136563e+05           0.401438  \n",
      "2    284164.896752         1.668212e+05  1.173437e+05           0.412942  \n",
      "3    283123.180400         1.668212e+05  1.163020e+05           0.410782  \n",
      "4     73629.284004         4.967441e+04  2.395488e+04           0.325344  \n",
      "5     73560.208282         4.922819e+04  2.433202e+04           0.330777  \n",
      "6     73629.284004         4.550411e+04  2.812517e+04           0.381984  \n",
      "7     73560.208282         4.501799e+04  2.854222e+04           0.388012  \n",
      "8    -44790.736205        -4.492860e+04  1.378681e+02           0.003078  \n",
      "9    -44928.603979        -4.492860e+04  0.000000e+00           0.000000  \n",
      "10   -44790.736205        -4.492860e+04  1.378679e+02           0.003078  \n",
      "11   -44928.603979        -4.492860e+04  0.000000e+00           0.000000  \n",
      "12  -587506.397186        -3.672405e+06  3.084899e+06           5.250835  \n",
      "13  -835094.022604        -3.661979e+06  2.826885e+06           3.385110  \n",
      "14  -587506.397186        -5.621857e+06  5.034351e+06           8.569015  \n",
      "15  -835094.022604        -5.609882e+06  4.774788e+06           5.717665  \n",
      "16        0.001249         2.540136e-06  1.246820e-03           0.997887  \n",
      "17        0.000627         2.124773e-06  6.246730e-04           0.996451  \n",
      "18        0.001249         9.241947e-07  1.248436e-03           0.999180  \n",
      "19        0.000627         7.966767e-07  6.260011e-04           0.998570  \n",
      "\n",
      "Bias Analysis:\n",
      "                Method Alpha   Race  True Solution Mean  True Solution Std  \\\n",
      "0               Solver   0.0  White            0.028225       5.312689e+00   \n",
      "1               Solver   0.0  Black            0.000000       0.000000e+00   \n",
      "2          Closed-Form   0.0  White            0.028225       5.312689e+00   \n",
      "3          Closed-Form   0.0  Black            0.000000       0.000000e+00   \n",
      "4        Solver (Fair)   0.0  White            0.028225       5.312689e+00   \n",
      "5        Solver (Fair)   0.0  Black            0.000000       0.000000e+00   \n",
      "6   Closed-Form (Fair)   0.0  White            0.028225       5.312689e+00   \n",
      "7   Closed-Form (Fair)   0.0  Black            0.000000       0.000000e+00   \n",
      "8               Solver   0.5  White            0.025235       3.627803e-02   \n",
      "9               Solver   0.5  Black            0.023181       3.595028e-02   \n",
      "10         Closed-Form   0.5  White            0.025235       3.623801e-02   \n",
      "11         Closed-Form   0.5  Black            0.023176       3.589608e-02   \n",
      "12       Solver (Fair)   0.5  White            0.025235       3.627803e-02   \n",
      "13       Solver (Fair)   0.5  Black            0.023181       3.595028e-02   \n",
      "14  Closed-Form (Fair)   0.5  White            0.025235       3.623801e-02   \n",
      "15  Closed-Form (Fair)   0.5  Black            0.023176       3.589608e-02   \n",
      "16              Solver   1.0  White            0.025000       2.317838e-05   \n",
      "17              Solver   1.0  Black            0.025000       2.447160e-05   \n",
      "18         Closed-Form   1.0  White            0.025000       3.469447e-18   \n",
      "19         Closed-Form   1.0  Black            0.025000       3.469447e-18   \n",
      "20       Solver (Fair)   1.0  White            0.025000       2.317838e-05   \n",
      "21       Solver (Fair)   1.0  Black            0.025000       2.447160e-05   \n",
      "22  Closed-Form (Fair)   1.0  White            0.025000       3.469447e-18   \n",
      "23  Closed-Form (Fair)   1.0  Black            0.025000       3.469447e-18   \n",
      "24              Solver   2.0  White            0.024766       1.816356e-01   \n",
      "25              Solver   2.0  Black            0.026810       1.917051e-01   \n",
      "26         Closed-Form   2.0  White            0.024752       2.157050e-01   \n",
      "27         Closed-Form   2.0  Black            0.026924       2.276908e-01   \n",
      "28       Solver (Fair)   2.0  White            0.024766       1.816356e-01   \n",
      "29       Solver (Fair)   2.0  Black            0.026810       1.917051e-01   \n",
      "30  Closed-Form (Fair)   2.0  White            0.024752       2.157050e-01   \n",
      "31  Closed-Form (Fair)   2.0  Black            0.026924       2.276908e-01   \n",
      "32              Solver   inf  White            0.024676       3.904994e-01   \n",
      "33              Solver   inf  Black            0.027514       4.122895e-01   \n",
      "34         Closed-Form   inf  White            0.024675       3.918284e-01   \n",
      "35         Closed-Form   inf  Black            0.027516       4.136931e-01   \n",
      "36       Solver (Fair)   inf  White            0.024676       3.904994e-01   \n",
      "37       Solver (Fair)   inf  Black            0.027514       4.122895e-01   \n",
      "38  Closed-Form (Fair)   inf  White            0.024675       3.918284e-01   \n",
      "39  Closed-Form (Fair)   inf  Black            0.027516       4.136931e-01   \n",
      "\n",
      "    Predicted Solution Mean  Predicted Solution Std  True Utility Mean  \\\n",
      "0                  0.028225            5.312689e+00           7.991283   \n",
      "1                  0.000000            0.000000e+00           0.000000   \n",
      "2                  0.028225            5.312689e+00           7.991283   \n",
      "3                  0.000000            0.000000e+00           0.000000   \n",
      "4                  0.028225            5.312689e+00           7.991283   \n",
      "5                  0.000000            0.000000e+00           0.000000   \n",
      "6                  0.028225            5.312689e+00           7.991283   \n",
      "7                  0.000000            0.000000e+00           0.000000   \n",
      "8                  0.024511            1.855352e-01           2.639826   \n",
      "9                  0.028787            1.233266e-01           2.472418   \n",
      "10                 0.024509            1.865006e-01           2.637937   \n",
      "11                 0.028805            1.239952e-01           2.469678   \n",
      "12                 0.024240            1.812565e-01           2.639826   \n",
      "13                 0.030894            2.180181e-01           2.472418   \n",
      "14                 0.024236            1.820159e-01           2.637937   \n",
      "15                 0.030920            2.190925e-01           2.469678   \n",
      "16                 0.025000            2.601972e-06           0.853495   \n",
      "17                 0.025000            4.297877e-06           0.783830   \n",
      "18                 0.025000            3.469447e-18           0.853446   \n",
      "19                 0.025000            3.469447e-18           0.783785   \n",
      "20                 0.025000            1.507733e-06           0.853495   \n",
      "21                 0.025000            1.311340e-06           0.783830   \n",
      "22                 0.025000            3.469447e-18           0.853446   \n",
      "23                 0.025000            3.469447e-18           0.783785   \n",
      "24                 0.025358            5.875849e-02           0.193273   \n",
      "25                 0.022223            5.924549e-02           0.181926   \n",
      "26                 0.025344            6.302333e-02           0.162248   \n",
      "27                 0.022330            6.597847e-02           0.152731   \n",
      "28                 0.025556            4.746211e-02           0.193273   \n",
      "29                 0.020690            4.383112e-02           0.181926   \n",
      "30                 0.025552            5.024200e-02           0.162248   \n",
      "31                 0.020718            4.740978e-02           0.152731   \n",
      "32                 0.025065            3.521821e-01           0.001246   \n",
      "33                 0.024498            3.780143e-01           0.001246   \n",
      "34                 0.024854            3.675680e-01           0.000627   \n",
      "35                 0.026133            4.381526e-01           0.000627   \n",
      "36                 0.025559            2.613243e-01           0.001246   \n",
      "37                 0.020664            2.397964e-01           0.001246   \n",
      "38                 0.025458            2.798081e-01           0.000627   \n",
      "39                 0.021449            2.739474e-01           0.000627   \n",
      "\n",
      "    True Utility Std  Predicted Utility Mean  Predicted Utility Std  \n",
      "0       1.504146e+03                4.783282             900.324922  \n",
      "1       0.000000e+00                0.000000               0.000000  \n",
      "2       1.504146e+03                4.783282             900.324922  \n",
      "3       0.000000e+00                0.000000               0.000000  \n",
      "4       1.504146e+03                4.708605             886.269043  \n",
      "5       0.000000e+00                0.000000               0.000000  \n",
      "6       1.504146e+03                4.708605             886.269043  \n",
      "7       0.000000e+00                0.000000               0.000000  \n",
      "8       6.385989e+00                1.842257              31.240538  \n",
      "9       6.345806e+00                1.855832              15.513150  \n",
      "10      6.376304e+00                1.829556              31.396624  \n",
      "11      6.333008e+00                1.841199              15.576684  \n",
      "12      6.385989e+00                2.117049              30.117205  \n",
      "13      6.345806e+00                2.624886              34.987966  \n",
      "14      6.376304e+00                2.108749              30.237817  \n",
      "15      6.333008e+00                2.617797              35.159269  \n",
      "16      1.225618e+00                0.853440               1.225540  \n",
      "17      1.214053e+00                0.783780               1.213976  \n",
      "18      1.225548e+00                0.853446               1.225548  \n",
      "19      1.213984e+00                0.783785               1.213984  \n",
      "20      1.225618e+00                0.853442               1.225542  \n",
      "21      1.214053e+00                0.783781               1.213979  \n",
      "22      1.225548e+00                0.853446               1.225548  \n",
      "23      1.213984e+00                0.783785               1.213984  \n",
      "24      1.434984e-01                0.585292               0.858060  \n",
      "25      1.417876e-01                0.492787               0.809464  \n",
      "26      1.206424e-01                0.592062               0.891632  \n",
      "27      1.192291e-01                0.499121               0.841030  \n",
      "28      1.434984e-01                0.497358               0.661718  \n",
      "29      1.417876e-01                0.405609               0.619621  \n",
      "30      1.206424e-01                0.505279               0.687355  \n",
      "31      1.192291e-01                0.412568               0.644356  \n",
      "32      3.909350e-05                0.104720               0.339636  \n",
      "33      4.129014e-05                0.084597               0.439139  \n",
      "34      1.974517e-19                0.097671               0.491269  \n",
      "35      6.687356e-20                0.083161               0.692423  \n",
      "36      3.909350e-05                0.126980               0.269268  \n",
      "37      4.129014e-05                0.092586               0.313451  \n",
      "38      1.974517e-19                0.119947               0.358750  \n",
      "39      6.687356e-20                0.090742               0.486367  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Define alpha values, including special cases\n",
    "    alphas = [0.0, 0.5, 1.0, 2.0, 'inf']\n",
    "    # model = RiskPredictor(feats.shape[1])\n",
    "    # model.load_state_dict(torch.load('risk_predictor_model.pth'))\n",
    "\n",
    "    # fair_model = FairRiskPredictor(feats.shape[1])\n",
    "    # fair_model.load_state_dict(torch.load('fair_risk_predictor_model.pth'))\n",
    "    \n",
    "    # Run the analysis\n",
    "    results_df, bias_analysis_df, solutions = twoStagePTO_with_bias_analysis(\n",
    "        model, fair_model, feats_sample, gainF_sample, risk_sample, cost_sample, race_sample, Q=1000, alphas=alphas\n",
    "    )\n",
    "\n",
    "    # Display the aggregated results\n",
    "    print(\"Aggregated Results:\")\n",
    "    print(results_df)\n",
    "\n",
    "    # Display the bias analysis\n",
    "    print(\"\\nBias Analysis:\")\n",
    "    print(bias_analysis_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Predicted Risk Mean</th>\n",
       "      <th>True Risk Mean</th>\n",
       "      <th>True Objective</th>\n",
       "      <th>Predicted Objective</th>\n",
       "      <th>Regret</th>\n",
       "      <th>Normalized Regret</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.0</th>\n",
       "      <th>Closed-Form</th>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>283123.180400</td>\n",
       "      <td>1.694669e+05</td>\n",
       "      <td>1.136563e+05</td>\n",
       "      <td>0.401438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Closed-Form (Fair)</th>\n",
       "      <td>2.149763</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>283123.180400</td>\n",
       "      <td>1.668212e+05</td>\n",
       "      <td>1.163020e+05</td>\n",
       "      <td>0.410782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solver</th>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>284164.896752</td>\n",
       "      <td>1.694669e+05</td>\n",
       "      <td>1.146980e+05</td>\n",
       "      <td>0.403632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solver (Fair)</th>\n",
       "      <td>2.149763</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>284164.896752</td>\n",
       "      <td>1.668212e+05</td>\n",
       "      <td>1.173437e+05</td>\n",
       "      <td>0.412942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.5</th>\n",
       "      <th>Closed-Form</th>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>73560.208282</td>\n",
       "      <td>4.922819e+04</td>\n",
       "      <td>2.433202e+04</td>\n",
       "      <td>0.330777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Closed-Form (Fair)</th>\n",
       "      <td>2.149763</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>73560.208282</td>\n",
       "      <td>4.501799e+04</td>\n",
       "      <td>2.854222e+04</td>\n",
       "      <td>0.388012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solver</th>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>73629.284004</td>\n",
       "      <td>4.967441e+04</td>\n",
       "      <td>2.395488e+04</td>\n",
       "      <td>0.325344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solver (Fair)</th>\n",
       "      <td>2.149763</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>73629.284004</td>\n",
       "      <td>4.550411e+04</td>\n",
       "      <td>2.812517e+04</td>\n",
       "      <td>0.381984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1.0</th>\n",
       "      <th>Closed-Form</th>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>-44928.603979</td>\n",
       "      <td>-4.492860e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Closed-Form (Fair)</th>\n",
       "      <td>2.149763</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>-44928.603979</td>\n",
       "      <td>-4.492860e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solver</th>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>-44790.736205</td>\n",
       "      <td>-4.492860e+04</td>\n",
       "      <td>1.378681e+02</td>\n",
       "      <td>0.003078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solver (Fair)</th>\n",
       "      <td>2.149763</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>-44790.736205</td>\n",
       "      <td>-4.492860e+04</td>\n",
       "      <td>1.378679e+02</td>\n",
       "      <td>0.003078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2.0</th>\n",
       "      <th>Closed-Form</th>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>-835094.022604</td>\n",
       "      <td>-3.661979e+06</td>\n",
       "      <td>2.826885e+06</td>\n",
       "      <td>3.385110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Closed-Form (Fair)</th>\n",
       "      <td>2.149763</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>-835094.022604</td>\n",
       "      <td>-5.609882e+06</td>\n",
       "      <td>4.774788e+06</td>\n",
       "      <td>5.717665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solver</th>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>-587506.397186</td>\n",
       "      <td>-3.672405e+06</td>\n",
       "      <td>3.084899e+06</td>\n",
       "      <td>5.250835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solver (Fair)</th>\n",
       "      <td>2.149763</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>-587506.397186</td>\n",
       "      <td>-5.621857e+06</td>\n",
       "      <td>5.034351e+06</td>\n",
       "      <td>8.569015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">inf</th>\n",
       "      <th>Closed-Form</th>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>2.124773e-06</td>\n",
       "      <td>6.246730e-04</td>\n",
       "      <td>0.996451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Closed-Form (Fair)</th>\n",
       "      <td>2.149763</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>7.966767e-07</td>\n",
       "      <td>6.260011e-04</td>\n",
       "      <td>0.998570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solver</th>\n",
       "      <td>2.703654</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>2.540136e-06</td>\n",
       "      <td>1.246820e-03</td>\n",
       "      <td>0.997887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solver (Fair)</th>\n",
       "      <td>2.149763</td>\n",
       "      <td>4.387572</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>9.241947e-07</td>\n",
       "      <td>1.248436e-03</td>\n",
       "      <td>0.999180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Predicted Risk Mean  True Risk Mean  True Objective  \\\n",
       "Alpha Method                                                                    \n",
       "0.0   Closed-Form                    2.703654        4.387572   283123.180400   \n",
       "      Closed-Form (Fair)             2.149763        4.387572   283123.180400   \n",
       "      Solver                         2.703654        4.387572   284164.896752   \n",
       "      Solver (Fair)                  2.149763        4.387572   284164.896752   \n",
       "0.5   Closed-Form                    2.703654        4.387572    73560.208282   \n",
       "      Closed-Form (Fair)             2.149763        4.387572    73560.208282   \n",
       "      Solver                         2.703654        4.387572    73629.284004   \n",
       "      Solver (Fair)                  2.149763        4.387572    73629.284004   \n",
       "1.0   Closed-Form                    2.703654        4.387572   -44928.603979   \n",
       "      Closed-Form (Fair)             2.149763        4.387572   -44928.603979   \n",
       "      Solver                         2.703654        4.387572   -44790.736205   \n",
       "      Solver (Fair)                  2.149763        4.387572   -44790.736205   \n",
       "2.0   Closed-Form                    2.703654        4.387572  -835094.022604   \n",
       "      Closed-Form (Fair)             2.149763        4.387572  -835094.022604   \n",
       "      Solver                         2.703654        4.387572  -587506.397186   \n",
       "      Solver (Fair)                  2.149763        4.387572  -587506.397186   \n",
       "inf   Closed-Form                    2.703654        4.387572        0.000627   \n",
       "      Closed-Form (Fair)             2.149763        4.387572        0.000627   \n",
       "      Solver                         2.703654        4.387572        0.001249   \n",
       "      Solver (Fair)                  2.149763        4.387572        0.001249   \n",
       "\n",
       "                          Predicted Objective        Regret  Normalized Regret  \n",
       "Alpha Method                                                                    \n",
       "0.0   Closed-Form                1.694669e+05  1.136563e+05           0.401438  \n",
       "      Closed-Form (Fair)         1.668212e+05  1.163020e+05           0.410782  \n",
       "      Solver                     1.694669e+05  1.146980e+05           0.403632  \n",
       "      Solver (Fair)              1.668212e+05  1.173437e+05           0.412942  \n",
       "0.5   Closed-Form                4.922819e+04  2.433202e+04           0.330777  \n",
       "      Closed-Form (Fair)         4.501799e+04  2.854222e+04           0.388012  \n",
       "      Solver                     4.967441e+04  2.395488e+04           0.325344  \n",
       "      Solver (Fair)              4.550411e+04  2.812517e+04           0.381984  \n",
       "1.0   Closed-Form               -4.492860e+04  0.000000e+00           0.000000  \n",
       "      Closed-Form (Fair)        -4.492860e+04  0.000000e+00           0.000000  \n",
       "      Solver                    -4.492860e+04  1.378681e+02           0.003078  \n",
       "      Solver (Fair)             -4.492860e+04  1.378679e+02           0.003078  \n",
       "2.0   Closed-Form               -3.661979e+06  2.826885e+06           3.385110  \n",
       "      Closed-Form (Fair)        -5.609882e+06  4.774788e+06           5.717665  \n",
       "      Solver                    -3.672405e+06  3.084899e+06           5.250835  \n",
       "      Solver (Fair)             -5.621857e+06  5.034351e+06           8.569015  \n",
       "inf   Closed-Form                2.124773e-06  6.246730e-04           0.996451  \n",
       "      Closed-Form (Fair)         7.966767e-07  6.260011e-04           0.998570  \n",
       "      Solver                     2.540136e-06  1.246820e-03           0.997887  \n",
       "      Solver (Fair)              9.241947e-07  1.248436e-03           0.999180  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m Kernel \n",
      "\u001b[1;31m\n",
      "\u001b[1;31m<a href='https://aka.ms/vscodeJupyterKernelCrash'></a>\n",
      "\u001b[1;31m Jupyter <a href='command:jupyter.viewOutput'>log</a>"
     ]
    }
   ],
   "source": [
    "results_df.groupby(['Alpha','Method']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>True Solution Mean</th>\n",
       "      <th>True Solution Std</th>\n",
       "      <th>Predicted Solution Mean</th>\n",
       "      <th>Predicted Solution Std</th>\n",
       "      <th>True Utility Mean</th>\n",
       "      <th>True Utility Std</th>\n",
       "      <th>Predicted Utility Mean</th>\n",
       "      <th>Predicted Utility Std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Closed-Form</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0282</td>\n",
       "      <td>5.3127</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>5.3127</td>\n",
       "      <td>7.9913</td>\n",
       "      <td>1504.1455</td>\n",
       "      <td>4.7833</td>\n",
       "      <td>900.3249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.5</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>2.4697</td>\n",
       "      <td>6.3330</td>\n",
       "      <td>1.8412</td>\n",
       "      <td>15.5767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.1865</td>\n",
       "      <td>2.6379</td>\n",
       "      <td>6.3763</td>\n",
       "      <td>1.8296</td>\n",
       "      <td>31.3966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7838</td>\n",
       "      <td>1.2140</td>\n",
       "      <td>0.7838</td>\n",
       "      <td>1.2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8534</td>\n",
       "      <td>1.2255</td>\n",
       "      <td>0.8534</td>\n",
       "      <td>1.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.2277</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>0.1527</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.4991</td>\n",
       "      <td>0.8410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.2157</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.5921</td>\n",
       "      <td>0.8916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">inf</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.4137</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.4382</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>0.6924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.3676</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0977</td>\n",
       "      <td>0.4913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Closed-Form (Fair)</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0282</td>\n",
       "      <td>5.3127</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>5.3127</td>\n",
       "      <td>7.9913</td>\n",
       "      <td>1504.1455</td>\n",
       "      <td>4.7086</td>\n",
       "      <td>886.2690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.5</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>2.4697</td>\n",
       "      <td>6.3330</td>\n",
       "      <td>2.6178</td>\n",
       "      <td>35.1593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.1820</td>\n",
       "      <td>2.6379</td>\n",
       "      <td>6.3763</td>\n",
       "      <td>2.1087</td>\n",
       "      <td>30.2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7838</td>\n",
       "      <td>1.2140</td>\n",
       "      <td>0.7838</td>\n",
       "      <td>1.2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8534</td>\n",
       "      <td>1.2255</td>\n",
       "      <td>0.8534</td>\n",
       "      <td>1.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.2277</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.1527</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.4126</td>\n",
       "      <td>0.6444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.2157</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.5053</td>\n",
       "      <td>0.6874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">inf</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.4137</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.2739</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0907</td>\n",
       "      <td>0.4864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.2798</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.3588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Solver</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0282</td>\n",
       "      <td>5.3127</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>5.3127</td>\n",
       "      <td>7.9913</td>\n",
       "      <td>1504.1455</td>\n",
       "      <td>4.7833</td>\n",
       "      <td>900.3249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.5</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>0.1233</td>\n",
       "      <td>2.4724</td>\n",
       "      <td>6.3458</td>\n",
       "      <td>1.8558</td>\n",
       "      <td>15.5131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.1855</td>\n",
       "      <td>2.6398</td>\n",
       "      <td>6.3860</td>\n",
       "      <td>1.8423</td>\n",
       "      <td>31.2405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7838</td>\n",
       "      <td>1.2141</td>\n",
       "      <td>0.7838</td>\n",
       "      <td>1.2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8535</td>\n",
       "      <td>1.2256</td>\n",
       "      <td>0.8534</td>\n",
       "      <td>1.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0268</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.1819</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.4928</td>\n",
       "      <td>0.8095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.1816</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.1435</td>\n",
       "      <td>0.5853</td>\n",
       "      <td>0.8581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">inf</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.4123</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.3780</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0846</td>\n",
       "      <td>0.4391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.3905</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.3522</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1047</td>\n",
       "      <td>0.3396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Solver (Fair)</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0282</td>\n",
       "      <td>5.3127</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>5.3127</td>\n",
       "      <td>7.9913</td>\n",
       "      <td>1504.1455</td>\n",
       "      <td>4.7086</td>\n",
       "      <td>886.2690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.5</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>2.4724</td>\n",
       "      <td>6.3458</td>\n",
       "      <td>2.6249</td>\n",
       "      <td>34.9880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.1813</td>\n",
       "      <td>2.6398</td>\n",
       "      <td>6.3860</td>\n",
       "      <td>2.1170</td>\n",
       "      <td>30.1172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7838</td>\n",
       "      <td>1.2141</td>\n",
       "      <td>0.7838</td>\n",
       "      <td>1.2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8535</td>\n",
       "      <td>1.2256</td>\n",
       "      <td>0.8534</td>\n",
       "      <td>1.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2.0</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0268</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.1819</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.4056</td>\n",
       "      <td>0.6196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.1816</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.1435</td>\n",
       "      <td>0.4974</td>\n",
       "      <td>0.6617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">inf</th>\n",
       "      <th>Black</th>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.4123</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.2398</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.3135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.3905</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.2613</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.2693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                True Solution Mean  True Solution Std  \\\n",
       "Method             Alpha Race                                           \n",
       "Closed-Form        0.0   Black              0.0000             0.0000   \n",
       "                         White              0.0282             5.3127   \n",
       "                   0.5   Black              0.0232             0.0359   \n",
       "                         White              0.0252             0.0362   \n",
       "                   1.0   Black              0.0250             0.0000   \n",
       "                         White              0.0250             0.0000   \n",
       "                   2.0   Black              0.0269             0.2277   \n",
       "                         White              0.0248             0.2157   \n",
       "                   inf   Black              0.0275             0.4137   \n",
       "                         White              0.0247             0.3918   \n",
       "Closed-Form (Fair) 0.0   Black              0.0000             0.0000   \n",
       "                         White              0.0282             5.3127   \n",
       "                   0.5   Black              0.0232             0.0359   \n",
       "                         White              0.0252             0.0362   \n",
       "                   1.0   Black              0.0250             0.0000   \n",
       "                         White              0.0250             0.0000   \n",
       "                   2.0   Black              0.0269             0.2277   \n",
       "                         White              0.0248             0.2157   \n",
       "                   inf   Black              0.0275             0.4137   \n",
       "                         White              0.0247             0.3918   \n",
       "Solver             0.0   Black              0.0000             0.0000   \n",
       "                         White              0.0282             5.3127   \n",
       "                   0.5   Black              0.0232             0.0360   \n",
       "                         White              0.0252             0.0363   \n",
       "                   1.0   Black              0.0250             0.0000   \n",
       "                         White              0.0250             0.0000   \n",
       "                   2.0   Black              0.0268             0.1917   \n",
       "                         White              0.0248             0.1816   \n",
       "                   inf   Black              0.0275             0.4123   \n",
       "                         White              0.0247             0.3905   \n",
       "Solver (Fair)      0.0   Black              0.0000             0.0000   \n",
       "                         White              0.0282             5.3127   \n",
       "                   0.5   Black              0.0232             0.0360   \n",
       "                         White              0.0252             0.0363   \n",
       "                   1.0   Black              0.0250             0.0000   \n",
       "                         White              0.0250             0.0000   \n",
       "                   2.0   Black              0.0268             0.1917   \n",
       "                         White              0.0248             0.1816   \n",
       "                   inf   Black              0.0275             0.4123   \n",
       "                         White              0.0247             0.3905   \n",
       "\n",
       "                                Predicted Solution Mean  \\\n",
       "Method             Alpha Race                             \n",
       "Closed-Form        0.0   Black                   0.0000   \n",
       "                         White                   0.0282   \n",
       "                   0.5   Black                   0.0288   \n",
       "                         White                   0.0245   \n",
       "                   1.0   Black                   0.0250   \n",
       "                         White                   0.0250   \n",
       "                   2.0   Black                   0.0223   \n",
       "                         White                   0.0253   \n",
       "                   inf   Black                   0.0261   \n",
       "                         White                   0.0249   \n",
       "Closed-Form (Fair) 0.0   Black                   0.0000   \n",
       "                         White                   0.0282   \n",
       "                   0.5   Black                   0.0309   \n",
       "                         White                   0.0242   \n",
       "                   1.0   Black                   0.0250   \n",
       "                         White                   0.0250   \n",
       "                   2.0   Black                   0.0207   \n",
       "                         White                   0.0256   \n",
       "                   inf   Black                   0.0214   \n",
       "                         White                   0.0255   \n",
       "Solver             0.0   Black                   0.0000   \n",
       "                         White                   0.0282   \n",
       "                   0.5   Black                   0.0288   \n",
       "                         White                   0.0245   \n",
       "                   1.0   Black                   0.0250   \n",
       "                         White                   0.0250   \n",
       "                   2.0   Black                   0.0222   \n",
       "                         White                   0.0254   \n",
       "                   inf   Black                   0.0245   \n",
       "                         White                   0.0251   \n",
       "Solver (Fair)      0.0   Black                   0.0000   \n",
       "                         White                   0.0282   \n",
       "                   0.5   Black                   0.0309   \n",
       "                         White                   0.0242   \n",
       "                   1.0   Black                   0.0250   \n",
       "                         White                   0.0250   \n",
       "                   2.0   Black                   0.0207   \n",
       "                         White                   0.0256   \n",
       "                   inf   Black                   0.0207   \n",
       "                         White                   0.0256   \n",
       "\n",
       "                                Predicted Solution Std  True Utility Mean  \\\n",
       "Method             Alpha Race                                               \n",
       "Closed-Form        0.0   Black                  0.0000             0.0000   \n",
       "                         White                  5.3127             7.9913   \n",
       "                   0.5   Black                  0.1240             2.4697   \n",
       "                         White                  0.1865             2.6379   \n",
       "                   1.0   Black                  0.0000             0.7838   \n",
       "                         White                  0.0000             0.8534   \n",
       "                   2.0   Black                  0.0660             0.1527   \n",
       "                         White                  0.0630             0.1622   \n",
       "                   inf   Black                  0.4382             0.0006   \n",
       "                         White                  0.3676             0.0006   \n",
       "Closed-Form (Fair) 0.0   Black                  0.0000             0.0000   \n",
       "                         White                  5.3127             7.9913   \n",
       "                   0.5   Black                  0.2191             2.4697   \n",
       "                         White                  0.1820             2.6379   \n",
       "                   1.0   Black                  0.0000             0.7838   \n",
       "                         White                  0.0000             0.8534   \n",
       "                   2.0   Black                  0.0474             0.1527   \n",
       "                         White                  0.0502             0.1622   \n",
       "                   inf   Black                  0.2739             0.0006   \n",
       "                         White                  0.2798             0.0006   \n",
       "Solver             0.0   Black                  0.0000             0.0000   \n",
       "                         White                  5.3127             7.9913   \n",
       "                   0.5   Black                  0.1233             2.4724   \n",
       "                         White                  0.1855             2.6398   \n",
       "                   1.0   Black                  0.0000             0.7838   \n",
       "                         White                  0.0000             0.8535   \n",
       "                   2.0   Black                  0.0592             0.1819   \n",
       "                         White                  0.0588             0.1933   \n",
       "                   inf   Black                  0.3780             0.0012   \n",
       "                         White                  0.3522             0.0012   \n",
       "Solver (Fair)      0.0   Black                  0.0000             0.0000   \n",
       "                         White                  5.3127             7.9913   \n",
       "                   0.5   Black                  0.2180             2.4724   \n",
       "                         White                  0.1813             2.6398   \n",
       "                   1.0   Black                  0.0000             0.7838   \n",
       "                         White                  0.0000             0.8535   \n",
       "                   2.0   Black                  0.0438             0.1819   \n",
       "                         White                  0.0475             0.1933   \n",
       "                   inf   Black                  0.2398             0.0012   \n",
       "                         White                  0.2613             0.0012   \n",
       "\n",
       "                                True Utility Std  Predicted Utility Mean  \\\n",
       "Method             Alpha Race                                              \n",
       "Closed-Form        0.0   Black            0.0000                  0.0000   \n",
       "                         White         1504.1455                  4.7833   \n",
       "                   0.5   Black            6.3330                  1.8412   \n",
       "                         White            6.3763                  1.8296   \n",
       "                   1.0   Black            1.2140                  0.7838   \n",
       "                         White            1.2255                  0.8534   \n",
       "                   2.0   Black            0.1192                  0.4991   \n",
       "                         White            0.1206                  0.5921   \n",
       "                   inf   Black            0.0000                  0.0832   \n",
       "                         White            0.0000                  0.0977   \n",
       "Closed-Form (Fair) 0.0   Black            0.0000                  0.0000   \n",
       "                         White         1504.1455                  4.7086   \n",
       "                   0.5   Black            6.3330                  2.6178   \n",
       "                         White            6.3763                  2.1087   \n",
       "                   1.0   Black            1.2140                  0.7838   \n",
       "                         White            1.2255                  0.8534   \n",
       "                   2.0   Black            0.1192                  0.4126   \n",
       "                         White            0.1206                  0.5053   \n",
       "                   inf   Black            0.0000                  0.0907   \n",
       "                         White            0.0000                  0.1199   \n",
       "Solver             0.0   Black            0.0000                  0.0000   \n",
       "                         White         1504.1455                  4.7833   \n",
       "                   0.5   Black            6.3458                  1.8558   \n",
       "                         White            6.3860                  1.8423   \n",
       "                   1.0   Black            1.2141                  0.7838   \n",
       "                         White            1.2256                  0.8534   \n",
       "                   2.0   Black            0.1418                  0.4928   \n",
       "                         White            0.1435                  0.5853   \n",
       "                   inf   Black            0.0000                  0.0846   \n",
       "                         White            0.0000                  0.1047   \n",
       "Solver (Fair)      0.0   Black            0.0000                  0.0000   \n",
       "                         White         1504.1455                  4.7086   \n",
       "                   0.5   Black            6.3458                  2.6249   \n",
       "                         White            6.3860                  2.1170   \n",
       "                   1.0   Black            1.2141                  0.7838   \n",
       "                         White            1.2256                  0.8534   \n",
       "                   2.0   Black            0.1418                  0.4056   \n",
       "                         White            0.1435                  0.4974   \n",
       "                   inf   Black            0.0000                  0.0926   \n",
       "                         White            0.0000                  0.1270   \n",
       "\n",
       "                                Predicted Utility Std  \n",
       "Method             Alpha Race                          \n",
       "Closed-Form        0.0   Black                 0.0000  \n",
       "                         White               900.3249  \n",
       "                   0.5   Black                15.5767  \n",
       "                         White                31.3966  \n",
       "                   1.0   Black                 1.2140  \n",
       "                         White                 1.2255  \n",
       "                   2.0   Black                 0.8410  \n",
       "                         White                 0.8916  \n",
       "                   inf   Black                 0.6924  \n",
       "                         White                 0.4913  \n",
       "Closed-Form (Fair) 0.0   Black                 0.0000  \n",
       "                         White               886.2690  \n",
       "                   0.5   Black                35.1593  \n",
       "                         White                30.2378  \n",
       "                   1.0   Black                 1.2140  \n",
       "                         White                 1.2255  \n",
       "                   2.0   Black                 0.6444  \n",
       "                         White                 0.6874  \n",
       "                   inf   Black                 0.4864  \n",
       "                         White                 0.3588  \n",
       "Solver             0.0   Black                 0.0000  \n",
       "                         White               900.3249  \n",
       "                   0.5   Black                15.5131  \n",
       "                         White                31.2405  \n",
       "                   1.0   Black                 1.2140  \n",
       "                         White                 1.2255  \n",
       "                   2.0   Black                 0.8095  \n",
       "                         White                 0.8581  \n",
       "                   inf   Black                 0.4391  \n",
       "                         White                 0.3396  \n",
       "Solver (Fair)      0.0   Black                 0.0000  \n",
       "                         White               886.2690  \n",
       "                   0.5   Black                34.9880  \n",
       "                         White                30.1172  \n",
       "                   1.0   Black                 1.2140  \n",
       "                         White                 1.2255  \n",
       "                   2.0   Black                 0.6196  \n",
       "                         White                 0.6617  \n",
       "                   inf   Black                 0.3135  \n",
       "                         White                 0.2693  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_analysis_df.groupby(['Method', 'Alpha','Race']).mean(numeric_only=True).round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
