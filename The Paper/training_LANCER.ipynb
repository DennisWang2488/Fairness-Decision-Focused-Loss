{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from typing import Union\n",
    "import abc\n",
    "import pandas as pd\n",
    "\n",
    "Activation = Union[str, nn.Module]\n",
    "_str_to_activation = {\n",
    "    'relu': nn.ReLU(),\n",
    "    'tanh': nn.Tanh(),\n",
    "    'leaky_relu': nn.LeakyReLU(),\n",
    "    'sigmoid': nn.Sigmoid(),\n",
    "    'selu': nn.SELU(),\n",
    "    'softplus': nn.Softplus(),\n",
    "    'identity': nn.Identity(),\n",
    "}\n",
    "\n",
    "def build_mlp(\n",
    "        input_size: int,\n",
    "        output_size: int,\n",
    "        n_layers: int,\n",
    "        size: int,\n",
    "        activation: Activation = 'tanh',\n",
    "        output_activation: Activation = 'identity',\n",
    "):\n",
    "    if isinstance(activation, str):\n",
    "        activation = _str_to_activation[activation]\n",
    "    if isinstance(output_activation, str):\n",
    "        output_activation = _str_to_activation[output_activation]\n",
    "    layers = []\n",
    "    in_size = input_size\n",
    "    for _ in range(n_layers):\n",
    "        layers.append(nn.Linear(in_size, size))\n",
    "        layers.append(activation)\n",
    "        # layers.append(nn.Dropout(p=0.6))\n",
    "        in_size = size\n",
    "    layers.append(nn.Linear(in_size, output_size))\n",
    "    layers.append(output_activation)\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "device = None\n",
    "\n",
    "def init_gpu(use_gpu=True, gpu_id=0):\n",
    "    global device\n",
    "    if torch.cuda.is_available() and use_gpu:\n",
    "        device = torch.device(\"cuda:\" + str(gpu_id))\n",
    "        print(\"Using GPU id {}\".format(gpu_id))\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"GPU not detected. Defaulting to CPU.\")\n",
    "\n",
    "\n",
    "def set_device(gpu_id):\n",
    "    torch.cuda.set_device(gpu_id)\n",
    "\n",
    "\n",
    "def from_numpy(*args, **kwargs):\n",
    "    return torch.from_numpy(*args, **kwargs).float().to(device)\n",
    "\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.to('cpu').detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "class BaseProblem(object, metaclass=abc.ABCMeta):\n",
    "    \"\"\"\n",
    "    BaseProblem defines and solves underlying mathematical optimization problem\n",
    "    Use this base class to define your own problem\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(BaseProblem, self).__init__()\n",
    "        self.num_feats = 0\n",
    "        self.lancer_out_activation = \"relu\"\n",
    "\n",
    "    def build_model(self, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def eval(self, z_pred: np.ndarray, z_true: np.ndarray, **kwargs) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Evaluates problem specific decision loss: f(x*; c_true),\n",
    "        where x* is the solution obtained using z_pred\n",
    "        :param z_pred: predicted problem descriptors\n",
    "        :param z_true: ground truth problem descriptors\n",
    "        :param kwargs: additional problem specific arguments\n",
    "        :return: f_hat_list = list of decision losses, one per datapoint\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_c_shapes(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_activations(self):\n",
    "        return \"tanh\", \"relu\"  # hidden layer(s) and output_activation for c_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AlphaFairness(util,alpha):\n",
    "    if alpha == 1:\n",
    "        return np.sum(np.log(util))\n",
    "    elif alpha == 0:\n",
    "        return np.sum(util)\n",
    "    elif alpha == 'inf':\n",
    "        return np.min(util)\n",
    "    else:\n",
    "        return np.sum(util**(1-alpha)/(1-alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/dennis/Downloads/2024-fall/research/Fairness-Decision-Focused-Loss/The Paper/algorithm')\n",
    "\n",
    "from myutil import *\n",
    "from features import get_all_features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "alpha, Q = 2, 20\n",
    "\n",
    "df = pd.read_csv('data/data.csv')\n",
    "df = df.sample(n=20, random_state=42)\n",
    "\n",
    "columns_to_keep = [\n",
    "    'risk_score_t', 'program_enrolled_t', 'cost_t', 'cost_avoidable_t', 'race', 'dem_female', 'gagne_sum_tm1', 'gagne_sum_t', \n",
    "    'risk_score_percentile', 'screening_eligible', 'avoidable_cost_mapped', 'propensity_score', 'g_binary', \n",
    "    'g_continuous', 'utility_binary', 'utility_continuous'\n",
    "]\n",
    "# for race 0 is white, 1 is black\n",
    "df_stat = df[columns_to_keep]\n",
    "df_feature = df[[col for col in df.columns if col not in columns_to_keep]]\n",
    "\n",
    "# Replace all values less than 0.1 with 0.1\n",
    "# Define input variables for DFL\n",
    "feats = df_feature[get_all_features(df_feature)].values\n",
    "risk = df_stat['risk_score_t'].values.clip(0.001)\n",
    "gainF = df_stat['g_continuous'].values.clip(0.1)\n",
    "decision = df_stat['propensity_score'].values\n",
    "cost = np.ones(risk.shape)\n",
    "race = df_stat['race'].values\n",
    "\n",
    "# Transform the features\n",
    "scaler = StandardScaler()\n",
    "feats = scaler.fit_transform(feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fair",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
