{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import cvxpy as cp\n",
    "import pandas as pd\n",
    "from typing import Union\n",
    "import abc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Helper Functions & Globals\n",
    "# ---------------------------\n",
    "Activation = Union[str, nn.Module]\n",
    "_str_to_activation = {\n",
    "    'relu': nn.ReLU(),\n",
    "    'tanh': nn.Tanh(),\n",
    "    'leaky_relu': nn.LeakyReLU(),\n",
    "    'sigmoid': nn.Sigmoid(),\n",
    "    'selu': nn.SELU(),\n",
    "    'softplus': nn.Softplus(),\n",
    "    'identity': nn.Identity(),\n",
    "}\n",
    "\n",
    "def build_mlp(\n",
    "        input_size: int,\n",
    "        output_size: int,\n",
    "        n_layers: int,\n",
    "        size: int,\n",
    "        activation: Activation = 'tanh',\n",
    "        output_activation: Activation = 'identity',\n",
    "):\n",
    "    if isinstance(activation, str):\n",
    "        activation = _str_to_activation[activation]\n",
    "    if isinstance(output_activation, str):\n",
    "        output_activation = _str_to_activation[output_activation]\n",
    "    layers = []\n",
    "    in_size = input_size\n",
    "    for _ in range(n_layers):\n",
    "        layers.append(nn.Linear(in_size, size))\n",
    "        layers.append(activation)\n",
    "        in_size = size\n",
    "    layers.append(nn.Linear(in_size, output_size))\n",
    "    layers.append(output_activation)\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "device = None\n",
    "def init_gpu(use_gpu=True, gpu_id=0):\n",
    "    global device\n",
    "    if torch.cuda.is_available() and use_gpu:\n",
    "        device = torch.device(\"cuda:\" + str(gpu_id))\n",
    "        print(\"Using GPU id {}\".format(gpu_id))\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"GPU not detected. Defaulting to CPU.\")\n",
    "\n",
    "def from_numpy(*args, **kwargs):\n",
    "    return torch.from_numpy(*args, **kwargs).float().to(device)\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.to('cpu').detach().numpy()\n",
    "\n",
    "# ---------------------------\n",
    "# Fairness Measure & Optimization Solver\n",
    "# ---------------------------\n",
    "def AlphaFairness(util, alpha):\n",
    "    if alpha == 1:\n",
    "        return np.sum(np.log(util))\n",
    "    elif alpha == 0:\n",
    "        return np.sum(util)\n",
    "    elif alpha == 'inf':\n",
    "        return np.min(util)\n",
    "    else:\n",
    "        return np.sum(util**(1-alpha)/(1-alpha))\n",
    "\n",
    "def solve_optimization(gainF, risk, cost, alpha, Q):\n",
    "    \"\"\"\n",
    "    Solves the following optimization problem over the full decision vector d ∈ ℝⁿ:\n",
    "    \n",
    "    \\[\n",
    "    \\begin{aligned}\n",
    "    \\max_{d \\ge 0} \\quad & W(d) = W\\bigl(gainF \\cdot risk \\cdot d\\bigr)\\\\[1mm]\n",
    "    \\text{s.t.} \\quad & \\sum_{i=1}^{n} cost_i \\, d_i \\le Q.\n",
    "    \\end{aligned}\n",
    "    \\]\n",
    "    \n",
    "    Returns the optimal decision vector \\( d \\) and the fairness objective value\n",
    "    computed as\n",
    "    \\[\n",
    "    F(d) = \\text{AlphaFairness}\\bigl(gainF \\cdot risk \\cdot d,\\, \\alpha\\bigr).\n",
    "    \\]\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays if needed.\n",
    "    gainF = gainF.detach().cpu().numpy() if isinstance(gainF, torch.Tensor) else gainF\n",
    "    risk = risk.detach().cpu().numpy() if isinstance(risk, torch.Tensor) else risk\n",
    "    cost = cost.detach().cpu().numpy() if isinstance(cost, torch.Tensor) else cost\n",
    "    risk = np.clip(risk, 0.001, None)\n",
    "    gainF, risk, cost = gainF.flatten(), risk.flatten(), cost.flatten()\n",
    "    \n",
    "    d = cp.Variable(risk.shape, nonneg=True)\n",
    "    utils = cp.multiply(cp.multiply(gainF, risk), d)\n",
    "    constraints = [d >= 0, cp.sum(cp.multiply(cost, d)) <= Q]\n",
    "    \n",
    "    if alpha == 1:\n",
    "        objective = cp.Maximize(cp.sum(cp.log(utils)))\n",
    "    elif alpha == 0:\n",
    "        objective = cp.Maximize(cp.sum(utils))\n",
    "    elif alpha == 'inf':\n",
    "        t = cp.Variable()\n",
    "        objective = cp.Maximize(t)\n",
    "        constraints.append(utils >= t)\n",
    "    else:\n",
    "        objective = cp.Maximize(cp.sum(utils**(1-alpha))/(1-alpha))\n",
    "    \n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve(solver=cp.MOSEK, verbose=False, warm_start=True)\n",
    "    if prob.status != cp.OPTIMAL:\n",
    "        print(\"Warning: Problem status =\", prob.status)\n",
    "    optimal_decision = d.value\n",
    "    optimal_value = AlphaFairness(optimal_decision * gainF * risk, alpha)\n",
    "    return optimal_decision, optimal_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Data Loading & Preprocessing\n",
    "# ---------------------------\n",
    "# (Assume helper functions such as get_all_features are defined in your modules)\n",
    "import sys\n",
    "sys.path.insert(0, 'E:\\\\User\\\\Stevens\\\\Code\\\\The Paper\\\\algorithm')\n",
    "\n",
    "from myutil import *\n",
    "from features import get_all_features\n",
    "\n",
    "alpha, Q = 2, 1000\n",
    "\n",
    "df = pd.read_csv('data/data.csv')\n",
    "df = df.sample(n=1000, random_state=42)\n",
    "\n",
    "columns_to_keep = [\n",
    "    'risk_score_t', 'program_enrolled_t', 'cost_t', 'cost_avoidable_t', 'race', 'dem_female', \n",
    "    'gagne_sum_tm1', 'gagne_sum_t', 'risk_score_percentile', 'screening_eligible', \n",
    "    'avoidable_cost_mapped', 'propensity_score', 'g_binary', 'g_continuous', \n",
    "    'utility_binary', 'utility_continuous'\n",
    "]\n",
    "df_stat = df[columns_to_keep]\n",
    "df_feature = df[[col for col in df.columns if col not in columns_to_keep]]\n",
    "\n",
    "# Define the inputs for decision-focused learning.\n",
    "# Here the entire dataset represents one decision problem (n dimensions).\n",
    "feats = df_feature[get_all_features(df_feature)].values\n",
    "risk = df_stat['risk_score_t'].values.clip(0.001)      # true r ∈ ℝⁿ\n",
    "gainF = df_stat['g_continuous'].values.clip(0.1)         # gain vector ∈ ℝⁿ\n",
    "cost = np.ones(risk.shape)                               # cost vector ∈ ℝⁿ\n",
    "race = df_stat['race'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "feats = scaler.fit_transform(feats)\n",
    "\n",
    "# For this problem, we treat the entire vector as one instance.\n",
    "# (If desired, one might use cross-validation or different splits; here we split into train/test.)\n",
    "train_feats, test_feats, train_risk, test_risk, train_gainF, test_gainF, train_cost, test_cost = train_test_split(\n",
    "    feats, risk, gainF, cost, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Model Definitions\n",
    "# ---------------------------\n",
    "class FairnessPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Predictor (C model) that maps features x to a predicted parameter \\(\\hat{r}\\) (a vector of size n).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, c_n_layers=0, c_layer_size=64, learning_rate=0.005, weight_decay=0.01,\n",
    "                 activation=\"tanh\", output_activation=\"relu\"):\n",
    "        super(FairnessPredictor, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        # If c_n_layers==0, use a linear model.\n",
    "        if c_n_layers == 0:\n",
    "            self.model = nn.Linear(input_dim, 1)\n",
    "        else:\n",
    "            self.model = build_mlp(input_size=input_dim,\n",
    "                                   output_size=1,\n",
    "                                   n_layers=c_n_layers,\n",
    "                                   size=c_layer_size,\n",
    "                                   activation=activation,\n",
    "                                   output_activation=output_activation)\n",
    "        self.model.to(device)\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is of shape (n, input_dim), output is (n,)\n",
    "        return self.model(x).squeeze(-1)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.forward(x)\n",
    "\n",
    "class LancerSurrogateFairness(nn.Module):\n",
    "    \"\"\"\n",
    "    Surrogate (LANCER) model that predicts the fairness loss (i.e. regret)\n",
    "    from the squared error \\((r - \\hat{r})^2\\).\n",
    "    \"\"\"\n",
    "    def __init__(self, lancer_n_layers=2, lancer_layer_size=64, learning_rate=0.001, weight_decay=0.01,\n",
    "                 activation=\"relu\", output_activation=\"relu\"):\n",
    "        super(LancerSurrogateFairness, self).__init__()\n",
    "        self.model = build_mlp(input_size=1,\n",
    "                               output_size=1,\n",
    "                               n_layers=lancer_n_layers,\n",
    "                               size=lancer_layer_size,\n",
    "                               activation=activation,\n",
    "                               output_activation=output_activation)\n",
    "        self.model.to(device)\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        \n",
    "    def forward(self, pred_r, true_r):\n",
    "        # Compute elementwise squared error, then output a scalar prediction per element.\n",
    "        diff = (true_r - pred_r)**2\n",
    "        if diff.dim() == 1:\n",
    "            diff = diff.unsqueeze(1)\n",
    "        # The model outputs a value per element; we average over all elements.\n",
    "        return self.model(diff).squeeze(-1).mean()\n",
    "    \n",
    "    def forward_theta_step(self, pred_r, true_r):\n",
    "        # Average surrogate output over all elements.\n",
    "        return self.forward(pred_r, true_r)\n",
    "    \n",
    "    def update(self, pred_r, true_r, f_hat):\n",
    "        # f_hat is a scalar target (the fairness loss/regret computed from the optimization problems).\n",
    "        prediction = self.forward(pred_r, true_r)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.loss(prediction, f_hat)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# LANCER Learner for Fairness (No Mini-batching)\n",
    "# ---------------------------\n",
    "class LancerLearnerFairness:\n",
    "    def __init__(self, predictor: FairnessPredictor, surrogate: LancerSurrogateFairness, z_regul=0.0):\n",
    "        self.predictor = predictor\n",
    "        self.surrogate = surrogate\n",
    "        self.z_regul = z_regul  # weight on the MSE loss for predictor update\n",
    "\n",
    "    def initial_fit(self, feats, true_risk, c_epochs_init=30):\n",
    "        \"\"\"Warm-start the predictor using the full dataset (no mini-batching).\"\"\"\n",
    "        self.predictor.train()\n",
    "        X = from_numpy(feats)\n",
    "        r_true = from_numpy(true_risk)\n",
    "        for epoch in range(c_epochs_init):\n",
    "            self.predictor.optimizer.zero_grad()\n",
    "            r_pred = self.predictor(X)\n",
    "            loss = self.predictor.loss(r_pred, r_true)\n",
    "            loss.backward()\n",
    "            self.predictor.optimizer.step()\n",
    "            print(f\"Initial fit epoch {epoch+1}, Predictor MSE Loss: {loss.item():.4f}\")\n",
    "\n",
    "    def train_surrogate(self, feats, true_risk, gainF, cost, alpha, Q, lancer_max_iter=5):\n",
    "        \"\"\"Train the surrogate (LANCER) model on the entire dataset.\"\"\"\n",
    "        self.surrogate.train()\n",
    "        X = from_numpy(feats)\n",
    "        r_true = from_numpy(true_risk)\n",
    "        with torch.no_grad():\n",
    "            r_pred = self.predictor(X)\n",
    "        # Convert to numpy arrays.\n",
    "        r_true_np = r_true.cpu().numpy().flatten()\n",
    "        r_pred_np = r_pred.cpu().numpy().flatten()\n",
    "        gainF_np = gainF.flatten()\n",
    "        cost_np = cost.flatten()\n",
    "        # Solve optimization with true risk:\n",
    "        _, fairness_true = solve_optimization(gainF_np, r_true_np, cost_np, alpha, Q)\n",
    "        # Solve optimization with predicted risk:\n",
    "        pred_sol, _ = solve_optimization(gainF_np, r_pred_np, cost_np, alpha, Q)\n",
    "        # Evaluate predicted fairness objective using true risk and the decision from predicted risk.\n",
    "        pred_obj = AlphaFairness(gainF_np * r_true_np * pred_sol, alpha)\n",
    "        f_hat = fairness_true - pred_obj  # target fairness loss (regret)\n",
    "        f_hat_tensor = from_numpy(np.array([f_hat]))\n",
    "        # Compute surrogate prediction over the full dataset.\n",
    "        surrogate_output = self.surrogate.forward(r_pred, r_true)\n",
    "        loss_val = self.surrogate.loss(surrogate_output, f_hat_tensor)\n",
    "        self.surrogate.optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        self.surrogate.optimizer.step()\n",
    "        return loss_val.item()\n",
    "\n",
    "    def train_predictor(self, feats, true_risk, c_max_iter=5):\n",
    "        \"\"\"Update the predictor using surrogate feedback plus standard MSE loss on the full dataset.\"\"\"\n",
    "        self.predictor.train()\n",
    "        X = from_numpy(feats)\n",
    "        r_true = from_numpy(true_risk)\n",
    "        total_loss = 0.0\n",
    "        for _ in range(c_max_iter):\n",
    "            r_pred = self.predictor(X)\n",
    "            surrogate_loss = self.surrogate.forward_theta_step(r_pred, r_true)\n",
    "            mse_loss = self.predictor.loss(r_pred, r_true)\n",
    "            loss = surrogate_loss + self.z_regul * mse_loss\n",
    "            self.predictor.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.predictor.optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        return total_loss / c_max_iter\n",
    "\n",
    "    def compute_regret(self, feats, true_risk, gainF, cost, alpha, Q):\n",
    "        \"\"\"\n",
    "        Compute the normalized regret on the full dataset.\n",
    "        \n",
    "        For the full instance:\n",
    "        - Solve the optimization problem with true risk to get opt_val.\n",
    "        - Solve the optimization problem with predicted risk to get a decision, then compute\n",
    "          the predicted fairness objective using true risk:\n",
    "          \n",
    "          \\[\n",
    "          \\text{pred\\_obj} = \\text{AlphaFairness}(gainF \\cdot r \\cdot \\mathbf{d}(\\hat{r}), \\alpha)\n",
    "          \\]\n",
    "          \n",
    "        - The normalized regret is:\n",
    "          \\[\n",
    "          \\text{Regret} = \\frac{opt\\_val - pred\\_obj}{|opt\\_val| + \\epsilon}.\n",
    "          \\]\n",
    "        \"\"\"\n",
    "        self.predictor.eval()\n",
    "        X = from_numpy(feats)\n",
    "        r_true = from_numpy(true_risk)\n",
    "        r_pred = self.predictor(X)\n",
    "        r_true_np = to_numpy(r_true).flatten()\n",
    "        r_pred_np = to_numpy(r_pred).flatten()\n",
    "        r_pred_np = np.clip(r_pred_np, 0.001, None)\n",
    "        gainF_np = gainF.flatten()\n",
    "        cost_np = cost.flatten()\n",
    "        _, opt_val = solve_optimization(gainF_np, r_true_np, cost_np, alpha, Q)\n",
    "        pred_sol, _ = solve_optimization(gainF_np, r_pred_np, cost_np, alpha, Q)\n",
    "        pred_obj = AlphaFairness(gainF_np * r_true_np * pred_sol, alpha)\n",
    "        regret = (opt_val - pred_obj) / (abs(opt_val) + 1e-7)\n",
    "        return regret\n",
    "\n",
    "    def training_loop(self, train_feats, train_risk, train_gainF, train_cost,\n",
    "                      test_feats, test_risk, test_gainF, test_cost,\n",
    "                      alpha, Q, n_iter=10, c_epochs_init=30, c_max_iter=5, lancer_max_iter=5, print_freq=1):\n",
    "        # Warm-start the predictor.\n",
    "        print(\"Warm-starting predictor...\")\n",
    "        self.initial_fit(train_feats, train_risk, c_epochs_init)\n",
    "        for itr in range(n_iter):\n",
    "            print(f\"\\nIteration {itr+1}\")\n",
    "            avg_surrogate_loss = 0.0\n",
    "            for _ in range(lancer_max_iter):\n",
    "                avg_surrogate_loss += self.train_surrogate(train_feats, train_risk, train_gainF, train_cost, alpha, Q, lancer_max_iter=1)\n",
    "            avg_surrogate_loss /= lancer_max_iter\n",
    "            avg_predictor_loss = self.train_predictor(train_feats, train_risk, c_max_iter)\n",
    "            train_regret = self.compute_regret(train_feats, train_risk, train_gainF, train_cost, alpha, Q)\n",
    "            test_regret = self.compute_regret(test_feats, test_risk, test_gainF, test_cost, alpha, Q)\n",
    "            if (itr+1) % print_freq == 0:\n",
    "                print(f\"Iteration {itr+1}: Predictor Loss: {avg_predictor_loss:.4f}, Surrogate Loss: {avg_surrogate_loss:.4f}\")\n",
    "                print(f\"Train Regret: {train_regret:.2f}%, Test Regret: {test_regret:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU id 0\n",
      "{'seed': 42, 'n_iter': 10, 'print_freq': 1, 'lancer_n_layers': 2, 'lancer_layer_size': 100, 'lancer_lr': 0.001, 'lancer_weight_decay': 0.01, 'lancer_max_iter': 5, 'c_n_layers': 0, 'c_layer_size': 64, 'c_lr': 0.005, 'c_weight_decay': 0.01, 'z_regul': 0.01, 'c_max_iter': 5, 'c_epochs_init': 30}\n",
      "Warm-starting predictor...\n",
      "Initial fit epoch 1, Predictor MSE Loss: 49.2716\n",
      "Initial fit epoch 2, Predictor MSE Loss: 48.0012\n",
      "Initial fit epoch 3, Predictor MSE Loss: 46.7925\n",
      "Initial fit epoch 4, Predictor MSE Loss: 45.6450\n",
      "Initial fit epoch 5, Predictor MSE Loss: 44.5583\n",
      "Initial fit epoch 6, Predictor MSE Loss: 43.5319\n",
      "Initial fit epoch 7, Predictor MSE Loss: 42.5647\n",
      "Initial fit epoch 8, Predictor MSE Loss: 41.6551\n",
      "Initial fit epoch 9, Predictor MSE Loss: 40.8006\n",
      "Initial fit epoch 10, Predictor MSE Loss: 39.9984\n",
      "Initial fit epoch 11, Predictor MSE Loss: 39.2455\n",
      "Initial fit epoch 12, Predictor MSE Loss: 38.5391\n",
      "Initial fit epoch 13, Predictor MSE Loss: 37.8765\n",
      "Initial fit epoch 14, Predictor MSE Loss: 37.2550\n",
      "Initial fit epoch 15, Predictor MSE Loss: 36.6721\n",
      "Initial fit epoch 16, Predictor MSE Loss: 36.1253\n",
      "Initial fit epoch 17, Predictor MSE Loss: 35.6123\n",
      "Initial fit epoch 18, Predictor MSE Loss: 35.1310\n",
      "Initial fit epoch 19, Predictor MSE Loss: 34.6792\n",
      "Initial fit epoch 20, Predictor MSE Loss: 34.2549\n",
      "Initial fit epoch 21, Predictor MSE Loss: 33.8563\n",
      "Initial fit epoch 22, Predictor MSE Loss: 33.4817\n",
      "Initial fit epoch 23, Predictor MSE Loss: 33.1293\n",
      "Initial fit epoch 24, Predictor MSE Loss: 32.7976\n",
      "Initial fit epoch 25, Predictor MSE Loss: 32.4850\n",
      "Initial fit epoch 26, Predictor MSE Loss: 32.1902\n",
      "Initial fit epoch 27, Predictor MSE Loss: 31.9118\n",
      "Initial fit epoch 28, Predictor MSE Loss: 31.6483\n",
      "Initial fit epoch 29, Predictor MSE Loss: 31.3985\n",
      "Initial fit epoch 30, Predictor MSE Loss: 31.1611\n",
      "\n",
      "Iteration 1\n",
      "Iteration 1: Predictor Loss: 10.4015, Surrogate Loss: 4663720.3000\n",
      "Train Regret: 7.72%, Test Regret: 9.24%\n",
      "\n",
      "Iteration 2\n",
      "Iteration 2: Predictor Loss: 17.7461, Surrogate Loss: 4531921.3000\n",
      "Train Regret: 7.71%, Test Regret: 9.45%\n",
      "\n",
      "Iteration 3\n",
      "Iteration 3: Predictor Loss: 26.2530, Surrogate Loss: 4486049.1000\n",
      "Train Regret: 7.61%, Test Regret: 9.08%\n",
      "\n",
      "Iteration 4\n",
      "Iteration 4: Predictor Loss: 36.1771, Surrogate Loss: 4336750.0000\n",
      "Train Regret: 7.25%, Test Regret: 8.89%\n",
      "\n",
      "Iteration 5\n",
      "Iteration 5: Predictor Loss: 47.7717, Surrogate Loss: 3883353.9500\n",
      "Train Regret: 6.88%, Test Regret: 8.54%\n",
      "\n",
      "Iteration 6\n",
      "Iteration 6: Predictor Loss: 61.0284, Surrogate Loss: 3443027.8500\n",
      "Train Regret: 6.63%, Test Regret: 8.01%\n",
      "\n",
      "Iteration 7\n",
      "Iteration 7: Predictor Loss: 75.6807, Surrogate Loss: 3147950.8000\n",
      "Train Regret: 6.39%, Test Regret: 7.58%\n",
      "\n",
      "Iteration 8\n",
      "Iteration 8: Predictor Loss: 91.6313, Surrogate Loss: 2863356.5000\n",
      "Train Regret: 6.18%, Test Regret: 7.24%\n",
      "\n",
      "Iteration 9\n",
      "Iteration 9: Predictor Loss: 108.8495, Surrogate Loss: 2617646.5500\n",
      "Train Regret: 6.05%, Test Regret: 6.98%\n",
      "\n",
      "Iteration 10\n",
      "Iteration 10: Predictor Loss: 127.4757, Surrogate Loss: 2443456.4500\n",
      "Train Regret: 5.98%, Test Regret: 7.03%\n"
     ]
    }
   ],
   "source": [
    "# Here we mimic extra runner parameters similar to the reference.\n",
    "import random\n",
    "\n",
    "def run_on_problem(params):\n",
    "    # For reproducibility.\n",
    "    seed = params[\"seed\"]\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # In this fairness problem, we treat the entire instance as one problem.\n",
    "    # (train/test split as above.)\n",
    "    learner = LancerLearnerFairness(\n",
    "        predictor=FairnessPredictor(input_dim=train_feats.shape[1],\n",
    "                                    c_n_layers=params[\"c_n_layers\"],\n",
    "                                    c_layer_size=params[\"c_layer_size\"],\n",
    "                                    learning_rate=params[\"c_lr\"],\n",
    "                                    weight_decay=params[\"c_weight_decay\"],\n",
    "                                    activation=\"tanh\",\n",
    "                                    output_activation=\"relu\"),\n",
    "        surrogate=LancerSurrogateFairness(lancer_n_layers=params[\"lancer_n_layers\"],\n",
    "                                          lancer_layer_size=params[\"lancer_layer_size\"],\n",
    "                                          learning_rate=params[\"lancer_lr\"],\n",
    "                                          weight_decay=params[\"lancer_weight_decay\"],\n",
    "                                          activation=\"relu\",\n",
    "                                          output_activation=\"relu\"),\n",
    "        z_regul=params[\"z_regul\"]\n",
    "    )\n",
    "    learner.training_loop(train_feats, train_risk, train_gainF, train_cost,\n",
    "                          test_feats, test_risk, test_gainF, test_cost,\n",
    "                          alpha, Q,\n",
    "                          n_iter=params[\"n_iter\"],\n",
    "                          c_epochs_init=params[\"c_epochs_init\"],\n",
    "                          c_max_iter=params[\"c_max_iter\"],\n",
    "                          lancer_max_iter=params[\"lancer_max_iter\"],\n",
    "                          print_freq=params[\"print_freq\"])\n",
    "\n",
    "def main():\n",
    "    # Define parameters directly as a dictionary\n",
    "    params = {\n",
    "        \"seed\": 42,\n",
    "        \"n_iter\": 10,\n",
    "        \"print_freq\": 1,\n",
    "        \"lancer_n_layers\": 2,\n",
    "        \"lancer_layer_size\": 100,\n",
    "        \"lancer_lr\": 0.001,\n",
    "        \"lancer_weight_decay\": 0.01,\n",
    "        \"lancer_max_iter\": 5,\n",
    "        \"c_n_layers\": 0,  # 0 for linear model\n",
    "        \"c_layer_size\": 64,\n",
    "        \"c_lr\": 0.005,\n",
    "        \"c_weight_decay\": 0.01,\n",
    "        \"z_regul\": 0.01,\n",
    "        \"c_max_iter\": 5,\n",
    "        \"c_epochs_init\": 30\n",
    "    }\n",
    "    print(params)\n",
    "    run_on_problem(params)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    init_gpu(use_gpu=True, gpu_id=0)\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
