{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import warnings\n",
    "import sys\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.insert(0, 'E:\\\\User\\\\Stevens\\\\Code\\\\The Paper\\\\algorithm')\n",
    "\n",
    "from myutil import *\n",
    "from features import get_all_features\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "df = pd.read_csv('data/data.csv')\n",
    "\n",
    "columns_to_keep = [\n",
    "    'risk_score_t', 'program_enrolled_t', 'cost_t', 'cost_avoidable_t', 'race', 'dem_female', 'gagne_sum_tm1', 'gagne_sum_t', \n",
    "    'risk_score_percentile', 'screening_eligible', 'avoidable_cost_mapped', 'propensity_score', 'g_binary', \n",
    "    'g_continuous', 'utility_binary', 'utility_continuous'\n",
    "]\n",
    "# for race 0 is white, 1 is black\n",
    "df_stat = df[columns_to_keep]\n",
    "df_feature = df[[col for col in df.columns if col not in columns_to_keep]]\n",
    "\n",
    "# Replace all values less than 0.1 with 0.1\n",
    "#df['risk_score_t'] = df['risk_score_t'].apply(lambda x: 0.1 if x < 0.1 else x)\n",
    "df['g_continuous'] = df['g_continuous'].apply(lambda x: 0.1 if x < 0.1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 168)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset a sample of 5000 rows of df\n",
    "df = df.sample(n=100, random_state=42)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0\n",
    "Q = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 60\n",
      "Test size: 40\n"
     ]
    }
   ],
   "source": [
    "# Define input variables for DFL\n",
    "feats = df[get_all_features(df)].values\n",
    "risk = df['risk_score_t'].values\n",
    "\n",
    "risk = risk + 0.001\n",
    "\n",
    "gainF = df['g_continuous'].values\n",
    "decision = df['propensity_score'].values\n",
    "cost = np.ones(risk.shape)\n",
    "race = df['race'].values\n",
    "\n",
    "# transform the features\n",
    "scaler = StandardScaler()\n",
    "feats = scaler.fit_transform(feats)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Perform train-test split\n",
    "feats_train, feats_test, gainF_train, gainF_test, risk_train, risk_test, cost_train, cost_test, race_train, race_test = train_test_split(\n",
    "    feats, gainF, risk, cost, df['race'].values, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train size: {feats_train.shape[0]}\")\n",
    "print(f\"Test size: {feats_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AlphaFairness(util, alpha):\n",
    "    if alpha == 1:\n",
    "        return np.sum(np.log(util))\n",
    "    elif alpha == 0:\n",
    "        return np.sum(util)\n",
    "    elif alpha == 'inf':\n",
    "        return np.min(util)\n",
    "    else:\n",
    "        return np.sum(util**(1-alpha) / (1-alpha))\n",
    "\n",
    "def solve_optimization(gainF, risk, cost, alpha=alpha, Q=Q):\n",
    "    gainF = gainF.detach().cpu().numpy() if isinstance(gainF, torch.Tensor) else gainF\n",
    "    risk = risk.detach().cpu().numpy() if isinstance(risk, torch.Tensor) else risk\n",
    "    cost = cost.detach().cpu().numpy() if isinstance(cost, torch.Tensor) else cost\n",
    "\n",
    "    risk = risk.clip(min=0.001)\n",
    "    gainF, risk, cost = gainF.flatten(), risk.flatten(), cost.flatten()\n",
    "    d = cp.Variable(risk.shape, nonneg=True)\n",
    "\n",
    "    if gainF.shape != risk.shape or risk.shape != cost.shape:\n",
    "        raise ValueError(\"Dimensions of gainF, risk, and cost do not match\")\n",
    "\n",
    "    utils = cp.multiply(cp.multiply(gainF, risk), d)\n",
    "    constraints = [d >= 0, cp.sum(cost * d) <= Q]\n",
    "\n",
    "    if alpha == 'inf':\n",
    "        t = cp.Variable()\n",
    "        objective = cp.Maximize(t)\n",
    "        constraints.append(utils >= t)\n",
    "    elif alpha == 1:\n",
    "        objective = cp.Maximize(cp.sum(cp.log(utils)))\n",
    "    elif alpha == 0:\n",
    "        objective = cp.Maximize(cp.sum(utils))\n",
    "    else:\n",
    "        objective = cp.Maximize(cp.sum(utils**(1-alpha)) / (1-alpha))\n",
    "\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve(solver=cp.MOSEK, verbose=False, warm_start=True, mosek_params={'MSK_IPAR_LOG': 1})\n",
    "\n",
    "    if problem.status != 'optimal':\n",
    "        print(f\"Warning: Problem status is {problem.status}\")\n",
    "\n",
    "    optimal_decision = d.value\n",
    "    optimal_value = AlphaFairness(optimal_decision * gainF * risk, alpha)\n",
    "\n",
    "    return optimal_decision, optimal_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FairRiskPredictor(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=149, out_features=1, bias=True)\n",
       "    (1): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the prediction model\n",
    "class FairRiskDataset(Dataset):\n",
    "    def __init__(self, features, races, risks):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.races = torch.LongTensor(races)\n",
    "        self.risks = torch.FloatTensor(risks).reshape(-1, 1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.races[idx], self.risks[idx]\n",
    "\n",
    "class FairRiskPredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "def train_fair_model(features, races, risks, epochs=20, batch_size=32, lambda_fairness=0):\n",
    "    \"\"\"\n",
    "    Train a fair regression model with a fairness regularizer.\n",
    "    \n",
    "    Args:\n",
    "        features (np.ndarray): Feature array.\n",
    "        races (np.ndarray): Array indicating race (0: white, 1: black).\n",
    "        risks (np.ndarray): True risk values.\n",
    "        epochs (int): Number of training epochs.\n",
    "        batch_size (int): Batch size for training.\n",
    "        lambda_fairness (float): Weight for the fairness regularizer.\n",
    "        \n",
    "    Returns:\n",
    "        nn.Module: Trained fair regression model.\n",
    "    \"\"\"\n",
    "    dataset = FairRiskDataset(features, races, risks)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = FairRiskPredictor(features.shape[1])\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch_features, batch_races, batch_risks in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(batch_features)\n",
    "            mse_loss = criterion(predictions, batch_risks)\n",
    "            \n",
    "            # Compute fairness loss\n",
    "            group0 = predictions[batch_races == 0]\n",
    "            group1 = predictions[batch_races == 1]\n",
    "            if len(group0) > 0 and len(group1) > 0:\n",
    "                fairness_loss = torch.abs(group0.mean() - group1.mean())\n",
    "            else:\n",
    "                fairness_loss = torch.tensor(0.0)\n",
    "            \n",
    "            # Total loss\n",
    "            total_loss = mse_loss + lambda_fairness * fairness_loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += total_loss.item()\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            avg_loss = epoch_loss / len(dataloader)\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Train the fair model\n",
    "# model = train_fair_model(feats_train, race, risk_train, epochs=20, lambda_fairness=0).to(device)\n",
    "# model.eval()\n",
    "\n",
    "# # save\n",
    "# torch.save(model.state_dict(), 'risk_predictor_model.pth')\n",
    "\n",
    "\n",
    "# load model from disk\n",
    "model = FairRiskPredictor(feats.shape[1])\n",
    "model.load_state_dict(torch.load('risk_predictor_model.pth'))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current alpha and Q values are: 0 100\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "class FairDFLDataset(Dataset):\n",
    "    def __init__(self, features, risk, gainF, cost, race, alpha=alpha, Q=Q):\n",
    "        self.features = features\n",
    "        self.risk = risk\n",
    "        self.gainF = gainF\n",
    "        self.cost = cost\n",
    "        self.race = race\n",
    "        self.alpha = alpha\n",
    "        self.Q = Q\n",
    "\n",
    "        self.sols, self.vals = self._get_solutions()\n",
    "        self._to_tensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def _get_solutions(self):\n",
    "        sols, vals = solve_optimization(self.gainF, self.risk, self.cost, self.alpha, self.Q)\n",
    "        return sols, vals\n",
    "\n",
    "    def _to_tensor(self):\n",
    "        self.features = torch.FloatTensor(self.features)\n",
    "        self.risk = torch.FloatTensor(self.risk)\n",
    "        self.gainF = torch.FloatTensor(self.gainF)\n",
    "        self.cost = torch.FloatTensor(self.cost)\n",
    "        self.race = torch.LongTensor(self.race)\n",
    "        self.sols = torch.FloatTensor(self.sols)\n",
    "        self.vals = torch.FloatTensor([self.vals])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.risk[idx], self.gainF[idx], self.cost[idx], self.race[idx], self.sols[idx], self.vals\n",
    "\n",
    "# test the dataset and dataloader\n",
    "dataset_train = FairDFLDataset(feats_train, risk_train, gainF_train, cost_train, race_train)\n",
    "dataset_test = FairDFLDataset(feats_test, risk_test, gainF_test, cost_test, race_test)\n",
    "\n",
    "# Load the dataset into a DataLoader\n",
    "loader_train = DataLoader(dataset_train, batch_size=len(dataset_train), shuffle=True)\n",
    "loader_test = DataLoader(dataset_test, batch_size=len(dataset_test), shuffle=False)\n",
    "print('The current alpha and Q values are:', alpha, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regret(predModel, optModel, dataloader, alphas=[alpha], Q=Q):\n",
    "    predModel.eval()\n",
    "    features, risk, gainF, cost, race, true_sols, true_vals = next(iter(dataloader))\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    features, risk, gainF, cost, race, true_sols, true_vals = (\n",
    "        features.to(device),\n",
    "        risk.to(device),\n",
    "        gainF.to(device),\n",
    "        cost.to(device),\n",
    "        race.to(device),\n",
    "        true_sols.to(device),\n",
    "        true_vals.to(device),\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_risk = predModel(features).clamp(min=0.001)\n",
    "    risk = risk.clamp(min=0.001)\n",
    "\n",
    "    pred_risk = pred_risk.cpu().numpy()\n",
    "    risk = risk.cpu().numpy()\n",
    "    gainF = gainF.cpu().numpy()\n",
    "    cost = cost.cpu().numpy()\n",
    "\n",
    "    regrets = []\n",
    "    for alpha in alphas:\n",
    "        true_sol, true_obj = optModel(gainF, risk, cost, alpha, Q)\n",
    "        pred_sol, _ = optModel(gainF, pred_risk, cost, alpha, Q)\n",
    "        pred_obj = AlphaFairness(gainF * risk * pred_sol, alpha)\n",
    "        normalized_regret = (true_obj - pred_obj) / (abs(true_obj) + 1e-7)\n",
    "        regrets.append(normalized_regret)\n",
    "\n",
    "    predModel.train()\n",
    "    return np.mean(regrets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_d_star_closed_form(g, r, c, alpha=alpha, Q=Q):\n",
    "\n",
    "    if not isinstance(c, np.ndarray) or not isinstance(r, np.ndarray) or not isinstance(g, np.ndarray):\n",
    "        raise TypeError(\"c, r, and g must be numpy arrays.\")\n",
    "    if c.shape != r.shape or c.shape != g.shape:\n",
    "        raise ValueError(\"c, r, and g must have the same shape.\")\n",
    "    if np.any(c <= 0):\n",
    "        raise ValueError(\"All cost values must be positive.\")\n",
    "    if np.any(r <= 0):\n",
    "        raise ValueError(\"All risk values must be positive.\")\n",
    "    if np.any(g <= 0):\n",
    "        raise ValueError(\"All gain factors must be positive.\")\n",
    "    \n",
    "    n = len(c)\n",
    "    utility = r * g\n",
    "    \n",
    "    if alpha == 0:\n",
    "        ratios = utility / c\n",
    "        sorted_indices = np.argsort(-ratios)  # Descending order\n",
    "        d_star_closed = np.zeros(n)\n",
    "        d_star_closed[sorted_indices[0]] = Q / c[sorted_indices[0]]\n",
    "        \n",
    "    elif alpha == 1:\n",
    "        d_star_closed = Q / (n * c)\n",
    "    \n",
    "    elif alpha == 'inf':\n",
    "        d_star_closed = (Q * c) / (utility * np.sum(c * c / utility))\n",
    "        \n",
    "    else:\n",
    "        if alpha <= 0:\n",
    "            raise ValueError(\"Alpha must be positive for general case.\")\n",
    "        #\n",
    "        # d_i* = (c_i^(-1/alpha) * (r_i*g_i)^(1/alpha - 1) * Q) / sum_j(c_j^(-1/alpha) * (r_j*g_j)^(1/alpha - 1))\n",
    "        \n",
    "        numerator = np.power(c, -1/alpha) * np.power(utility, 1/alpha - 1)\n",
    "        denominator = np.sum(numerator)\n",
    "        \n",
    "        if denominator == 0:\n",
    "            raise ValueError(\"Denominator is zero in closed-form solution.\")\n",
    "            \n",
    "        d_star_closed = (numerator / denominator) * Q\n",
    "    \n",
    "    # if not np.isclose(np.sum(c * d_star_closed), Q, rtol=1e-5):\n",
    "    #     raise ValueError(\"Solution does not satisfy budget constraint.\")\n",
    "        \n",
    "    return d_star_closed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_gradient_closed_form(g, r, c, alpha, Q):\n",
    "    \"\"\"\n",
    "    Compute the analytical gradient of the optimal solution with respect to r.\n",
    "\n",
    "    This function computes the gradient matrix where each element (i, k) is the partial derivative\n",
    "    of d_i* with respect to r_k.\n",
    "\n",
    "    Parameters:\n",
    "    - g (np.ndarray): Gain factors (g_i), shape (n,)\n",
    "    - r (np.ndarray): Risk values (r_i), shape (n,)\n",
    "    - c (np.ndarray): Cost values (c_i), shape (n,)\n",
    "    - alpha (float or str): Fairness parameter. Can be 0, 1, 'inf', or a positive real number.\n",
    "    - Q (float): Total budget.\n",
    "\n",
    "    Returns:\n",
    "    - gradient (np.ndarray): Gradient matrix of shape (n, n)\n",
    "    \"\"\"\n",
    "    n = len(c)\n",
    "    gradient = np.zeros((n, n))\n",
    "    \n",
    "    # Compute S where necessary\n",
    "    if alpha == 1 or alpha == 'inf':\n",
    "        S = np.sum(c / (r * g))\n",
    "    elif isinstance(alpha, (int, float)) and alpha > 0 and alpha !=1:\n",
    "        S = np.sum((c / (r * g))** (1 / alpha))\n",
    "    \n",
    "    if alpha == 0:\n",
    "        # Utilitarian case: Allocate everything to the individual with the highest ratio\n",
    "        ratios = (r * g) / c\n",
    "        i_star = np.argmax(ratios)\n",
    "        # Gradient is Q * g_i / c_i at the allocated index, zero elsewhere\n",
    "        gradient[i_star, i_star] = Q * g[i_star] / c[i_star]\n",
    "        return gradient\n",
    "\n",
    "    elif alpha == 1:\n",
    "        # Nash welfare case\n",
    "        # d_i* = (Q / S) * (1 / c_i)\n",
    "        # ∂d_i*/∂r_k = Q * c_k / (c_i * r_k * g_k * S^2)\n",
    "        for i in range(n):\n",
    "            for k in range(n):\n",
    "                gradient[i, k] = (Q * c[k]) / (c[i] * r[k] * g[k] * S**2)\n",
    "        return gradient\n",
    "\n",
    "    elif alpha == 'inf':\n",
    "        # Maximin fairness case\n",
    "        # d_i* = (Q / S) * (1 / (r_i * g_i))\n",
    "        # ∂d_i*/∂r_k = \n",
    "        #   -Q / (r_i * g_i * S^2) if i == k\n",
    "        #   Q * c_k / (r_k * g_k)^2 / (r_i * g_i * S^2) if i != k\n",
    "        for i in range(n):\n",
    "            for k in range(n):\n",
    "                if i == k:\n",
    "                    gradient[i, k] = -Q / (r[i] * g[i] * S**2)\n",
    "                else:\n",
    "                    gradient[i, k] = (Q * c[k]) / ((r[k] * g[k])**2 * r[i] * g[i] * S**2)\n",
    "        return gradient\n",
    "\n",
    "    else:\n",
    "        # General alpha case: alpha >0, alpha !=1\n",
    "        if not isinstance(alpha, (int, float)):\n",
    "            raise TypeError(\"Alpha must be a positive real number, 0, 1, or 'inf'.\")\n",
    "        if alpha <= 0:\n",
    "            raise ValueError(\"Alpha must be positive for gradient computation.\")\n",
    "        \n",
    "        # d_i* = ( (r_i * g_i / c_i)^(1/alpha) ) / S * Q\n",
    "        # ∂d_i*/∂r_k = Q / S * (1/alpha) * (r_i * g_i / c_i)^(1/alpha -1) * (g_i / c_i if i ==k else 0) \n",
    "        # - Q / S^2 * ( (r_i * g_i / c_i)^(1/alpha) ) * ( (1/alpha) * (c_k / (r_k^2 * g_k)) * (r_k * g_k / c_k)^(1/alpha -1) ) )\n",
    "        \n",
    "        # Precompute terms\n",
    "        term = (r * g) / c  # Shape: (n,)\n",
    "        term_alpha = term**(1/alpha)  # Shape: (n,)\n",
    "        d_star = (term_alpha / S) * Q  # Shape: (n,)\n",
    "        \n",
    "        for i in range(n):\n",
    "            for k in range(n):\n",
    "                if i == k:\n",
    "                    # ∂d_i*/∂r_k = (1/alpha) * (r_i * g_i / c_i)^(1/alpha -1) * (g_i / c_i) * Q / S\n",
    "                    partial1 = (1.0 / alpha) * (term[i]**(1/alpha -1)) * (g[i] / c[i]) * Q / S\n",
    "                else:\n",
    "                    # ∂d_i*/∂r_k = - (term_alpha[i] * (1/alpha) * (c[k] / (r[k]**2 * g[k])) ) * Q / S^2\n",
    "                    partial1 = 0  # Since d_i* does not directly depend on r_k when i !=k in this term\n",
    "                # Now, the derivative of 1/S with respect to r_k:\n",
    "                # ∂(1/S)/∂r_k = - (c_k / (r_k**2 * g_k)) / S^2\n",
    "                partial2 = - (c[k] / (r[k]**2 * g[k])) / (S**2)\n",
    "                \n",
    "                # ∂d_i*/∂r_k = term_alpha[i] * partial2 * Q\n",
    "                gradient[i, k] = term_alpha[i] * partial2 * Q\n",
    "                \n",
    "                if i == k:\n",
    "                    gradient[i, k] += (1.0 / alpha) * (term[i]**(1/alpha -1)) * (g[i] / c[i]) * Q / S\n",
    "        \n",
    "        return gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0.,   0.,   0.,   0.,   0.,   0.,   0., 100.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.]),\n",
       " 19699.813436563036)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_c = compute_d_star_closed_form(gainF, risk, cost, alpha, Q)\n",
    "val_c = AlphaFairness(gainF * risk * sol_c, alpha)\n",
    "sol_c, val_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0.,   0.,   0.,   0.,   0.,   0.,   0., 100.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.]),\n",
       " 19699.813436563036)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol, val = solve_optimization(gainF, risk, cost, alpha, Q)\n",
    "sol, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(sol, sol_c, atol=1e-3), np.isclose(val, val_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "difference = np.abs(sol - sol_c) / (np.abs(sol_c) + 1e-7)\n",
    "difference.sum()\n",
    "\n",
    "percent_difference = difference.sum() * 100\n",
    "print('percent difference:', percent_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_c = compute_gradient_closed_form(gainF, risk, cost, alpha, Q) \n",
    "grad_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finite_difference_gradient(func, g, r, c, alpha, Q, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Compute numerical gradient using central finite differences.\n",
    "\n",
    "    Parameters:\n",
    "    - func: Function to compute d_star.\n",
    "    - g, r, c, alpha, Q: Parameters for the function.\n",
    "    - epsilon: Small perturbation.\n",
    "\n",
    "    Returns:\n",
    "    - numerical_grad: Gradient matrix of shape (n, n)\n",
    "    \"\"\"\n",
    "    n = len(r)\n",
    "    numerical_grad = np.zeros((n, n))\n",
    "    d_star_original = func(g, r, c, alpha, Q)\n",
    "    \n",
    "    for k in range(n):\n",
    "        r_perturbed = r.copy()\n",
    "        \n",
    "        if alpha == 0:\n",
    "            # Special handling for alpha = 0 (discrete allocation)\n",
    "            max_idx_original = np.argmax((r * g) / c)\n",
    "            max_idx_perturbed = np.argmax(((r + epsilon * (np.arange(n) == k)) * g) / c)\n",
    "            \n",
    "            if max_idx_original == max_idx_perturbed:\n",
    "                # No change in allocation, gradient is zero\n",
    "                numerical_grad[max_idx_original, k] = 0\n",
    "            else:\n",
    "                # Allocation changes, set a large gradient to reflect sensitivity\n",
    "                numerical_grad[max_idx_perturbed, k] = Q / c[max_idx_perturbed]        \n",
    "        else:\n",
    "            # General case: Compute finite difference\n",
    "            r_perturbed[k] += epsilon\n",
    "            d_star_perturbed = func(g, r_perturbed, c, alpha, Q)\n",
    "            \n",
    "            r_perturbed[k] -= 2 * epsilon\n",
    "            d_star_perturbed_neg = func(g, r_perturbed, c, alpha, Q)\n",
    "            \n",
    "            # ∂d_i*/∂r_k ≈ (d_star_perturbed - d_star_perturbed_neg) / (2 * epsilon)\n",
    "            numerical_grad[:, k] = (d_star_perturbed - d_star_perturbed_neg) / (2 * epsilon)\n",
    "    \n",
    "    return numerical_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytical_grad = compute_gradient_closed_form(gainF, risk, cost, alpha, Q)\n",
    "numerical_gradient = finite_difference_gradient(compute_d_star_closed_form, gainF, risk, cost, alpha, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytical_grad, numerical_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compare_gradients(analytical, numerical, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Compare analytical and numerical gradients using various metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    - analytical (np.ndarray): Analytical gradient matrix.\n",
    "    - numerical (np.ndarray): Numerical gradient matrix.\n",
    "    - epsilon (float): Small value to prevent division by zero.\n",
    "    \n",
    "    Returns:\n",
    "    - metrics (dict): Dictionary containing comparison metrics.\n",
    "    \"\"\"\n",
    "    absolute_error = np.abs(analytical - numerical)\n",
    "    relative_error = absolute_error / np.maximum(np.maximum(np.abs(analytical), np.abs(numerical)), epsilon)\n",
    "    l2_norm = np.linalg.norm(analytical - numerical)\n",
    "    linf_norm = np.linalg.norm(analytical - numerical, ord=np.inf)\n",
    "    cosine_similarity = np.dot(analytical.flatten(), numerical.flatten()) / (\n",
    "        np.linalg.norm(analytical) * np.linalg.norm(numerical) + epsilon\n",
    "    )\n",
    "    \n",
    "    metrics = {\n",
    "        \"Absolute Error\": absolute_error,\n",
    "        \"Relative Error\": relative_error,\n",
    "        \"L2 Norm\": l2_norm,\n",
    "        \"L-Infinity Norm\": linf_norm,\n",
    "        \"Cosine Similarity\": cosine_similarity\n",
    "    }\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Absolute Error** is calculated as:\n",
    "\n",
    "$$\n",
    "\\text{Absolute Error} = \\left| \\text{Analytical Gradient} - \\text{Numerical Gradient} \\right|\n",
    "$$\n",
    "\n",
    "**Relative Error** is calculated as:\n",
    "\n",
    "$$\n",
    "\\text{Relative Error} = \\frac{\\left| \\text{Analytical Gradient} - \\text{Numerical Gradient} \\right|}{\\max\\left(\\left| \\text{Analytical Gradient} \\right|, \\left| \\text{Numerical Gradient} \\right|, \\epsilon\\right)}\n",
    "$$\n",
    "\n",
    "**L2 Norm of Difference:** $$\\| \\text{Analytical Gradient} - \\text{Numerical Gradient} \\|_2$$\n",
    "\n",
    "**L-Infinity Norm (Maximum Absolute Error):** $$\\| \\text{Analytical Gradient} - \\text{Numerical Gradient} \\|_\\infty$$\n",
    "\n",
    "- Summarizes the overall difference. May mask local discrepancies.\n",
    "\n",
    "**Cosine Similarity**  $$\\frac{\\text{Analytical Gradient} \\cdot \\text{Numerical Gradient}}{\\| \\text{Analytical Gradient} \\|_2 \\| \\text{Numerical Gradient} \\|_2}$$\n",
    "\n",
    "- Measures the alignment of gradients irrespective of their magnitudes. Does not account for scale; two gradients can be parallel but differ in magnitude.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Analytical Gradient:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Numerical Gradient via Finite Differences:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Gradient Comparison Metrics:\n",
      "Absolute Error:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Relative Error:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "L2 Norm:\n",
      "50294.22591004963\n",
      "L-Infinity Norm:\n",
      "50294.22591004963\n",
      "Cosine Similarity:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the simple parameters\n",
    "g = gainF\n",
    "r = risk\n",
    "c = cost\n",
    "\n",
    "# Normalize r, c, g\n",
    "r_normalized = r / np.max(r)\n",
    "c_normalized = c / np.max(c)\n",
    "g_normalized = g / np.max(g)\n",
    "Q_normalized = Q / np.max(c)\n",
    "\n",
    "# Compute d_star\n",
    "d_star = compute_d_star_closed_form(g, r, c, alpha, Q)\n",
    "\n",
    "d_star_solver = solve_optimization(g, r, c, alpha, Q)\n",
    "print(np.allclose(d_star, d_star_solver[0], atol=1e-3))\n",
    "\n",
    "# Compute analytical gradient\n",
    "gradient_analytical = compute_gradient_closed_form(g, r, c, alpha, Q)\n",
    "print(\"Analytical Gradient:\\n\", gradient_analytical)\n",
    "\n",
    "# Compute numerical gradient using finite differences\n",
    "def finite_difference_gradient(func, g, r, c, alpha, Q, epsilon=1e-7):\n",
    "    n = len(r)\n",
    "    numerical_grad = np.zeros((n, n))\n",
    "    \n",
    "    for k in range(n):\n",
    "        r_plus = r.copy()\n",
    "        r_plus[k] += epsilon\n",
    "        d_star_plus = func(g, r_plus, c, alpha, Q)\n",
    "        \n",
    "        r_minus = r.copy()\n",
    "        r_minus[k] -= epsilon\n",
    "        d_star_minus = func(g, r_minus, c, alpha, Q)\n",
    "        \n",
    "        numerical_grad[:, k] = (d_star_plus - d_star_minus) / (2 * epsilon)\n",
    "    \n",
    "    return numerical_grad\n",
    "\n",
    "\n",
    "gradient_numerical = finite_difference_gradient(compute_d_star_closed_form, g, r, c, alpha, Q)\n",
    "print(\"\\nNumerical Gradient via Finite Differences:\\n\", gradient_numerical)\n",
    "\n",
    "\n",
    "# Compare gradients\n",
    "metrics = compare_gradients(gradient_analytical, gradient_numerical)\n",
    "print(\"\\nGradient Comparison Metrics:\")\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}:\")\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_gradients(analytical, numerical, title=\"Gradient Comparison\"):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(analytical, cmap='viridis', interpolation='none')\n",
    "    plt.title('Analytical Gradient')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(numerical, cmap='viridis', interpolation='none')\n",
    "    plt.title('Numerical Gradient')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_gradients(gradient_analytical, gradient_numerical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
